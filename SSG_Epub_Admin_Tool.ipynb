{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìö SSG Epub Admin Tool - Google Colab\n",
        "\n",
        "**Version**: 1.0  \n",
        "**Updated**: 2024-01-16  \n",
        "**Purpose**: Automated tool ƒë·ªÉ th√™m s√°ch v√†o SSG Epub Library\n",
        "\n",
        "## üéØ Ch·ª©c nƒÉng ch√≠nh:\n",
        "- **Mode 1**: Th√™m s√°ch manual v·ªõi platform shortening\n",
        "- **Mode 2**: Extract t·ª´ Google Drive epub file  \n",
        "- **Mode 3**: Bulk processing t·ª´ Google Drive folder\n",
        "- **Platform Management**: Add/manage URL shortening platforms\n",
        "- **Legacy Conversion**: Convert existing books v·ªõi platform m·ªõi\n",
        "\n",
        "## ‚ö†Ô∏è L∆∞u √Ω:\n",
        "- Mode 2 & 3: C·∫ßn paste fresh cURL v·ªõi authentication\n",
        "- Platform configs ƒë∆∞·ª£c l∆∞u trong GitHub `_data/platforms.yml`\n",
        "- T·∫•t c·∫£ URL ƒë∆∞·ª£c obfuscate tr∆∞·ªõc khi l∆∞u\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üì¶ Setup & Installation\n",
        "# @markdown C√†i ƒë·∫∑t dependencies v√† setup m√¥i tr∆∞·ªùng\n",
        "\n",
        "!pip install PyGithub requests ebooklib cloudinary Pillow python-dotenv pyyaml -q\n",
        "\n",
        "import os\n",
        "import json\n",
        "import yaml\n",
        "import requests\n",
        "import base64\n",
        "import re\n",
        "import shlex\n",
        "from datetime import datetime\n",
        "from urllib.parse import parse_qs, urlparse, urlencode\n",
        "import time\n",
        "\n",
        "# Google Colab specific imports\n",
        "from google.colab import files, drive, userdata\n",
        "from github import Github\n",
        "\n",
        "print(\"‚úÖ Dependencies installed successfully!\")\n",
        "print(\"üîß Setup ho√†n t·∫•t - s·∫µn s√†ng s·ª≠ d·ª•ng!\")\n",
        "print(\"üîê Secure credential management enabled v·ªõi Google Colab userdata\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üîê Secure Configuration & Credentials  \n",
        "# @markdown Load credentials t·ª´ Google Colab userdata (secure storage)\n",
        "\n",
        "class SecureCredentialManager:\n",
        "    \"\"\"Qu·∫£n l√Ω credentials m·ªôt c√°ch b·∫£o m·∫≠t v·ªõi Google Colab userdata\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.credentials = {}\n",
        "        self.load_credentials()\n",
        "    \n",
        "    def get_credential(self, key, prompt_text, is_required=True):\n",
        "        \"\"\"Get credential t·ª´ userdata ho·∫∑c prompt user\"\"\"\n",
        "        try:\n",
        "            # Ki·ªÉm tra userdata tr∆∞·ªõc\n",
        "            value = userdata.get(key)\n",
        "            if value:\n",
        "                print(f\"üîç ƒê√£ t√¨m th·∫•y {key} trong userdata\")\n",
        "                return value\n",
        "        except:\n",
        "            print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y {key} trong userdata\")\n",
        "        \n",
        "        # N·∫øu ch∆∞a c√≥, y√™u c·∫ßu ng∆∞·ªùi d√πng nh·∫≠p\n",
        "        if is_required:\n",
        "            value = input(f\"üîë {prompt_text}: \").strip()\n",
        "            if value:\n",
        "                print(f\"üìù B·∫°n c√≥ th·ªÉ l∆∞u v√†o userdata: userdata.set('{key}', 'your_value')\")\n",
        "                return value\n",
        "            else:\n",
        "                print(f\"‚ùå {key} is required!\")\n",
        "                return None\n",
        "        else:\n",
        "            value = input(f\"üîë {prompt_text} (optional): \").strip()\n",
        "            if value:\n",
        "                print(f\"üìù C√≥ th·ªÉ l∆∞u v√†o userdata: userdata.set('{key}', 'your_value')\")\n",
        "            return value or None\n",
        "    \n",
        "    def load_credentials(self):\n",
        "        \"\"\"Load t·∫•t c·∫£ credentials c·∫ßn thi·∫øt\"\"\"\n",
        "        print(\"üîê Loading Secure Credentials\")\n",
        "        print(\"=\" * 40)\n",
        "        \n",
        "        # GitHub credentials (required)\n",
        "        self.credentials['github_token'] = self.get_credential(\n",
        "            'GITHUB_TOKEN', \n",
        "            'GitHub Personal Access Token', \n",
        "            True\n",
        "        )\n",
        "        \n",
        "        self.credentials['github_repo'] = self.get_credential(\n",
        "            'GITHUB_REPO', \n",
        "            'GitHub Repository (user/repo)', \n",
        "            True\n",
        "        )\n",
        "        \n",
        "        self.credentials['branch_name'] = self.get_credential(\n",
        "            'BRANCH_NAME', \n",
        "            'Git Branch Name', \n",
        "            False\n",
        "        ) or \"main\"\n",
        "        \n",
        "        # Cloudinary credentials (optional)\n",
        "        self.credentials['cloudinary_cloud_name'] = self.get_credential(\n",
        "            'CLOUDINARY_CLOUD_NAME', \n",
        "            'Cloudinary Cloud Name', \n",
        "            False\n",
        "        )\n",
        "        \n",
        "        if self.credentials['cloudinary_cloud_name']:\n",
        "            self.credentials['cloudinary_api_key'] = self.get_credential(\n",
        "                'CLOUDINARY_API_KEY', \n",
        "                'Cloudinary API Key', \n",
        "                False\n",
        "            )\n",
        "            \n",
        "            self.credentials['cloudinary_api_secret'] = self.get_credential(\n",
        "                'CLOUDINARY_API_SECRET', \n",
        "                'Cloudinary API Secret', \n",
        "                False\n",
        "            )\n",
        "        \n",
        "        # API Configuration\n",
        "        self.credentials['default_config_api'] = self.get_credential(\n",
        "            'DEFAULT_CONFIG_API', \n",
        "            'Default Config API URL', \n",
        "            False\n",
        "        ) or \"\"\n",
        "        \n",
        "        # Validate and test GitHub\n",
        "        self.test_github_connection()\n",
        "    \n",
        "    def test_github_connection(self):\n",
        "        \"\"\"Test GitHub connection\"\"\"\n",
        "        if not self.credentials['github_token'] or not self.credentials['github_repo']:\n",
        "            print(\"‚ùå GitHub credentials missing!\")\n",
        "            return False\n",
        "        \n",
        "        try:\n",
        "            g = Github(self.credentials['github_token'])\n",
        "            repo = g.get_repo(self.credentials['github_repo'])\n",
        "            print(f\"‚úÖ GitHub connection successful: {repo.full_name}\")\n",
        "            print(f\"üìä Repository stats: {repo.stargazers_count} stars, {repo.forks_count} forks\")\n",
        "            \n",
        "            self.credentials['github_instance'] = g\n",
        "            self.credentials['repo_instance'] = repo\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå GitHub connection failed: {e}\")\n",
        "            print(\"üîß Please check your token and repository name\")\n",
        "            return False\n",
        "    \n",
        "    def get(self, key):\n",
        "        \"\"\"Get credential value\"\"\"\n",
        "        return self.credentials.get(key)\n",
        "    \n",
        "    def show_status(self):\n",
        "        \"\"\"Show configuration status\"\"\"\n",
        "        print(\"\\nüîß Configuration Status:\")\n",
        "        print(\"=\" * 30)\n",
        "        print(f\"üìÇ Target repository: {self.get('github_repo')}\")\n",
        "        print(f\"üåø Target branch: {self.get('branch_name')}\")\n",
        "        \n",
        "        if self.get('cloudinary_cloud_name'):\n",
        "            print(f\"‚òÅÔ∏è Cloudinary configured: {self.get('cloudinary_cloud_name')}\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Cloudinary not configured (image processing disabled)\")\n",
        "        \n",
        "        if self.get('default_config_api'):\n",
        "            print(f\"üîó Default API: {self.get('default_config_api')[:50]}...\")\n",
        "        \n",
        "        print(\"\\nüí° Tip: L∆∞u credentials v√†o userdata ƒë·ªÉ tr√°nh nh·∫≠p l·∫°i:\")\n",
        "        print(\"   userdata.set('GITHUB_TOKEN', 'your_token')\")\n",
        "        print(\"   userdata.set('GITHUB_REPO', 'user/repo')\")\n",
        "\n",
        "# Initialize secure credential manager\n",
        "credential_manager = SecureCredentialManager()\n",
        "credential_manager.show_status()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üîß Core Classes - GitHub Manager\n",
        "# @markdown GitHub operations for file management\n",
        "\n",
        "class GitHubManager:\n",
        "    def __init__(self, token, repo_name, branch=\"main\"):\n",
        "        self.github = Github(token)\n",
        "        self.repo = self.github.get_repo(repo_name)\n",
        "        self.branch = branch\n",
        "        \n",
        "    def file_exists(self, file_path):\n",
        "        \"\"\"Check if file exists in repo\"\"\"\n",
        "        try:\n",
        "            self.repo.get_contents(file_path, ref=self.branch)\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "    \n",
        "    def get_file_content(self, file_path):\n",
        "        \"\"\"Get file content as string\"\"\"\n",
        "        try:\n",
        "            file_data = self.repo.get_contents(file_path, ref=self.branch)\n",
        "            content = base64.b64decode(file_data.content).decode('utf-8')\n",
        "            return content\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to get file content: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def create_file(self, file_path, content, commit_message):\n",
        "        \"\"\"Create new file in repository\"\"\"\n",
        "        try:\n",
        "            if self.file_exists(file_path):\n",
        "                raise Exception(f\"File {file_path} already exists!\")\n",
        "            \n",
        "            self.repo.create_file(\n",
        "                path=file_path,\n",
        "                message=commit_message,\n",
        "                content=content,\n",
        "                branch=self.branch\n",
        "            )\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to create file: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def update_file(self, file_path, content, commit_message):\n",
        "        \"\"\"Update existing file\"\"\"\n",
        "        try:\n",
        "            file_data = self.repo.get_contents(file_path, ref=self.branch)\n",
        "            self.repo.update_file(\n",
        "                path=file_path,\n",
        "                message=commit_message,\n",
        "                content=content,\n",
        "                sha=file_data.sha,\n",
        "                branch=self.branch\n",
        "            )\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to update file: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def check_duplicate_book(self, title, author):\n",
        "        \"\"\"Check if book already exists\"\"\"\n",
        "        try:\n",
        "            contents = self.repo.get_contents(\"_epubs\", ref=self.branch)\n",
        "            \n",
        "            for content in contents:\n",
        "                if content.name.endswith('.md'):\n",
        "                    file_content = base64.b64decode(content.content).decode('utf-8')\n",
        "                    \n",
        "                    if '---' in file_content:\n",
        "                        yaml_content = file_content.split('---')[1]\n",
        "                        if f'title: \"{title}\"' in yaml_content and f'author: \"{author}\"' in yaml_content:\n",
        "                            return True, content.name\n",
        "            \n",
        "            return False, None\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not check duplicates: {e}\")\n",
        "            return False, None\n",
        "\n",
        "# Initialize GitHub manager v·ªõi secure credentials\n",
        "if credential_manager.get('github_token') and credential_manager.get('github_repo'):\n",
        "    try:\n",
        "        github_manager = GitHubManager(\n",
        "            credential_manager.get('github_token'), \n",
        "            credential_manager.get('github_repo'), \n",
        "            credential_manager.get('branch_name')\n",
        "        )\n",
        "        print(\"üìÇ GitHub Manager initialized successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå GitHub Manager failed: {e}\")\n",
        "        github_manager = None\n",
        "else:\n",
        "    github_manager = None\n",
        "    print(\"‚ö†Ô∏è GitHub Manager not initialized - please configure credentials first\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üîó URL Obfuscation System\n",
        "# @markdown Simple obfuscation cho download URLs\n",
        "\n",
        "class LinkObfuscator:\n",
        "    \"\"\"Simple obfuscation utilities - consistent v·ªõi frontend\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def encode(url):\n",
        "        try:\n",
        "            # Simple XOR with key + Base64 (same as frontend)\n",
        "            key = 'SSGEpub2024'\n",
        "            result = ''\n",
        "            for i in range(len(url)):\n",
        "                result += chr(ord(url[i]) ^ ord(key[i % len(key)]))\n",
        "            \n",
        "            encoded = base64.b64encode(result.encode('utf-8')).decode('utf-8')\n",
        "            return f\"data:encoded,{encoded}\"\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Failed to encode URL: {e}\")\n",
        "            return url\n",
        "    \n",
        "    @staticmethod\n",
        "    def decode(encoded_url):\n",
        "        try:\n",
        "            if encoded_url.startswith('data:encoded,'):\n",
        "                encoded_part = encoded_url.replace('data:encoded,', '')\n",
        "            else:\n",
        "                encoded_part = encoded_url\n",
        "            \n",
        "            key = 'SSGEpub2024'\n",
        "            decoded = base64.b64decode(encoded_part).decode('utf-8')\n",
        "            result = ''\n",
        "            for i in range(len(decoded)):\n",
        "                result += chr(ord(decoded[i]) ^ ord(key[i % len(key)]))\n",
        "            \n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Failed to decode URL: {e}\")\n",
        "            return None\n",
        "\n",
        "# Test obfuscation\n",
        "test_url = \"https://drive.google.com/file/d/1atVRKbZ07rSF5X_Q0OW1lLKywqAj4yvd/view?usp=sharing\"\n",
        "encoded = LinkObfuscator.encode(test_url)\n",
        "decoded = LinkObfuscator.decode(encoded)\n",
        "\n",
        "print(\"üß™ Testing URL Obfuscation:\")\n",
        "print(f\"Original: {test_url[:50]}...\")\n",
        "print(f\"Encoded: {encoded[:50]}...\")\n",
        "print(f\"Decoded: {decoded[:50]}...\")\n",
        "print(f\"‚úÖ Test: {'PASSED' if decoded == test_url else 'FAILED'}\")\n",
        "\n",
        "link_obfuscator = LinkObfuscator()\n",
        "print(\"üîó Link Obfuscator ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üåê Dynamic Platform Manager\n",
        "# @markdown Universal cURL parser cho custom shortening platforms\n",
        "\n",
        "class DynamicPlatformManager:\n",
        "    \"\"\"Dynamic platform manager v·ªõi simplified authentication\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.platforms = {}\n",
        "        \n",
        "    def parse_curl_command(self, curl_command):\n",
        "        \"\"\"Parse cURL command th√†nh request components\"\"\"\n",
        "        try:\n",
        "            # Clean command\n",
        "            curl_command = curl_command.strip()\n",
        "            if curl_command.startswith('curl '):\n",
        "                curl_command = curl_command[5:]\n",
        "            \n",
        "            config = {\n",
        "                'method': 'GET',\n",
        "                'url': '',\n",
        "                'headers': {},\n",
        "                'data': None,\n",
        "                'json': None\n",
        "            }\n",
        "            \n",
        "            # Extract method\n",
        "            method_match = re.search(r'-X\\s+(\\w+)', curl_command)\n",
        "            if method_match:\n",
        "                config['method'] = method_match.group(1).upper()\n",
        "            \n",
        "            # Extract URL\n",
        "            urls = re.findall(r'https?://[^\\s\\'\"]+', curl_command)\n",
        "            if urls:\n",
        "                config['url'] = urls[0]\n",
        "            \n",
        "            # Extract headers\n",
        "            headers = re.findall(r'-H\\s+[\\'\"]([^\\'\"]*)[\\'\"]', curl_command)\n",
        "            for header in headers:\n",
        "                if ':' in header:\n",
        "                    key, value = header.split(':', 1)\n",
        "                    config['headers'][key.strip()] = value.strip()\n",
        "            \n",
        "            # Extract data\n",
        "            data_matches = re.findall(r'-d\\s+[\\'\"]([^\\'\"]*)[\\'\"]', curl_command)\n",
        "            if data_matches:\n",
        "                data_string = data_matches[0]\n",
        "                \n",
        "                # Determine if JSON or form data\n",
        "                content_type = config['headers'].get('Content-Type', '').lower()\n",
        "                if 'application/json' in content_type:\n",
        "                    try:\n",
        "                        config['json'] = json.loads(data_string)\n",
        "                    except:\n",
        "                        config['data'] = data_string\n",
        "                else:\n",
        "                    # Parse as form data\n",
        "                    config['data'] = self._parse_form_data(data_string)\n",
        "            \n",
        "            return config\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error parsing cURL: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def _parse_form_data(self, data_string):\n",
        "        \"\"\"Parse form data string\"\"\"\n",
        "        try:\n",
        "            result = {}\n",
        "            pairs = data_string.split('&')\n",
        "            for pair in pairs:\n",
        "                if '=' in pair:\n",
        "                    key, value = pair.split('=', 1)\n",
        "                    result[key] = value\n",
        "            return result\n",
        "        except:\n",
        "            return data_string\n",
        "    \n",
        "    def add_platform_from_curl(self, platform_name, curl_command, response_config=None):\n",
        "        \"\"\"Add platform t·ª´ cURL example\"\"\"\n",
        "        request_config = self.parse_curl_command(curl_command)\n",
        "        if not request_config:\n",
        "            print(f\"‚ùå Failed to parse cURL for {platform_name}\")\n",
        "            return False\n",
        "        \n",
        "        if not response_config:\n",
        "            response_config = {'type': 'auto'}\n",
        "        \n",
        "        self.platforms[platform_name] = {\n",
        "            'name': platform_name,\n",
        "            'request_config': request_config,\n",
        "            'response_config': response_config,\n",
        "            'curl_template': curl_command\n",
        "        }\n",
        "        \n",
        "        print(f\"‚úÖ Added platform: {platform_name}\")\n",
        "        return True\n",
        "    \n",
        "    def shorten_url(self, platform_name, target_url):\n",
        "        \"\"\"Shorten URL v·ªõi specified platform\"\"\"\n",
        "        if platform_name not in self.platforms:\n",
        "            print(f\"‚ùå Platform not found: {platform_name}\")\n",
        "            return target_url\n",
        "        \n",
        "        platform = self.platforms[platform_name]\n",
        "        \n",
        "        try:\n",
        "            # Build request v·ªõi target URL\n",
        "            request_config = self._prepare_request(platform['request_config'], target_url)\n",
        "            \n",
        "            # Execute request\n",
        "            response = self._execute_request(request_config)\n",
        "            \n",
        "            if response and response.status_code == 200:\n",
        "                short_url = self._extract_short_url(response, platform['response_config'])\n",
        "                \n",
        "                if short_url and short_url.startswith('http'):\n",
        "                    print(f\"‚úÖ {platform_name}: {target_url[:50]}... ‚Üí {short_url}\")\n",
        "                    return short_url\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è Could not extract URL from {platform_name} response\")\n",
        "                    return target_url\n",
        "            else:\n",
        "                status = response.status_code if response else 'No response'\n",
        "                print(f\"‚ùå {platform_name} request failed: {status}\")\n",
        "                return target_url\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error with {platform_name}: {e}\")\n",
        "            return target_url\n",
        "    \n",
        "    def _prepare_request(self, config, target_url):\n",
        "        \"\"\"Replace ${link_drive} placeholder v·ªõi actual URL\"\"\"\n",
        "        prepared_config = config.copy()\n",
        "        \n",
        "        # Replace in JSON data\n",
        "        if prepared_config.get('json'):\n",
        "            prepared_config['json'] = self._replace_placeholder(\n",
        "                prepared_config['json'], target_url\n",
        "            )\n",
        "        \n",
        "        # Replace in form data\n",
        "        if prepared_config.get('data'):\n",
        "            prepared_config['data'] = self._replace_placeholder(\n",
        "                prepared_config['data'], target_url\n",
        "            )\n",
        "        \n",
        "        return prepared_config\n",
        "    \n",
        "    def _replace_placeholder(self, data, target_url):\n",
        "        \"\"\"Replace ${link_drive} placeholder recursively\"\"\"\n",
        "        if isinstance(data, dict):\n",
        "            return {k: self._replace_placeholder(v, target_url) for k, v in data.items()}\n",
        "        elif isinstance(data, str):\n",
        "            return data.replace('${link_drive}', target_url)\n",
        "        else:\n",
        "            return data\n",
        "    \n",
        "    def _execute_request(self, config):\n",
        "        \"\"\"Execute HTTP request\"\"\"\n",
        "        try:\n",
        "            method = config['method'].lower()\n",
        "            url = config['url']\n",
        "            headers = config.get('headers', {})\n",
        "            \n",
        "            kwargs = {'headers': headers}\n",
        "            \n",
        "            if config.get('json'):\n",
        "                kwargs['json'] = config['json']\n",
        "            elif config.get('data'):\n",
        "                kwargs['data'] = config['data']\n",
        "            \n",
        "            response = getattr(requests, method)(url, **kwargs)\n",
        "            return response\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Request execution failed: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def _extract_short_url(self, response, config):\n",
        "        \"\"\"Extract short URL t·ª´ response\"\"\"\n",
        "        try:\n",
        "            if response.headers.get('content-type', '').startswith('application/json'):\n",
        "                data = response.json()\n",
        "                \n",
        "                if 'path' in config:\n",
        "                    path_parts = config['path'].split('.')\n",
        "                    current = data\n",
        "                    for part in path_parts:\n",
        "                        if isinstance(current, dict) and part in current:\n",
        "                            current = current[part]\n",
        "                        else:\n",
        "                            return None\n",
        "                    return str(current) if current else None\n",
        "                \n",
        "                # Auto-detect common fields\n",
        "                common_fields = ['short_url', 'shortened_url', 'url', 'link', 'shortlink']\n",
        "                for field in common_fields:\n",
        "                    if field in data:\n",
        "                        return str(data[field])\n",
        "            else:\n",
        "                text = response.text.strip()\n",
        "                if 'regex' in config:\n",
        "                    match = re.search(config['regex'], text)\n",
        "                    return match.group(0) if match else None\n",
        "                elif text.startswith('http'):\n",
        "                    return text\n",
        "            \n",
        "            return None\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Extraction error: {e}\")\n",
        "            return None\n",
        "\n",
        "# Initialize dynamic platform manager\n",
        "dynamic_platform_manager = DynamicPlatformManager()\n",
        "print(\"üåê Dynamic Platform Manager initialized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üèóÔ∏è Platform Configuration Manager\n",
        "# @markdown Qu·∫£n l√Ω platform configs trong GitHub\n",
        "\n",
        "class PlatformConfigManager:\n",
        "    def __init__(self, github_manager):\n",
        "        self.github_manager = github_manager\n",
        "        self.config_file = \"_data/platforms.yml\"\n",
        "        self.platforms = {}\n",
        "        self.next_index = 0\n",
        "        \n",
        "        # Load existing platforms\n",
        "        self.load_platforms()\n",
        "    \n",
        "    def load_platforms(self):\n",
        "        \"\"\"Load platforms t·ª´ GitHub\"\"\"\n",
        "        try:\n",
        "            if self.github_manager and self.github_manager.file_exists(self.config_file):\n",
        "                content = self.github_manager.get_file_content(self.config_file)\n",
        "                if content:\n",
        "                    config = yaml.safe_load(content)\n",
        "                    if config and 'platforms' in config:\n",
        "                        for platform in config['platforms']:\n",
        "                            self.platforms[platform['id']] = platform\n",
        "                        \n",
        "                        # Calculate next available index\n",
        "                        if self.platforms:\n",
        "                            self.next_index = max(p['index'] for p in self.platforms.values()) + 1\n",
        "                        else:\n",
        "                            self.next_index = 0\n",
        "                        \n",
        "                        print(f\"‚úÖ Loaded {len(self.platforms)} platforms from GitHub\")\n",
        "                        return\n",
        "            \n",
        "            # Initialize with default platforms\n",
        "            self._initialize_default_platforms()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error loading platforms: {e}\")\n",
        "            self._initialize_default_platforms()\n",
        "    \n",
        "    def _initialize_default_platforms(self):\n",
        "        \"\"\"Initialize v·ªõi default platforms\"\"\"\n",
        "        default_platforms = [\n",
        "            {\n",
        "                'name': 'Google Drive',\n",
        "                'id': 'gdrive',\n",
        "                'index': 0,\n",
        "                'icon': 'fab fa-google-drive',\n",
        "                'type': 'direct',\n",
        "                'active': True,\n",
        "                'created_date': datetime.now().isoformat()\n",
        "            },\n",
        "            {\n",
        "                'name': 'OneDrive',\n",
        "                'id': 'onedrive',\n",
        "                'index': 1,\n",
        "                'icon': 'fab fa-microsoft',\n",
        "                'type': 'direct',\n",
        "                'active': True,\n",
        "                'created_date': datetime.now().isoformat()\n",
        "            }\n",
        "        ]\n",
        "        \n",
        "        for platform in default_platforms:\n",
        "            self.platforms[platform['id']] = platform\n",
        "        \n",
        "        self.next_index = 2\n",
        "        print(\"üîß Initialized v·ªõi default platforms\")\n",
        "    \n",
        "    def add_platform(self, name, platform_id, icon, curl_template, response_config):\n",
        "        \"\"\"Add new platform v·ªõi fixed index\"\"\"\n",
        "        try:\n",
        "            if platform_id in self.platforms:\n",
        "                print(f\"‚ö†Ô∏è Platform {platform_id} already exists!\")\n",
        "                return False\n",
        "            \n",
        "            new_platform = {\n",
        "                'name': name,\n",
        "                'id': platform_id,\n",
        "                'index': self.next_index,\n",
        "                'icon': icon,\n",
        "                'type': 'shortener',\n",
        "                'active': True,\n",
        "                'created_date': datetime.now().isoformat(),\n",
        "                'curl_template': curl_template,\n",
        "                'response_config': response_config\n",
        "            }\n",
        "            \n",
        "            self.platforms[platform_id] = new_platform\n",
        "            self.next_index += 1\n",
        "            \n",
        "            # Save to GitHub\n",
        "            if self.save_platforms():\n",
        "                print(f\"‚úÖ Added platform: {name} (index {new_platform['index']})\\\")\\n                return True\\n            else:\\n                # Rollback\\n                del self.platforms[platform_id]\\n                self.next_index -= 1\\n                print(f\\\"‚ùå Failed to save platform {name}\\\")\\n                return False\\n                \\n        except Exception as e:\\n            print(f\\\"‚ùå Error adding platform: {e}\\\")\\n            return False\\n    \\n    def save_platforms(self):\\n        \\\"\\\"\\\"Save platforms to GitHub\\\"\\\"\\\"\\n        try:\\n            config = {\\n                'platforms': list(self.platforms.values()),\\n                'metadata': {\\n                    'version': '1.0.0',\\n                    'last_updated': datetime.now().isoformat(),\\n                    'next_index': self.next_index\\n                }\\n            }\\n            \\n            yaml_content = yaml.dump(config, default_flow_style=False, allow_unicode=True)\\n            \\n            if self.github_manager.file_exists(self.config_file):\\n                success = self.github_manager.update_file(\\n                    self.config_file,\\n                    yaml_content,\\n                    f\\\"C·∫≠p nh·∫≠t platform configurations - {len(self.platforms)} platforms\\\"\\n                )\\n            else:\\n                success = self.github_manager.create_file(\\n                    self.config_file,\\n                    yaml_content,\\n                    \\\"Kh·ªüi t·∫°o platform configurations\\\"\\n                )\\n            \\n            if success:\\n                print(f\\\"üíæ Saved {len(self.platforms)} platforms to GitHub\\\")\\n                return True\\n            else:\\n                print(\\\"‚ùå Failed to save platforms to GitHub\\\")\\n                return False\\n                \\n        except Exception as e:\\n            print(f\\\"‚ùå Error saving platforms: {e}\\\")\\n            return False\\n    \\n    def get_platform_by_index(self, index):\\n        \\\"\\\"\\\"Get platform by index\\\"\\\"\\\"\\n        for platform in self.platforms.values():\\n            if platform['index'] == index:\\n                return platform\\n        return None\\n    \\n    def list_platforms(self):\\n        \\\"\\\"\\\"List all platforms\\\"\\\"\\\"\\n        print(\\\"üìã Available Platforms:\\\")\\n        print(\\\"=\\\" * 50)\\n        \\n        sorted_platforms = sorted(self.platforms.values(), key=lambda x: x['index'])\\n        \\n        for platform in sorted_platforms:\\n            status = \\\"üü¢\\\" if platform['active'] else \\\"üî¥\\\"\\n            platform_type = \\\"üìé\\\" if platform['type'] == 'direct' else \\\"üîó\\\"\\n            \\n            print(f\\\"{status} {platform_type} [{platform['index']}] {platform['name']} ({platform['id']})\\\")\\n            \\n            if platform.get('curl_template'):\\n                print(f\\\"   üìù cURL configured\\\")\\n            \\n        print(f\\\"\\\\nüìä Total: {len(self.platforms)} platforms\\\")\\n        print(f\\\"üî¢ Next index: {self.next_index}\\\")\\n\\n# Initialize platform config manager\\nif github_manager:\\n    platform_config_manager = PlatformConfigManager(github_manager)\\n    print(\\\"üèóÔ∏è Platform Config Manager initialized!\\\")\\nelse:\\n    platform_config_manager = None\\n    print(\\\"‚ö†Ô∏è Platform Config Manager not initialized - GitHub required\\\")\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üìù Markdown Generator\n",
        "# @markdown Generate Jekyll-compatible markdown files\n",
        "\n",
        "class MarkdownGenerator:\n",
        "    def __init__(self):\n",
        "        self.obfuscator = LinkObfuscator()\n",
        "    \n",
        "    def generate_filename(self, title):\n",
        "        \"\"\"Generate filename from title\"\"\"\n",
        "        # Remove Vietnamese tones and special chars\n",
        "        filename = self.remove_vietnamese_tones(title)\n",
        "        filename = re.sub(r'[^a-zA-Z0-9\\s]', '', filename)\n",
        "        filename = re.sub(r'\\s+', '-', filename.strip().lower())\n",
        "        return f\"{filename[:50]}.md\"\n",
        "    \n",
        "    def remove_vietnamese_tones(self, text):\n",
        "        \"\"\"Remove Vietnamese accents\"\"\"\n",
        "        replacements = {\n",
        "            '√†|√°|·∫°|·∫£|√£|√¢|·∫ß|·∫•|·∫≠|·∫©|·∫´|ƒÉ|·∫±|·∫Ø|·∫∑|·∫≥|·∫µ': 'a',\n",
        "            '√®|√©|·∫π|·∫ª|·∫Ω|√™|·ªÅ|·∫ø|·ªá|·ªÉ|·ªÖ': 'e',\n",
        "            '√¨|√≠|·ªã|·ªâ|ƒ©': 'i',\n",
        "            '√≤|√≥|·ªç|·ªè|√µ|√¥|·ªì|·ªë|·ªô|·ªï|·ªó|∆°|·ªù|·ªõ|·ª£|·ªü|·ª°': 'o',\n",
        "            '√π|√∫|·ª•|·ªß|≈©|∆∞|·ª´|·ª©|·ª±|·ª≠|·ªØ': 'u',\n",
        "            '·ª≥|√Ω|·ªµ|·ª∑|·ªπ': 'y',\n",
        "            'ƒë': 'd'\n",
        "        }\n",
        "        \n",
        "        for pattern, replacement in replacements.items():\n",
        "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "        \n",
        "        return text\n",
        "    \n",
        "    def generate_markdown(self, book_data):\n",
        "        \"\"\"Generate complete markdown file content\"\"\"\n",
        "        \n",
        "        yaml_lines = [\"---\", \"layout: epub\"]\n",
        "        \n",
        "        # Required fields\n",
        "        yaml_lines.append(f'title: \"{book_data[\"title\"]}\"')\n",
        "        yaml_lines.append(f'author: \"{book_data[\"author\"]}\"')\n",
        "        yaml_lines.append(f'cover_image: \"{book_data[\"cover_image\"]}\"')\n",
        "        \n",
        "        # Optional fields\n",
        "        optional_fields = ['preview_image', 'isbn', 'published_date', 'language', 'publisher']\n",
        "        for field in optional_fields:\n",
        "            if book_data.get(field):\n",
        "                yaml_lines.append(f'{field}: \"{book_data[field]}\"')\n",
        "        \n",
        "        # Genre array\n",
        "        if book_data.get(\"genre\"):\n",
        "            yaml_lines.append(\"genre:\")\n",
        "            for genre in book_data[\"genre\"]:\n",
        "                yaml_lines.append(f'  - \"{genre}\"')\n",
        "        \n",
        "        yaml_lines.append(f'description: \"{book_data[\"description\"]}\"')\n",
        "        \n",
        "        # Numeric fields\n",
        "        if book_data.get(\"rating\"):\n",
        "            yaml_lines.append(f'rating: {book_data[\"rating\"]}')\n",
        "        \n",
        "        if book_data.get(\"pages\"):\n",
        "            yaml_lines.append(f'pages: {book_data[\"pages\"]}')\n",
        "        \n",
        "        # Preview content\n",
        "        if book_data.get(\"preview_content\"):\n",
        "            yaml_lines.append(\"preview_content: |\")\n",
        "            for line in book_data[\"preview_content\"].split('\\n'):\n",
        "                yaml_lines.append(f\"  {line}\")\n",
        "        \n",
        "        # Download links v·ªõi obfuscation\n",
        "        if book_data.get(\"download_links\"):\n",
        "            yaml_lines.append(\"download_links:\")\n",
        "            for link in book_data[\"download_links\"]:\n",
        "                # Obfuscate URL if not already obfuscated\n",
        "                url = link[\"url\"]\n",
        "                if not url.startswith('data:encoded,'):\n",
        "                    url = self.obfuscator.encode(url)\n",
        "                \n",
        "                yaml_lines.append(f'  - platform: \"{link[\"platform\"]}\"')\n",
        "                yaml_lines.append(f'    url: \"{url}\"')\n",
        "                yaml_lines.append(f'    index: {link[\"index\"]}')\n",
        "                yaml_lines.append(f'    icon: \"{link[\"icon\"]}\"')\n",
        "        \n",
        "        # Config URL\n",
        "        if book_data.get(\"config_url\"):\n",
        "            yaml_lines.append(f'download_config_url: \"{book_data[\"config_url\"]}\"')\n",
        "        \n",
        "        # Tags\n",
        "        if book_data.get(\"tags\"):\n",
        "            yaml_lines.append(\"tags:\")\n",
        "            for tag in book_data[\"tags\"]:\n",
        "                yaml_lines.append(f'  - \"{tag}\"')\n",
        "        \n",
        "        yaml_lines.append(\"---\")\n",
        "        yaml_lines.append(\"\")\n",
        "        yaml_lines.append(f'ƒê√¢y l√† trang chi ti·∫øt c·ªßa cu·ªën s√°ch \"{{{{ page.title }}}}\" c·ªßa t√°c gi·∫£ {{{{ page.author }}}}.') \n",
        "        \n",
        "        return '\\n'.join(yaml_lines)\n",
        "\n",
        "# Initialize markdown generator\n",
        "markdown_generator = MarkdownGenerator()\n",
        "print(\"üìù Markdown Generator initialized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üöÄ System Status Check\n",
        "# @markdown Ki·ªÉm tra status v√† s·∫µn s√†ng s·ª≠ d·ª•ng\n",
        "\n",
        "def check_system_status():\n",
        "    \"\"\"Check system components status\"\"\"\n",
        "    print(\"üîç System Status Check:\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # GitHub\n",
        "    if github_manager:\n",
        "        print(\"‚úÖ GitHub Manager: Ready\")\n",
        "        try:\n",
        "            # Test repo access\n",
        "            repo_info = github_manager.repo\n",
        "            print(f\"   üìÇ Repository: {repo_info.full_name}\")\n",
        "            print(f\"   üåø Branch: {github_manager.branch}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è Repository access issue: {e}\")\n",
        "    else:\n",
        "        print(\"‚ùå GitHub Manager: Not configured\")\n",
        "    \n",
        "    # Platform Manager\n",
        "    print(f\"‚úÖ Platform Manager: Ready ({len(dynamic_platform_manager.platforms)} platforms)\")\n",
        "    \n",
        "    # Platform Config Manager\n",
        "    if platform_config_manager:\n",
        "        print(f\"‚úÖ Platform Config: Ready ({len(platform_config_manager.platforms)} registered)\")\n",
        "    else:\n",
        "        print(\"‚ùå Platform Config: Not initialized\")\n",
        "    \n",
        "    # Obfuscation\n",
        "    print(\"‚úÖ Link Obfuscation: Ready\")\n",
        "    \n",
        "    # Markdown Generator\n",
        "    print(\"‚úÖ Markdown Generator: Ready\")\n",
        "    \n",
        "    # Cloudinary\n",
        "    if credential_manager.get('cloudinary_cloud_name'):\n",
        "        print(f\"‚úÖ Cloudinary: Configured ({credential_manager.get('cloudinary_cloud_name')})\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Cloudinary: Not configured (image processing disabled)\")\n",
        "    \n",
        "    print(\"\\nüéØ Available Commands:\")\n",
        "    print(\"   üìö Mode 1: Manual book addition\")\n",
        "    print(\"   üìÇ Mode 2: Google Drive epub extraction\")\n",
        "    print(\"   üìÅ Mode 3: Bulk folder processing\")\n",
        "    print(\"   üîß Platform Management\")\n",
        "    print(\"   üîÑ Legacy Conversion\")\n",
        "\n",
        "# Run status check\n",
        "check_system_status()\n",
        "\n",
        "print(\"\\nüöÄ SSG Epub Admin Tool s·∫µn s√†ng s·ª≠ d·ª•ng!\")\n",
        "print(\"üìã Ch·∫°y c√°c cell b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üîß Platform Management\n",
        "\n",
        "Qu·∫£n l√Ω c√°c platform r√∫t g·ªçn link\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üìã List Existing Platforms\n",
        "# @markdown Hi·ªÉn th·ªã t·∫•t c·∫£ platforms ƒë√£ ƒëƒÉng k√Ω\n",
        "\n",
        "if platform_config_manager:\n",
        "    platform_config_manager.list_platforms()\n",
        "else:\n",
        "    print(\"‚ùå Platform Config Manager not available!\")\n",
        "    print(\"üîß Please configure GitHub credentials first\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ‚ûï Add New Platform\n",
        "# @markdown Th√™m platform r√∫t g·ªçn m·ªõi\n",
        "\n",
        "def add_new_platform():\n",
        "    \"\"\"Interactive platform addition\"\"\"\n",
        "    if not platform_config_manager:\n",
        "        print(\"‚ùå Platform Config Manager not available!\")\n",
        "        return\n",
        "    \n",
        "    print(\"üîß Th√™m Platform R√∫t G·ªçn M·ªõi\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Platform info\n",
        "    platform_name = input(\"üìù T√™n platform (VD: YeuMoney): \").strip()\n",
        "    if not platform_name:\n",
        "        print(\"‚ùå Platform name is required!\")\n",
        "        return\n",
        "    \n",
        "    platform_id = input(\"üÜî Platform ID (VD: yeumoney): \").strip().lower()\n",
        "    if not platform_id:\n",
        "        platform_id = platform_name.lower().replace(' ', '')\n",
        "    \n",
        "    icon = input(\"üé® Icon class (VD: fas fa-heart): \").strip()\n",
        "    if not icon:\n",
        "        icon = \"fas fa-link\"\n",
        "    \n",
        "    print(f\"\\nüìù Nh·∫≠p cURL command (c√≥ ch·ª©a ${{link_drive}}):\")\n",
        "    print(\"VD: curl -X POST 'https://yeumoney.com/api' -H 'Authorization: Bearer abc123' -d '{\\\"url\\\": \\\"${{link_drive}}\\\"}'\\\")\n",
        "    \n",
        "    curl_command = input(\"\\ncURL: \").strip()\n",
        "    if not curl_command:\n",
        "        print(\"‚ùå cURL command is required!\")\n",
        "        return\n",
        "    \n",
        "    # Response config\n",
        "    print(f\"\\nüîß Response Configuration:\")\n",
        "    print(\"1. Auto-detect (recommended)\")\n",
        "    print(\"2. JSON path (VD: data.short_url)\")\n",
        "    print(\"3. Regex pattern\")\n",
        "    \n",
        "    config_choice = input(\"Ch·ªçn (1-3): \").strip()\n",
        "    \n",
        "    response_config = {'type': 'auto'}\n",
        "    \n",
        "    if config_choice == \"2\":\n",
        "        json_path = input(\"JSON path (VD: data.short_url): \").strip()\n",
        "        if json_path:\n",
        "            response_config = {'type': 'json', 'path': json_path}\n",
        "    elif config_choice == \"3\":\n",
        "        regex_pattern = input(\"Regex pattern: \").strip()\n",
        "        if regex_pattern:\n",
        "            response_config = {'type': 'text', 'regex': regex_pattern}\n",
        "    \n",
        "    # Test platform\n",
        "    print(f\"\\nüß™ Testing platform configuration...\")\n",
        "    \n",
        "    # Add to dynamic manager for testing\n",
        "    dynamic_platform_manager.add_platform_from_curl(platform_name, curl_command, response_config)\n",
        "    \n",
        "    test_url = \"https://drive.google.com/file/d/1atVRKbZ07rSF5X_Q0OW1lLKywqAj4yvd/view?usp=sharing\"\n",
        "    print(f\"üîó Testing v·ªõi: {test_url[:50]}...\")\n",
        "    \n",
        "    result = dynamic_platform_manager.shorten_url(platform_name, test_url)\n",
        "    \n",
        "    if result != test_url:\n",
        "        print(f\"‚úÖ Test successful: {result}\")\n",
        "        \n",
        "        # Confirm save\n",
        "        save_confirm = input(f\"\\nüíæ Save platform '{platform_name}' to GitHub? (y/N): \").strip().lower()\n",
        "        \n",
        "        if save_confirm == 'y':\n",
        "            success = platform_config_manager.add_platform(\n",
        "                platform_name, platform_id, icon, curl_command, response_config\n",
        "            )\n",
        "            \n",
        "            if success:\n",
        "                print(f\"‚úÖ Platform '{platform_name}' added successfully!\")\n",
        "                print(f\"üìç Assigned index: {platform_config_manager.platforms[platform_id]['index']}\")\n",
        "            else:\n",
        "                print(f\"‚ùå Failed to save platform!\")\n",
        "        else:\n",
        "            print(\"‚ùå Platform not saved\")\n",
        "    else:\n",
        "        print(f\"‚ùå Test failed - platform kh√¥ng ho·∫°t ƒë·ªông ƒë√∫ng\")\n",
        "        print(\"üîß Ki·ªÉm tra l·∫°i cURL command v√† response config\")\n",
        "\n",
        "# Run interactive platform addition\n",
        "add_new_platform()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üìö Mode 1: Manual Book Addition  \n",
        "\n",
        "Th√™m s√°ch th·ªß c√¥ng v·ªõi platform shortening\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üìù Mode 1: Manual Book Addition\n",
        "# @markdown Th√™m s√°ch th·ªß c√¥ng v·ªõi platform shortening\n",
        "\n",
        "def mode1_manual_book_addition():\n",
        "    \"\"\"Mode 1: Manual book addition v·ªõi platform shortening\"\"\"\n",
        "    \n",
        "    if not github_manager or not platform_config_manager:\n",
        "        print(\"‚ùå Required managers not available!\")\n",
        "        print(\"üîß Please configure GitHub credentials first\")\n",
        "        return\n",
        "    \n",
        "    print(\"üìö Mode 1: Manual Book Addition\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Basic book information\n",
        "    print(\"üìñ Basic Information:\")\n",
        "    title = input(\"üìñ Title: \").strip()\n",
        "    if not title:\n",
        "        print(\"‚ùå Title is required!\")\n",
        "        return\n",
        "    \n",
        "    author = input(\"‚úçÔ∏è Author: \").strip()\n",
        "    if not author:\n",
        "        print(\"‚ùå Author is required!\")\n",
        "        return\n",
        "    \n",
        "    # Check for duplicates\n",
        "    print(f\"\\nüîç Checking for duplicates...\")\n",
        "    is_duplicate, existing_file = github_manager.check_duplicate_book(title, author)\n",
        "    \n",
        "    if is_duplicate:\n",
        "        print(f\"‚ö†Ô∏è Book already exists: {existing_file}\")\n",
        "        overwrite = input(\"üìù Continue anyway? (y/N): \").strip().lower()\n",
        "        if overwrite != 'y':\n",
        "            print(\"‚ùå Operation cancelled\")\n",
        "            return\n",
        "    \n",
        "    # Collect book metadata\n",
        "    description = input(\"üìÑ Description: \").strip()\n",
        "    cover_image = input(\"üñºÔ∏è Cover image URL: \").strip()\n",
        "    \n",
        "    # Optional fields\n",
        "    preview_image = input(\"üñºÔ∏è Preview image URL (optional): \").strip()\n",
        "    isbn = input(\"üìä ISBN (optional): \").strip()\n",
        "    published_date = input(\"üìÖ Published date (YYYY-MM-DD, optional): \").strip()\n",
        "    language = input(\"üåê Language (optional): \").strip() or \"Ti·∫øng Vi·ªát\"\n",
        "    publisher = input(\"üè¢ Publisher (optional): \").strip()\n",
        "    \n",
        "    # Genre\n",
        "    genres_input = input(\"üè∑Ô∏è Genres (comma separated): \").strip()\n",
        "    genres = [g.strip() for g in genres_input.split(',')] if genres_input else []\n",
        "    \n",
        "    # Rating and pages\n",
        "    rating_input = input(\"‚≠ê Rating (1-5, optional): \").strip()\n",
        "    rating = float(rating_input) if rating_input and rating_input.replace('.', '').isdigit() else None\n",
        "    \n",
        "    pages_input = input(\"üìÑ Pages (optional): \").strip()\n",
        "    pages = int(pages_input) if pages_input.isdigit() else None\n",
        "    \n",
        "    # Config URL\n",
        "    config_url = input(\"üîó Config API URL (optional): \").strip() or credential_manager.get('default_config_api')\n",
        "    \n",
        "    # Download links setup\n",
        "    print(f\"\\nüîó Download Links Setup:\")\n",
        "    print(\"Available platforms:\")\n",
        "    if platform_config_manager:\n",
        "        platform_config_manager.list_platforms()\n",
        "    \n",
        "    download_links = []\n",
        "    \n",
        "    while True:\n",
        "        print(f\"\\n‚ûï Adding download link #{len(download_links) + 1}\")\n",
        "        \n",
        "        # Show available platforms\n",
        "        available_platforms = list(platform_config_manager.platforms.keys())\n",
        "        print(f\"Available platforms: {', '.join(available_platforms)}\")\n",
        "        \n",
        "        platform_id = input(\"üåê Platform ID (ho·∫∑c 'done' ƒë·ªÉ ho√†n th√†nh): \").strip().lower()\n",
        "        \n",
        "        if platform_id == 'done':\n",
        "            break\n",
        "        \n",
        "        if platform_id not in platform_config_manager.platforms:\n",
        "            print(f\"‚ùå Platform '{platform_id}' not found!\")\n",
        "            continue\n",
        "        \n",
        "        platform_info = platform_config_manager.platforms[platform_id]\n",
        "        \n",
        "        # Get original URL\n",
        "        original_url = input(f\"üîó Original URL cho {platform_info['name']}: \").strip()\n",
        "        if not original_url:\n",
        "            print(\"‚ùå URL is required!\")\n",
        "            continue\n",
        "        \n",
        "        # For shortener platforms, get cURL for shortening\n",
        "        if platform_info['type'] == 'shortener':\n",
        "            print(f\"\\nüîß Shortening with {platform_info['name']}...\")\n",
        "            print(f\"üìù Paste fresh cURL command (v·ªõi authentication):\\\")\\n            print(f\\\"(Replace ${{link_drive}} s·∫Ω ƒë∆∞·ª£c thay th·∫ø t·ª± ƒë·ªông)\\\")\\n            \\n            fresh_curl = input(\\\"cURL: \\\").strip()\\n            if fresh_curl:\\n                # Update platform with fresh cURL\\n                dynamic_platform_manager.add_platform_from_curl(\\n                    platform_info['name'], \\n                    fresh_curl, \\n                    platform_info.get('response_config')\\n                )\\n                \\n                # Shorten URL\\n                shortened_url = dynamic_platform_manager.shorten_url(platform_info['name'], original_url)\\n                \\n                if shortened_url != original_url:\\n                    final_url = shortened_url\\n                    print(f\\\"‚úÖ Shortened: {original_url[:30]}... ‚Üí {shortened_url}\\\")\\n                else:\\n                    print(f\\\"‚ö†Ô∏è Shortening failed, using original URL\\\")\\n                    final_url = original_url\\n            else:\\n                print(f\\\"‚ö†Ô∏è No cURL provided, using original URL\\\")\\n                final_url = original_url\\n        else:\\n            # Direct platform\\n            final_url = original_url\\n        \\n        download_links.append({\\n            'platform': platform_info['name'],\\n            'url': final_url,\\n            'index': platform_info['index'],\\n            'icon': platform_info['icon']\\n        })\\n        \\n        print(f\\\"‚úÖ Added {platform_info['name']} (index {platform_info['index']})\\\")\\n    \\n    if not download_links:\\n        print(\\\"‚ùå At least one download link is required!\\\")\\n        return\\n    \\n    # Build book data\\n    book_data = {\\n        'title': title,\\n        'author': author,\\n        'description': description,\\n        'cover_image': cover_image,\\n        'download_links': download_links,\\n        'config_url': config_url\\n    }\\n    \\n    # Add optional fields\\n    if preview_image:\\n        book_data['preview_image'] = preview_image\\n    if isbn:\\n        book_data['isbn'] = isbn\\n    if published_date:\\n        book_data['published_date'] = published_date\\n    if language:\\n        book_data['language'] = language\\n    if publisher:\\n        book_data['publisher'] = publisher\\n    if genres:\\n        book_data['genre'] = genres\\n    if rating:\\n        book_data['rating'] = rating\\n    if pages:\\n        book_data['pages'] = pages\\n    \\n    # Generate markdown\\n    print(f\\\"\\\\nüìù Generating markdown file...\\\")\\n    markdown_content = markdown_generator.generate_markdown(book_data)\\n    filename = markdown_generator.generate_filename(title)\\n    \\n    print(f\\\"üìÑ Generated file: {filename}\\\")\\n    print(f\\\"üìè Content length: {len(markdown_content)} characters\\\")\\n    \\n    # Preview\\n    print(f\\\"\\\\nüìã Preview (first 300 chars):\\\")\\n    print(\\\"-\\\" * 40)\\n    print(markdown_content[:300] + \\\"...\\\")\\n    print(\\\"-\\\" * 40)\\n    \\n    # Confirm upload\\n    upload_confirm = input(f\\\"\\\\nüì§ Upload '{filename}' to GitHub? (y/N): \\\").strip().lower()\\n    \\n    if upload_confirm == 'y':\\n        file_path = f\\\"_epubs/{filename}\\\"\\n        commit_message = f\\\"Th√™m s√°ch: {title} - {author}\\\"\\n        \\n        try:\\n            if github_manager.file_exists(file_path):\\n                success = github_manager.update_file(file_path, markdown_content, commit_message)\\n                action = \\\"Updated\\\"\\n            else:\\n                success = github_manager.create_file(file_path, markdown_content, commit_message)\\n                action = \\\"Created\\\"\\n            \\n            if success:\\n                print(f\\\"‚úÖ {action} file successfully!\\\")\\n                print(f\\\"üìÇ File: {file_path}\\\")\\n                print(f\\\"üí¨ Commit: {commit_message}\\\")\\n                print(f\\\"üöÄ GitHub Pages s·∫Ω rebuild automatically\\\")\\n                \\n                # Summary\\n                print(f\\\"\\\\nüìä Summary:\\\")\\n                print(f\\\"   üìñ Title: {title}\\\")\\n                print(f\\\"   ‚úçÔ∏è Author: {author}\\\")\\n                print(f\\\"   üîó Download links: {len(download_links)}\\\")\\n                for link in download_links:\\n                    print(f\\\"      [{link['index']}] {link['platform']}\\\")\\n            else:\\n                print(f\\\"‚ùå Failed to {action.lower()} file!\\\")\\n                \\n        except Exception as e:\\n            print(f\\\"‚ùå Error uploading file: {e}\\\")\\n    else:\\n        print(\\\"‚ùå File not uploaded\\\")\\n        print(f\\\"üíæ Markdown content saved locally for reference\\\")\\n\\n# Run Mode 1\\nmode1_manual_book_addition()\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üîê Secure Platform Authentication Manager\n",
        "# @markdown Qu·∫£n l√Ω authentication cho c√°c platform m·ªôt c√°ch b·∫£o m·∫≠t\n",
        "\n",
        "class SecurePlatformAuthManager:\n",
        "    \"\"\"Qu·∫£n l√Ω authentication cho platforms v·ªõi userdata\"\"\"\n",
        "    \n",
        "    def __init__(self, credential_manager):\n",
        "        self.credential_manager = credential_manager\n",
        "        self.platform_auth = {}\n",
        "    \n",
        "    def get_platform_auth(self, platform_id, platform_name, auth_type=\"cookie\"):\n",
        "        \"\"\"Get authentication cho platform t·ª´ userdata ho·∫∑c input\"\"\"\n",
        "        auth_key = f\"{platform_id}_{auth_type}\".upper()\n",
        "        \n",
        "        try:\n",
        "            # Ki·ªÉm tra userdata tr∆∞·ªõc\n",
        "            auth_value = userdata.get(auth_key)\n",
        "            if auth_value:\n",
        "                print(f\"üîç ƒê√£ t√¨m th·∫•y {auth_type} cho {platform_name} trong userdata\")\n",
        "                return auth_value\n",
        "        except:\n",
        "            print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y {auth_type} cho {platform_name} trong userdata\")\n",
        "        \n",
        "        # Y√™u c·∫ßu user nh·∫≠p\n",
        "        if auth_type == \"cookie\":\n",
        "            prompt = f\"üç™ Nh·∫≠p cookie cho {platform_name}\"\n",
        "        elif auth_type == \"token\":\n",
        "            prompt = f\"üîë Nh·∫≠p access token cho {platform_name}\"\n",
        "        else:\n",
        "            prompt = f\"üîê Nh·∫≠p {auth_type} cho {platform_name}\"\n",
        "        \n",
        "        auth_value = input(f\"{prompt}: \").strip()\n",
        "        \n",
        "        if auth_value:\n",
        "            print(f\"üìù L∆∞u v√†o userdata: userdata.set('{auth_key}', 'your_{auth_type}')\")\n",
        "            self.platform_auth[platform_id] = {\n",
        "                'type': auth_type,\n",
        "                'value': auth_value\n",
        "            }\n",
        "            return auth_value\n",
        "        else:\n",
        "            print(f\"‚ùå {auth_type} cho {platform_name} kh√¥ng ƒë∆∞·ª£c cung c·∫•p\")\n",
        "            return None\n",
        "    \n",
        "    def get_fresh_curl_with_auth(self, platform_id, platform_name, base_curl_template):\n",
        "        \"\"\"Get fresh cURL v·ªõi authentication m·ªõi\"\"\"\n",
        "        print(f\"\\nüîß C·∫ßn fresh authentication cho {platform_name}\")\n",
        "        print(\"‚ö†Ô∏è Platform authentication c√≥ th·ªÉ ƒë√£ h·∫øt h·∫°n\")\n",
        "        print(\"üìù Vui l√≤ng cung c·∫•p cURL command m·ªõi v·ªõi valid authentication\")\n",
        "        print(\"üîó Placeholder ${link_drive} s·∫Ω ƒë∆∞·ª£c thay th·∫ø t·ª± ƒë·ªông\")\n",
        "        print(\"\\nV√≠ d·ª•:\")\n",
        "        print(f\"curl -X POST 'https://{platform_id}.com/api' \\\\\")\n",
        "        print(\"  -H 'Authorization: Bearer your_fresh_token' \\\\\")\n",
        "        print(\"  -d '{\\\"url\\\": \\\"${link_drive}\\\"}'\")\n",
        "        \n",
        "        fresh_curl = input(f\"\\nüîÑ Fresh cURL cho {platform_name}: \").strip()\n",
        "        \n",
        "        if fresh_curl:\n",
        "            print(f\"‚úÖ Fresh cURL received cho {platform_name}\")\n",
        "            \n",
        "            # Extract v√† l∆∞u authentication info n·∫øu c√≥ th·ªÉ\n",
        "            if 'Authorization: Bearer' in fresh_curl:\n",
        "                auth_match = re.search(r'Authorization: Bearer ([^\\'\\\"\\\\s]+)', fresh_curl)\n",
        "                if auth_match:\n",
        "                    token = auth_match.group(1)\n",
        "                    auth_key = f\"{platform_id}_TOKEN\".upper()\n",
        "                    print(f\"üîë Extracted token - c√≥ th·ªÉ l∆∞u: userdata.set('{auth_key}', '{token[:10]}...')\")\n",
        "            \n",
        "            elif 'Cookie:' in fresh_curl:\n",
        "                cookie_match = re.search(r'Cookie: ([^\\'\\\"\\\\n]+)', fresh_curl)\n",
        "                if cookie_match:\n",
        "                    cookie = cookie_match.group(1)\n",
        "                    auth_key = f\"{platform_id}_COOKIE\".upper()\n",
        "                    print(f\"üç™ Extracted cookie - c√≥ th·ªÉ l∆∞u: userdata.set('{auth_key}', 'your_cookie')\")\n",
        "            \n",
        "            return fresh_curl\n",
        "        else:\n",
        "            print(f\"‚ùå Kh√¥ng c√≥ fresh cURL cho {platform_name}\")\n",
        "            return None\n",
        "    \n",
        "    def build_authenticated_curl(self, platform_id, platform_name, base_template):\n",
        "        \"\"\"Build cURL v·ªõi authentication t·ª´ userdata ho·∫∑c fresh input\"\"\"\n",
        "        \n",
        "        # Try to get stored auth first\n",
        "        stored_auth = None\n",
        "        for auth_type in ['TOKEN', 'COOKIE', 'API_KEY']:\n",
        "            auth_key = f\"{platform_id}_{auth_type}\".upper()\n",
        "            try:\n",
        "                stored_value = userdata.get(auth_key)\n",
        "                if stored_value:\n",
        "                    stored_auth = {'type': auth_type, 'value': stored_value}\n",
        "                    print(f\"üîç Found stored {auth_type} cho {platform_name}\")\n",
        "                    break\n",
        "            except:\n",
        "                continue\n",
        "        \n",
        "        if stored_auth:\n",
        "            # Try to use stored auth\n",
        "            use_stored = input(f\"üîÑ S·ª≠ d·ª•ng stored {stored_auth['type']} cho {platform_name}? (y/N): \").strip().lower()\n",
        "            \n",
        "            if use_stored == 'y':\n",
        "                # Build cURL v·ªõi stored auth\n",
        "                auth_curl = self._inject_auth_into_curl(base_template, stored_auth)\n",
        "                if auth_curl:\n",
        "                    return auth_curl\n",
        "        \n",
        "        # Get fresh cURL if no stored auth ho·∫∑c user kh√¥ng mu·ªën d√πng\n",
        "        return self.get_fresh_curl_with_auth(platform_id, platform_name, base_template)\n",
        "    \n",
        "    def _inject_auth_into_curl(self, base_template, auth_info):\n",
        "        \"\"\"Inject authentication v√†o base cURL template\"\"\"\n",
        "        try:\n",
        "            if auth_info['type'] == 'TOKEN':\n",
        "                if 'Authorization:' not in base_template:\n",
        "                    # Add authorization header\n",
        "                    if '-H' in base_template:\n",
        "                        base_template = base_template.replace(\n",
        "                            '-H', \n",
        "                            f'-H \"Authorization: Bearer {auth_info[\"value\"]}\" -H', \n",
        "                            1\n",
        "                        )\n",
        "                    else:\n",
        "                        base_template = base_template.replace(\n",
        "                            'curl ', \n",
        "                            f'curl -H \"Authorization: Bearer {auth_info[\"value\"]}\" '\n",
        "                        )\n",
        "                else:\n",
        "                    # Replace existing authorization\n",
        "                    base_template = re.sub(\n",
        "                        r'Authorization: Bearer [^\\s\\'\"]+',\n",
        "                        f'Authorization: Bearer {auth_info[\"value\"]}',\n",
        "                        base_template\n",
        "                    )\n",
        "            \n",
        "            elif auth_info['type'] == 'COOKIE':\n",
        "                if 'Cookie:' not in base_template:\n",
        "                    # Add cookie header\n",
        "                    if '-H' in base_template:\n",
        "                        base_template = base_template.replace(\n",
        "                            '-H', \n",
        "                            f'-H \"Cookie: {auth_info[\"value\"]}\" -H', \n",
        "                            1\n",
        "                        )\n",
        "                    else:\n",
        "                        base_template = base_template.replace(\n",
        "                            'curl ', \n",
        "                            f'curl -H \"Cookie: {auth_info[\"value\"]}\" '\n",
        "                        )\n",
        "                else:\n",
        "                    # Replace existing cookie\n",
        "                    base_template = re.sub(\n",
        "                        r'Cookie: [^\\n\\'\"]+',\n",
        "                        f'Cookie: {auth_info[\"value\"]}',\n",
        "                        base_template\n",
        "                    )\n",
        "            \n",
        "            print(f\"‚úÖ Injected {auth_info['type']} v√†o cURL template\")\n",
        "            return base_template\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error injecting auth: {e}\")\n",
        "            return None\n",
        "\n",
        "# Initialize secure platform auth manager\n",
        "platform_auth_manager = SecurePlatformAuthManager(credential_manager)\n",
        "print(\"üîê Secure Platform Authentication Manager initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üîê Secure Credentials Usage Guide\n",
        "\n",
        "C√°ch s·ª≠ d·ª•ng Google Colab userdata ƒë·ªÉ l∆∞u credentials an to√†n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üí° Secure Credentials Setup Guide\n",
        "# @markdown H∆∞·ªõng d·∫´n setup credentials an to√†n\n",
        "\n",
        "def show_credentials_setup_guide():\n",
        "    \"\"\"Display guide cho vi·ªác setup secure credentials\"\"\"\n",
        "    print(\"üîê SECURE CREDENTIALS SETUP GUIDE\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    print(\"\\nüìã REQUIRED CREDENTIALS:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"üîë GitHub Token:\")\n",
        "    print(\"   userdata.set('GITHUB_TOKEN', 'ghp_your_token_here')\")\n",
        "    print(\"   üëÜ Get from: https://github.com/settings/tokens\")\n",
        "    \n",
        "    print(\"\\nüìÇ GitHub Repository:\")\n",
        "    print(\"   userdata.set('GITHUB_REPO', 'username/repository')\")\n",
        "    print(\"   üëÜ Format: username/repo-name\")\n",
        "    \n",
        "    print(\"\\nüåø Git Branch (optional):\")\n",
        "    print(\"   userdata.set('BRANCH_NAME', 'main')\")\n",
        "    print(\"   üëÜ Default: 'main'\")\n",
        "    \n",
        "    print(\"\\nüìã OPTIONAL CREDENTIALS:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"‚òÅÔ∏è Cloudinary (for image processing):\")\n",
        "    print(\"   userdata.set('CLOUDINARY_CLOUD_NAME', 'your_cloud')\")\n",
        "    print(\"   userdata.set('CLOUDINARY_API_KEY', 'your_key')\")\n",
        "    print(\"   userdata.set('CLOUDINARY_API_SECRET', 'your_secret')\")\n",
        "    \n",
        "    print(\"\\nüîó Default Config API:\")\n",
        "    print(\"   userdata.set('DEFAULT_CONFIG_API', 'https://your-api.com')\")\n",
        "    \n",
        "    print(\"\\nüìã PLATFORM AUTHENTICATION:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"üç™ Platform Cookies/Tokens (v√≠ d·ª• cho YeuMoney):\")\n",
        "    print(\"   userdata.set('YEUMONEY_TOKEN', 'your_token')\")\n",
        "    print(\"   userdata.set('YEUMONEY_COOKIE', 'session=abc123;auth=xyz')\")\n",
        "    print(\"   userdata.set('SITE2S_TOKEN', 'your_token')\")\n",
        "    \n",
        "    print(\"\\nüí° USAGE TIPS:\")\n",
        "    print(\"-\" * 20)\n",
        "    print(\"‚úÖ Credentials ƒë∆∞·ª£c l∆∞u permanent trong session\")\n",
        "    print(\"‚úÖ Kh√¥ng c·∫ßn nh·∫≠p l·∫°i khi restart notebook\")\n",
        "    print(\"‚úÖ An to√†n h∆°n so v·ªõi hardcode trong code\")\n",
        "    print(\"‚úÖ Automatically detect v√† s·ª≠ d·ª•ng stored values\")\n",
        "    \n",
        "    print(\"\\nüõ°Ô∏è SECURITY BEST PRACTICES:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"üîí Ch·ªâ l∆∞u credentials trong userdata khi c·∫ßn\")\n",
        "    print(\"üîí Kh√¥ng share notebook v·ªõi credentials\")\n",
        "    print(\"üîí Use minimal scope tokens cho GitHub\")\n",
        "    print(\"üîí Revoke tokens khi kh√¥ng s·ª≠ d·ª•ng\")\n",
        "    \n",
        "    print(\"\\nüìã QUICK SETUP COMMANDS:\")\n",
        "    print(\"-\" * 25)\n",
        "    print(\"# Copy v√† run nh·ªØng d√≤ng sau ƒë·ªÉ setup nhanh:\")\n",
        "    print(\"from google.colab import userdata\")\n",
        "    print(\"userdata.set('GITHUB_TOKEN', 'your_token')\")\n",
        "    print(\"userdata.set('GITHUB_REPO', 'username/repo')\")\n",
        "    print(\"# Sau ƒë√≥ restart notebook ƒë·ªÉ load credentials\")\n",
        "\n",
        "# Run setup guide\n",
        "show_credentials_setup_guide()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üìö Google Drive & Epub Processing Support\n",
        "# @markdown Support libraries cho Mode 2 & 3\n",
        "\n",
        "# Additional imports for epub processing\n",
        "try:\n",
        "    import ebooklib\n",
        "    from ebooklib import epub\n",
        "    print(\"‚úÖ ebooklib imported successfully\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Installing ebooklib...\")\n",
        "    !pip install ebooklib -q\n",
        "    import ebooklib\n",
        "    from ebooklib import epub\n",
        "    print(\"‚úÖ ebooklib installed and imported\")\n",
        "\n",
        "# Additional imports for image processing\n",
        "try:\n",
        "    from PIL import Image\n",
        "    import cloudinary\n",
        "    import cloudinary.uploader\n",
        "    import cloudinary.api\n",
        "    print(\"‚úÖ Image processing libraries available\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Installing image processing libraries...\")\n",
        "    !pip install Pillow cloudinary -q\n",
        "    from PIL import Image\n",
        "    import cloudinary\n",
        "    import cloudinary.uploader\n",
        "    import cloudinary.api\n",
        "    print(\"‚úÖ Image processing libraries installed\")\n",
        "\n",
        "# Google Drive processing\n",
        "import io\n",
        "from urllib.parse import parse_qs, urlparse\n",
        "\n",
        "class GoogleDriveProcessor:\n",
        "    \"\"\"Process Google Drive links v√† files\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.drive_mounted = False\n",
        "        \n",
        "    def mount_drive(self):\n",
        "        \"\"\"Mount Google Drive if not already mounted\"\"\"\n",
        "        if not self.drive_mounted:\n",
        "            try:\n",
        "                drive.mount('/content/drive')\n",
        "                self.drive_mounted = True\n",
        "                print(\"‚úÖ Google Drive mounted successfully\")\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed to mount Google Drive: {e}\")\n",
        "                return False\n",
        "        return True\n",
        "    \n",
        "    def extract_file_id_from_url(self, drive_url):\n",
        "        \"\"\"Extract file ID t·ª´ Google Drive URL\"\"\"\n",
        "        try:\n",
        "            if '/file/d/' in drive_url:\n",
        "                # Standard sharing link\n",
        "                file_id = drive_url.split('/file/d/')[1].split('/')[0]\n",
        "                return file_id\n",
        "            elif 'id=' in drive_url:\n",
        "                # Query parameter format\n",
        "                parsed = urlparse(drive_url)\n",
        "                query_params = parse_qs(parsed.query)\n",
        "                return query_params.get('id', [None])[0]\n",
        "            else:\n",
        "                print(f\"‚ùå Unsupported Google Drive URL format: {drive_url}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error extracting file ID: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def get_direct_download_url(self, file_id):\n",
        "        \"\"\"Convert file ID to direct download URL\"\"\"\n",
        "        return f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "    \n",
        "    def download_file_from_drive(self, drive_url, local_path):\n",
        "        \"\"\"Download file from Google Drive URL\"\"\"\n",
        "        try:\n",
        "            file_id = self.extract_file_id_from_url(drive_url)\n",
        "            if not file_id:\n",
        "                return False\n",
        "            \n",
        "            download_url = self.get_direct_download_url(file_id)\n",
        "            \n",
        "            # Download file\n",
        "            response = requests.get(download_url)\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                with open(local_path, 'wb') as f:\n",
        "                    f.write(response.content)\n",
        "                print(f\"‚úÖ Downloaded: {local_path}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"‚ùå Download failed: HTTP {response.status_code}\")\n",
        "                return False\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error downloading file: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def create_public_sharing_link(self, file_path):\n",
        "        \"\"\"Create public sharing link for file in user's Drive\"\"\"\n",
        "        try:\n",
        "            if not self.mount_drive():\n",
        "                return None\n",
        "            \n",
        "            # This would require Google Drive API setup\n",
        "            # For now, we'll assume user provides the public link\n",
        "            print(\"‚ö†Ô∏è Please create public sharing link manually and provide it\")\n",
        "            public_link = input(\"üìÇ Public sharing link: \").strip()\n",
        "            return public_link if public_link else None\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error creating public link: {e}\")\n",
        "            return None\n",
        "\n",
        "class EpubProcessor:\n",
        "    \"\"\"Process EPUB files v√† extract metadata\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.temp_dir = \"/tmp/epub_processing\"\n",
        "        os.makedirs(self.temp_dir, exist_ok=True)\n",
        "    \n",
        "    def extract_metadata(self, epub_path):\n",
        "        \"\"\"Extract metadata t·ª´ EPUB file\"\"\"\n",
        "        try:\n",
        "            book = epub.read_epub(epub_path)\n",
        "            \n",
        "            metadata = {\n",
        "                'title': '',\n",
        "                'author': '',\n",
        "                'description': '',\n",
        "                'language': 'Ti·∫øng Vi·ªát',\n",
        "                'publisher': '',\n",
        "                'published_date': '',\n",
        "                'isbn': '',\n",
        "                'pages': 0,\n",
        "                'preview_content': ''\n",
        "            }\n",
        "            \n",
        "            # Extract basic metadata\n",
        "            title = book.get_metadata('DC', 'title')\n",
        "            if title:\n",
        "                metadata['title'] = title[0][0] if title else 'Unknown Title'\n",
        "            \n",
        "            creator = book.get_metadata('DC', 'creator')\n",
        "            if creator:\n",
        "                metadata['author'] = creator[0][0] if creator else 'Unknown Author'\n",
        "            \n",
        "            description = book.get_metadata('DC', 'description')\n",
        "            if description:\n",
        "                metadata['description'] = description[0][0] if description else ''\n",
        "            \n",
        "            language = book.get_metadata('DC', 'language')\n",
        "            if language:\n",
        "                metadata['language'] = language[0][0] if language else 'Ti·∫øng Vi·ªát'\n",
        "            \n",
        "            publisher = book.get_metadata('DC', 'publisher')\n",
        "            if publisher:\n",
        "                metadata['publisher'] = publisher[0][0] if publisher else ''\n",
        "            \n",
        "            date = book.get_metadata('DC', 'date')\n",
        "            if date:\n",
        "                metadata['published_date'] = date[0][0] if date else ''\n",
        "            \n",
        "            identifier = book.get_metadata('DC', 'identifier')\n",
        "            if identifier:\n",
        "                for ident in identifier:\n",
        "                    if 'isbn' in ident[1].get('scheme', '').lower():\n",
        "                        metadata['isbn'] = ident[0]\n",
        "                        break\n",
        "            \n",
        "            print(f\"‚úÖ Extracted metadata for: {metadata['title']}\")\n",
        "            return metadata\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error extracting metadata: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def extract_cover_image(self, epub_path):\n",
        "        \"\"\"Extract cover image t·ª´ EPUB\"\"\"\n",
        "        try:\n",
        "            book = epub.read_epub(epub_path)\n",
        "            \n",
        "            # Try to find cover image\n",
        "            cover_image = None\n",
        "            \n",
        "            # Method 1: Look for cover in metadata\n",
        "            cover_meta = book.get_metadata('OPF', 'cover')\n",
        "            if cover_meta:\n",
        "                cover_id = cover_meta[0][0]\n",
        "                for item in book.get_items():\n",
        "                    if item.get_id() == cover_id:\n",
        "                        cover_image = item.get_content()\n",
        "                        break\n",
        "            \n",
        "            # Method 2: Look for common cover file names\n",
        "            if not cover_image:\n",
        "                cover_names = ['cover.jpg', 'cover.jpeg', 'cover.png', 'cover.gif']\n",
        "                for item in book.get_items():\n",
        "                    if item.get_type() == ebooklib.ITEM_IMAGE:\n",
        "                        filename = item.get_name().lower()\n",
        "                        if any(name in filename for name in cover_names):\n",
        "                            cover_image = item.get_content()\n",
        "                            break\n",
        "            \n",
        "            # Method 3: Take first image\n",
        "            if not cover_image:\n",
        "                for item in book.get_items():\n",
        "                    if item.get_type() == ebooklib.ITEM_IMAGE:\n",
        "                        cover_image = item.get_content()\n",
        "                        break\n",
        "            \n",
        "            if cover_image:\n",
        "                cover_path = os.path.join(self.temp_dir, \"cover.jpg\")\n",
        "                with open(cover_path, 'wb') as f:\n",
        "                    f.write(cover_image)\n",
        "                print(f\"‚úÖ Extracted cover image: {cover_path}\")\n",
        "                return cover_path\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è No cover image found in EPUB\")\n",
        "                return None\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error extracting cover: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def extract_preview_content(self, epub_path, max_chars=500):\n",
        "        \"\"\"Extract preview text t·ª´ EPUB\"\"\"\n",
        "        try:\n",
        "            book = epub.read_epub(epub_path)\n",
        "            \n",
        "            preview_text = \"\"\n",
        "            \n",
        "            # Get readable items (chapters)\n",
        "            for item in book.get_items():\n",
        "                if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
        "                    content = item.get_content().decode('utf-8')\n",
        "                    \n",
        "                    # Simple HTML tag removal\n",
        "                    import re\n",
        "                    text = re.sub(r'<[^>]+>', '', content)\n",
        "                    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "                    \n",
        "                    if text and len(text) > 50:  # Skip short/empty chapters\n",
        "                        preview_text = text[:max_chars]\n",
        "                        break\n",
        "            \n",
        "            if preview_text:\n",
        "                print(f\"‚úÖ Extracted preview ({len(preview_text)} chars)\")\n",
        "                return preview_text\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è No readable content found for preview\")\n",
        "                return \"\"\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error extracting preview: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "# Initialize processors\n",
        "drive_processor = GoogleDriveProcessor()\n",
        "epub_processor = EpubProcessor()\n",
        "\n",
        "print(\"üìö Google Drive & Epub Processing initialized!\")\n",
        "print(\"üîß Ready for Mode 2 & 3 operations\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ‚òÅÔ∏è Cloudinary Image Manager\n",
        "# @markdown Process v√† upload images to Cloudinary v·ªõi optimal settings\n",
        "\n",
        "class CloudinaryImageManager:\n",
        "    \"\"\"Manage image processing v√† upload v·ªõi Cloudinary\"\"\"\n",
        "    \n",
        "    def __init__(self, credential_manager):\n",
        "        self.credential_manager = credential_manager\n",
        "        self.configured = False\n",
        "        self.setup_cloudinary()\n",
        "    \n",
        "    def setup_cloudinary(self):\n",
        "        \"\"\"Setup Cloudinary configuration\"\"\"\n",
        "        try:\n",
        "            cloud_name = self.credential_manager.get('cloudinary_cloud_name')\n",
        "            api_key = self.credential_manager.get('cloudinary_api_key')\n",
        "            api_secret = self.credential_manager.get('cloudinary_api_secret')\n",
        "            \n",
        "            if cloud_name and api_key and api_secret:\n",
        "                cloudinary.config(\n",
        "                    cloud_name=cloud_name,\n",
        "                    api_key=api_key,\n",
        "                    api_secret=api_secret\n",
        "                )\n",
        "                self.configured = True\n",
        "                print(f\"‚úÖ Cloudinary configured: {cloud_name}\")\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Cloudinary not configured - image processing disabled\")\n",
        "                self.configured = False\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Cloudinary setup failed: {e}\")\n",
        "            self.configured = False\n",
        "    \n",
        "    def optimize_image(self, image_path, target_width, target_height, quality=80):\n",
        "        \"\"\"Optimize image dimensions v√† quality\"\"\"\n",
        "        try:\n",
        "            with Image.open(image_path) as img:\n",
        "                # Convert to RGB if needed\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "                \n",
        "                # Calculate resize dimensions maintaining aspect ratio\n",
        "                img_ratio = img.width / img.height\n",
        "                target_ratio = target_width / target_height\n",
        "                \n",
        "                if img_ratio > target_ratio:\n",
        "                    # Image is wider, fit by height\n",
        "                    new_height = target_height\n",
        "                    new_width = int(target_height * img_ratio)\n",
        "                else:\n",
        "                    # Image is taller, fit by width\n",
        "                    new_width = target_width\n",
        "                    new_height = int(target_width / img_ratio)\n",
        "                \n",
        "                # Resize image\n",
        "                resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "                \n",
        "                # Save optimized version\n",
        "                optimized_path = image_path.replace('.jpg', '_optimized.jpg')\n",
        "                resized_img.save(optimized_path, 'JPEG', quality=quality, optimize=True)\n",
        "                \n",
        "                print(f\"‚úÖ Optimized: {img.width}x{img.height} ‚Üí {new_width}x{new_height}\")\n",
        "                return optimized_path\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Image optimization failed: {e}\")\n",
        "            return image_path\n",
        "    \n",
        "    def upload_cover_image(self, image_path):\n",
        "        \"\"\"Upload cover image v·ªõi optimal settings cho epub cards\"\"\"\n",
        "        if not self.configured:\n",
        "            print(\"‚ö†Ô∏è Cloudinary not configured, returning local path\")\n",
        "            return image_path\n",
        "        \n",
        "        try:\n",
        "            # Optimize for cover display (400x600px, WebP 80% quality)\n",
        "            optimized_path = self.optimize_image(image_path, 400, 600, 80)\n",
        "            \n",
        "            # Upload to Cloudinary\n",
        "            upload_result = cloudinary.uploader.upload(\n",
        "                optimized_path,\n",
        "                folder=\"epub_covers\",\n",
        "                format=\"webp\",\n",
        "                quality=\"auto:good\",\n",
        "                fetch_format=\"auto\",\n",
        "                responsive=True,\n",
        "                width=400,\n",
        "                height=600,\n",
        "                crop=\"fit\"\n",
        "            )\n",
        "            \n",
        "            cloudinary_url = upload_result['secure_url']\n",
        "            print(f\"‚úÖ Cover uploaded: {cloudinary_url}\")\n",
        "            \n",
        "            # Cleanup local files\n",
        "            if os.path.exists(optimized_path):\n",
        "                os.remove(optimized_path)\n",
        "            \n",
        "            return cloudinary_url\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Cover upload failed: {e}\")\n",
        "            return image_path\n",
        "    \n",
        "    def upload_preview_image(self, image_path):\n",
        "        \"\"\"Upload preview image v·ªõi larger dimensions\"\"\"\n",
        "        if not self.configured:\n",
        "            print(\"‚ö†Ô∏è Cloudinary not configured, returning local path\")\n",
        "            return image_path\n",
        "        \n",
        "        try:\n",
        "            # Optimize for preview display (800x1200px, WebP 80% quality)\n",
        "            optimized_path = self.optimize_image(image_path, 800, 1200, 80)\n",
        "            \n",
        "            # Upload to Cloudinary\n",
        "            upload_result = cloudinary.uploader.upload(\n",
        "                optimized_path,\n",
        "                folder=\"epub_previews\",\n",
        "                format=\"webp\",\n",
        "                quality=\"auto:good\",\n",
        "                fetch_format=\"auto\",\n",
        "                responsive=True,\n",
        "                width=800,\n",
        "                height=1200,\n",
        "                crop=\"fit\"\n",
        "            )\n",
        "            \n",
        "            cloudinary_url = upload_result['secure_url']\n",
        "            print(f\"‚úÖ Preview uploaded: {cloudinary_url}\")\n",
        "            \n",
        "            # Cleanup local files\n",
        "            if os.path.exists(optimized_path):\n",
        "                os.remove(optimized_path)\n",
        "            \n",
        "            return cloudinary_url\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Preview upload failed: {e}\")\n",
        "            return image_path\n",
        "    \n",
        "    def process_epub_images(self, cover_path, preview_path=None):\n",
        "        \"\"\"Process both cover v√† preview images\"\"\"\n",
        "        results = {}\n",
        "        \n",
        "        if cover_path and os.path.exists(cover_path):\n",
        "            results['cover_url'] = self.upload_cover_image(cover_path)\n",
        "        else:\n",
        "            results['cover_url'] = \"https://via.placeholder.com/400x600/cccccc/ffffff?text=No+Cover\"\n",
        "        \n",
        "        if preview_path and os.path.exists(preview_path):\n",
        "            results['preview_url'] = self.upload_preview_image(preview_path)\n",
        "        else:\n",
        "            results['preview_url'] = results['cover_url']  # Use cover as preview fallback\n",
        "        \n",
        "        return results\n",
        "\n",
        "# Initialize cloudinary manager\n",
        "if credential_manager:\n",
        "    cloudinary_manager = CloudinaryImageManager(credential_manager)\n",
        "    print(\"‚òÅÔ∏è Cloudinary Image Manager initialized!\")\n",
        "else:\n",
        "    cloudinary_manager = None\n",
        "    print(\"‚ö†Ô∏è Cloudinary Image Manager not initialized - missing credential manager\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üìÇ Mode 2: Google Drive Epub Extraction\n",
        "\n",
        "Extract th√¥ng tin t·ª´ single Google Drive EPUB file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üìÇ Mode 2: Google Drive Epub Extraction\n",
        "# @markdown Extract metadata t·ª´ single Google Drive EPUB link\n",
        "\n",
        "def mode2_gdrive_epub_extraction():\n",
        "    \"\"\"Mode 2: Extract book t·ª´ Google Drive EPUB link\"\"\"\n",
        "    \n",
        "    if not github_manager or not platform_config_manager:\n",
        "        print(\"‚ùå Required managers not available!\")\n",
        "        print(\"üîß Please configure GitHub credentials first\")\n",
        "        return\n",
        "    \n",
        "    print(\"üìÇ Mode 2: Google Drive Epub Extraction\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Get Google Drive link\n",
        "    print(\"üìã Google Drive Information:\")\n",
        "    drive_url = input(\"üîó Google Drive EPUB URL: \").strip()\n",
        "    if not drive_url:\n",
        "        print(\"‚ùå Google Drive URL is required!\")\n",
        "        return\n",
        "    \n",
        "    # Validate Google Drive URL\n",
        "    if 'drive.google.com' not in drive_url:\n",
        "        print(\"‚ùå Invalid Google Drive URL!\")\n",
        "        return\n",
        "    \n",
        "    file_id = drive_processor.extract_file_id_from_url(drive_url)\n",
        "    if not file_id:\n",
        "        print(\"‚ùå Could not extract file ID from URL!\")\n",
        "        return\n",
        "    \n",
        "    print(f\"‚úÖ Extracted file ID: {file_id}\")\n",
        "    \n",
        "    # Download EPUB file\n",
        "    temp_epub_path = f\"/tmp/epub_{file_id}.epub\"\n",
        "    print(f\"\\nüì• Downloading EPUB file...\")\n",
        "    \n",
        "    if not drive_processor.download_file_from_drive(drive_url, temp_epub_path):\n",
        "        print(\"‚ùå Failed to download EPUB file!\")\n",
        "        return\n",
        "    \n",
        "    # Extract metadata\n",
        "    print(f\"\\nüìñ Extracting metadata...\")\n",
        "    metadata = epub_processor.extract_metadata(temp_epub_path)\n",
        "    if not metadata:\n",
        "        print(\"‚ùå Failed to extract metadata!\")\n",
        "        return\n",
        "    \n",
        "    # Check for duplicates\n",
        "    print(f\"\\nüîç Checking for duplicates...\")\n",
        "    is_duplicate, existing_file = github_manager.check_duplicate_book(\n",
        "        metadata['title'], metadata['author']\n",
        "    )\n",
        "    \n",
        "    if is_duplicate:\n",
        "        print(f\"‚ö†Ô∏è Book already exists: {existing_file}\")\n",
        "        overwrite = input(\"üìù Continue anyway? (y/N): \").strip().lower()\n",
        "        if overwrite != 'y':\n",
        "            print(\"‚ùå Operation cancelled\")\n",
        "            # Cleanup\n",
        "            if os.path.exists(temp_epub_path):\n",
        "                os.remove(temp_epub_path)\n",
        "            return\n",
        "    \n",
        "    # Extract images\n",
        "    print(f\"\\nüñºÔ∏è Processing images...\")\n",
        "    cover_path = epub_processor.extract_cover_image(temp_epub_path)\n",
        "    \n",
        "    # Process v·ªõi Cloudinary n·∫øu available\n",
        "    image_urls = {}\n",
        "    if cloudinary_manager and cloudinary_manager.configured:\n",
        "        print(\"‚òÅÔ∏è Uploading images to Cloudinary...\")\n",
        "        image_urls = cloudinary_manager.process_epub_images(cover_path)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Cloudinary not configured, using placeholder images\")\n",
        "        image_urls = {\n",
        "            'cover_url': \"https://via.placeholder.com/400x600/cccccc/ffffff?text=No+Cover\",\n",
        "            'preview_url': \"https://via.placeholder.com/800x1200/cccccc/ffffff?text=No+Preview\"\n",
        "        }\n",
        "    \n",
        "    # Extract preview content\n",
        "    print(f\"\\nüìÑ Extracting preview content...\")\n",
        "    preview_content = epub_processor.extract_preview_content(temp_epub_path)\n",
        "    \n",
        "    # Review extracted information\n",
        "    print(f\"\\nüìã Extracted Information:\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"üìñ Title: {metadata['title']}\")\n",
        "    print(f\"‚úçÔ∏è Author: {metadata['author']}\")\n",
        "    print(f\"üìÑ Description: {metadata['description'][:100]}...\" if metadata['description'] else \"üìÑ Description: (empty)\")\n",
        "    print(f\"üåê Language: {metadata['language']}\")\n",
        "    print(f\"üè¢ Publisher: {metadata['publisher']}\")\n",
        "    print(f\"üìÖ Published: {metadata['published_date']}\")\n",
        "    print(f\"üìä ISBN: {metadata['isbn']}\")\n",
        "    print(f\"üñºÔ∏è Cover: {image_urls['cover_url'][:50]}...\")\n",
        "    print(f\"üìÑ Preview: {len(preview_content)} characters\")\n",
        "    \n",
        "    # Allow editing\n",
        "    print(f\"\\n‚úèÔ∏è Review and Edit Information:\")\n",
        "    edit_confirm = input(\"üìù Edit any information? (y/N): \").strip().lower()\n",
        "    \n",
        "    if edit_confirm == 'y':\n",
        "        print(\"\\nüìù Edit Mode (press Enter to keep current value):\")\n",
        "        \n",
        "        new_title = input(f\"üìñ Title [{metadata['title']}]: \").strip()\n",
        "        if new_title:\n",
        "            metadata['title'] = new_title\n",
        "        \n",
        "        new_author = input(f\"‚úçÔ∏è Author [{metadata['author']}]: \").strip()\n",
        "        if new_author:\n",
        "            metadata['author'] = new_author\n",
        "        \n",
        "        new_description = input(f\"üìÑ Description [{metadata['description'][:50]}...]: \").strip()\n",
        "        if new_description:\n",
        "            metadata['description'] = new_description\n",
        "        \n",
        "        new_language = input(f\"üåê Language [{metadata['language']}]: \").strip()\n",
        "        if new_language:\n",
        "            metadata['language'] = new_language\n",
        "        \n",
        "        # Genre input\n",
        "        genres_input = input(\"üè∑Ô∏è Genres (comma separated): \").strip()\n",
        "        genres = [g.strip() for g in genres_input.split(',')] if genres_input else []\n",
        "        \n",
        "        # Rating and pages\n",
        "        rating_input = input(\"‚≠ê Rating (1-5, optional): \").strip()\n",
        "        rating = float(rating_input) if rating_input and rating_input.replace('.', '').isdigit() else None\n",
        "    else:\n",
        "        genres = []\n",
        "        rating = None\n",
        "    \n",
        "    # Platform shortening setup\n",
        "    print(f\"\\nüîó Platform Shortening Setup:\")\n",
        "    print(\"Available platforms:\")\n",
        "    if platform_config_manager:\n",
        "        platform_config_manager.list_platforms()\n",
        "    \n",
        "    # Use the original Google Drive sharing URL for shortening\n",
        "    download_links = []\n",
        "    shortener_platforms = [p for p in platform_config_manager.platforms.values() if p['type'] == 'shortener']\n",
        "    \n",
        "    if shortener_platforms:\n",
        "        print(f\"\\nüöÄ Auto-shortening v·ªõi all available platforms...\")\n",
        "        \n",
        "        for platform_info in shortener_platforms:\n",
        "            print(f\"\\nüîß Processing {platform_info['name']}...\")\n",
        "            \n",
        "            # Get authenticated cURL (userdata or fresh input)\n",
        "            authenticated_curl = platform_auth_manager.build_authenticated_curl(\n",
        "                platform_info['id'], \n",
        "                platform_info['name'], \n",
        "                platform_info.get('curl_template', '')\n",
        "            )\n",
        "            \n",
        "            if authenticated_curl:\n",
        "                # Update platform v·ªõi authenticated cURL\n",
        "                dynamic_platform_manager.add_platform_from_curl(\n",
        "                    platform_info['name'], \n",
        "                    authenticated_curl, \n",
        "                    platform_info.get('response_config')\n",
        "                )\n",
        "                \n",
        "                # Shorten the original Google Drive URL\n",
        "                shortened_url = dynamic_platform_manager.shorten_url(platform_info['name'], drive_url)\n",
        "                \n",
        "                if shortened_url != drive_url:\n",
        "                    download_links.append({\n",
        "                        'platform': platform_info['name'],\n",
        "                        'url': shortened_url,\n",
        "                        'index': platform_info['index'],\n",
        "                        'icon': platform_info['icon']\n",
        "                    })\n",
        "                    print(f\"‚úÖ {platform_info['name']}: {drive_url[:30]}... ‚Üí {shortened_url}\")\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è {platform_info['name']}: Shortening failed, skipping\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è {platform_info['name']}: No authentication, skipping\")\n",
        "    \n",
        "    # Add direct Google Drive link as fallback\n",
        "    gdrive_platform = platform_config_manager.get_platform_by_index(0)  # Assuming Google Drive is index 0\n",
        "    if gdrive_platform:\n",
        "        download_links.append({\n",
        "            'platform': gdrive_platform['name'],\n",
        "            'url': drive_url,\n",
        "            'index': gdrive_platform['index'],\n",
        "            'icon': gdrive_platform['icon']\n",
        "        })\n",
        "        print(f\"‚úÖ Added direct Google Drive link\")\n",
        "    \n",
        "    if not download_links:\n",
        "        print(\"‚ùå No download links available!\")\n",
        "        return\n",
        "    \n",
        "    # Build book data\n",
        "    book_data = {\n",
        "        'title': metadata['title'],\n",
        "        'author': metadata['author'],\n",
        "        'description': metadata['description'],\n",
        "        'cover_image': image_urls['cover_url'],\n",
        "        'preview_image': image_urls['preview_url'],\n",
        "        'language': metadata['language'],\n",
        "        'download_links': download_links,\n",
        "        'config_url': credential_manager.get('default_config_api') or \"\"\n",
        "    }\n",
        "    \n",
        "    # Add optional fields\n",
        "    if metadata.get('publisher'):\\n        book_data['publisher'] = metadata['publisher']\\n    if metadata.get('published_date'):\\n        book_data['published_date'] = metadata['published_date']\\n    if metadata.get('isbn'):\\n        book_data['isbn'] = metadata['isbn']\\n    if genres:\\n        book_data['genre'] = genres\\n    if rating:\\n        book_data['rating'] = rating\\n    if preview_content:\\n        book_data['preview_content'] = preview_content\\n    \\n    # Generate markdown\\n    print(f\\\"\\\\nüìù Generating markdown file...\\\")\\n    markdown_content = markdown_generator.generate_markdown(book_data)\\n    filename = markdown_generator.generate_filename(metadata['title'])\\n    \\n    print(f\\\"üìÑ Generated file: {filename}\\\")\\n    print(f\\\"üìè Content length: {len(markdown_content)} characters\\\")\\n    print(f\\\"üîó Download links: {len(download_links)}\\\")\\n    \\n    # Preview\\n    print(f\\\"\\\\nüìã Preview (first 300 chars):\\\")\\n    print(\\\"-\\\" * 40)\\n    print(markdown_content[:300] + \\\"...\\\")\\n    print(\\\"-\\\" * 40)\\n    \\n    # Confirm upload\\n    upload_confirm = input(f\\\"\\\\nüì§ Upload '{filename}' to GitHub? (y/N): \\\").strip().lower()\\n    \\n    if upload_confirm == 'y':\\n        file_path = f\\\"_epubs/{filename}\\\"\\n        commit_message = f\\\"Th√™m s√°ch t·ª´ Google Drive: {metadata['title']} - {metadata['author']}\\\"\\n        \\n        try:\\n            if github_manager.file_exists(file_path):\\n                success = github_manager.update_file(file_path, markdown_content, commit_message)\\n                action = \\\"Updated\\\"\\n            else:\\n                success = github_manager.create_file(file_path, markdown_content, commit_message)\\n                action = \\\"Created\\\"\\n            \\n            if success:\\n                print(f\\\"‚úÖ {action} file successfully!\\\")\\n                print(f\\\"üìÇ File: {file_path}\\\")\\n                print(f\\\"üí¨ Commit: {commit_message}\\\")\\n                print(f\\\"üöÄ GitHub Pages s·∫Ω rebuild automatically\\\")\\n                \\n                # Summary\\n                print(f\\\"\\\\nüìä Summary:\\\")\\n                print(f\\\"   üìñ Title: {metadata['title']}\\\")\\n                print(f\\\"   ‚úçÔ∏è Author: {metadata['author']}\\\")\\n                print(f\\\"   üìÇ Source: Google Drive\\\")\\n                print(f\\\"   üîó Download links: {len(download_links)}\\\")\\n                print(f\\\"   üñºÔ∏è Images: Processed\\\")\\n                for link in download_links:\\n                    print(f\\\"      [{link['index']}] {link['platform']}\\\")\\n            else:\\n                print(f\\\"‚ùå Failed to {action.lower()} file!\\\")\\n                \\n        except Exception as e:\\n            print(f\\\"‚ùå Error uploading file: {e}\\\")\\n    else:\\n        print(\\\"‚ùå File not uploaded\\\")\\n        print(f\\\"üíæ Markdown content available for reference\\\")\\n    \\n    # Cleanup temporary files\\n    print(f\\\"\\\\nüßπ Cleaning up temporary files...\\\")\\n    if os.path.exists(temp_epub_path):\\n        os.remove(temp_epub_path)\\n    if cover_path and os.path.exists(cover_path):\\n        os.remove(cover_path)\\n    print(\\\"‚úÖ Cleanup completed\\\")\\n\\n# Run Mode 2\\nmode2_gdrive_epub_extraction()\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üìÅ Mode 3: Bulk Folder Processing\n",
        "\n",
        "X·ª≠ l√Ω bulk t·ª´ th∆∞ m·ª•c Google Drive ch·ª©a nhi·ªÅu EPUB files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üìÅ Mode 3: Bulk Folder Processing\n",
        "# @markdown X·ª≠ l√Ω bulk multiple EPUB files t·ª´ Google Drive folder\n",
        "\n",
        "def mode3_bulk_folder_processing():\n",
        "    \"\"\"Mode 3: Bulk process EPUB files t·ª´ Google Drive folder\"\"\"\n",
        "    \n",
        "    if not github_manager or not platform_config_manager:\n",
        "        print(\"‚ùå Required managers not available!\")\n",
        "        print(\"üîß Please configure GitHub credentials first\")\n",
        "        return\n",
        "    \n",
        "    print(\"üìÅ Mode 3: Bulk Folder Processing\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Mount Google Drive\n",
        "    print(\"üìÇ Mounting Google Drive...\")\n",
        "    if not drive_processor.mount_drive():\n",
        "        print(\"‚ùå Failed to mount Google Drive!\")\n",
        "        return\n",
        "    \n",
        "    # Get folder path\n",
        "    print(\"\\nüìã Folder Information:\")\n",
        "    print(\"üí° Tip: Browse to your EPUB folder trong file browser v√† copy path\")\n",
        "    print(\"üìù Example: /content/drive/MyDrive/Books/EPUBs/\")\n",
        "    \n",
        "    folder_path = input(\"üìÅ Folder path containing EPUB files: \").strip()\n",
        "    if not folder_path:\n",
        "        print(\"‚ùå Folder path is required!\")\n",
        "        return\n",
        "    \n",
        "    # Validate folder exists\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"‚ùå Folder not found: {folder_path}\")\n",
        "        return\n",
        "    \n",
        "    # Find EPUB files\n",
        "    print(f\"\\nüîç Scanning for EPUB files...\")\n",
        "    epub_files = []\n",
        "    \n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.epub'):\n",
        "                epub_path = os.path.join(root, file)\n",
        "                epub_files.append(epub_path)\n",
        "    \n",
        "    if not epub_files:\n",
        "        print(f\"‚ùå No EPUB files found in {folder_path}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"‚úÖ Found {len(epub_files)} EPUB files:\")\n",
        "    for i, epub_path in enumerate(epub_files, 1):\n",
        "        filename = os.path.basename(epub_path)\n",
        "        print(f\"   {i}. {filename}\")\n",
        "    \n",
        "    # Confirm processing\n",
        "    process_confirm = input(f\"\\nüìã Process all {len(epub_files)} EPUB files? (y/N): \").strip().lower()\n",
        "    \n",
        "    if process_confirm != 'y':\n",
        "        print(\"‚ùå Bulk processing cancelled\")\n",
        "        return\n",
        "    \n",
        "    # Setup processing parameters\n",
        "    print(f\"\\n‚öôÔ∏è Processing Configuration:\")\n",
        "    \n",
        "    # Batch size\n",
        "    batch_size_input = input(\"üì¶ Batch size (default: 5): \").strip()\n",
        "    batch_size = int(batch_size_input) if batch_size_input.isdigit() else 5\n",
        "    \n",
        "    # Skip duplicates option\n",
        "    skip_duplicates = input(\"üîÑ Skip duplicate books? (Y/n): \").strip().lower()\n",
        "    skip_duplicates = skip_duplicates != 'n'\n",
        "    \n",
        "    # Get shortener platforms for bulk processing\n",
        "    shortener_platforms = [p for p in platform_config_manager.platforms.values() if p['type'] == 'shortener']\n",
        "    \n",
        "    if shortener_platforms:\n",
        "        print(f\"\\nüîó Available shortener platforms: {len(shortener_platforms)}\")\n",
        "        for platform in shortener_platforms:\n",
        "            print(f\"   ‚Ä¢ {platform['name']} (index {platform['index']})\")\n",
        "        \n",
        "        # Get fresh authentication for all platforms upfront\n",
        "        platform_auths = {}\n",
        "        for platform_info in shortener_platforms:\n",
        "            print(f\"\\nüîê Setting up authentication for {platform_info['name']}...\")\n",
        "            \n",
        "            authenticated_curl = platform_auth_manager.build_authenticated_curl(\n",
        "                platform_info['id'], \n",
        "                platform_info['name'], \n",
        "                platform_info.get('curl_template', '')\n",
        "            )\n",
        "            \n",
        "            if authenticated_curl:\n",
        "                # Setup platform for bulk processing\n",
        "                dynamic_platform_manager.add_platform_from_curl(\n",
        "                    platform_info['name'], \n",
        "                    authenticated_curl, \n",
        "                    platform_info.get('response_config')\n",
        "                )\n",
        "                platform_auths[platform_info['id']] = True\n",
        "                print(f\"‚úÖ {platform_info['name']} ready for bulk processing\")\n",
        "            else:\n",
        "                platform_auths[platform_info['id']] = False\n",
        "                print(f\"‚ö†Ô∏è {platform_info['name']} authentication failed, will skip\")\n",
        "    \n",
        "    # Start bulk processing\n",
        "    print(f\"\\nüöÄ Starting bulk processing...\")\n",
        "    print(f\"üì¶ Batch size: {batch_size}\")\n",
        "    print(f\"üîÑ Skip duplicates: {'Yes' if skip_duplicates else 'No'}\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    processed_count = 0\n",
        "    success_count = 0\n",
        "    duplicate_count = 0\n",
        "    error_count = 0\n",
        "    \n",
        "    # Process in batches\n",
        "    for batch_start in range(0, len(epub_files), batch_size):\n",
        "        batch_end = min(batch_start + batch_size, len(epub_files))\n",
        "        batch_files = epub_files[batch_start:batch_end]\n",
        "        \n",
        "        print(f\"\\nüì¶ Processing batch {batch_start//batch_size + 1}/{(len(epub_files)-1)//batch_size + 1}\")\n",
        "        print(f\"üìÇ Files {batch_start + 1}-{batch_end} of {len(epub_files)}\")\n",
        "        \n",
        "        for epub_path in batch_files:\n",
        "            processed_count += 1\n",
        "            filename = os.path.basename(epub_path)\n",
        "            \n",
        "            print(f\"\\nüìñ [{processed_count}/{len(epub_files)}] Processing: {filename}\")\n",
        "            \n",
        "            try:\n",
        "                # Extract metadata\n",
        "                print(\"   üìù Extracting metadata...\")\n",
        "                metadata = epub_processor.extract_metadata(epub_path)\n",
        "                if not metadata:\n",
        "                    print(\"   ‚ùå Failed to extract metadata, skipping\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Check for duplicates\n",
        "                if skip_duplicates:\n",
        "                    is_duplicate, existing_file = github_manager.check_duplicate_book(\n",
        "                        metadata['title'], metadata['author']\n",
        "                    )\n",
        "                    \n",
        "                    if is_duplicate:\n",
        "                        print(f\"   ‚ö†Ô∏è Duplicate found: {existing_file}, skipping\")\n",
        "                        duplicate_count += 1\n",
        "                        continue\n",
        "                \n",
        "                # Create public sharing link\n",
        "                print(\"   üîó Creating public sharing link...\")\n",
        "                # For bulk processing, we'll create a simple file://path as placeholder\n",
        "                # In real scenario, this would involve Google Drive API\n",
        "                public_drive_link = f\"https://drive.google.com/file/d/PLACEHOLDER_{processed_count}/view?usp=sharing\"\n",
        "                print(f\"   üìã Note: Please manually create sharing link for {filename}\")\n",
        "                \n",
        "                # Extract images\n",
        "                print(\"   üñºÔ∏è Processing images...\")\n",
        "                cover_path = epub_processor.extract_cover_image(epub_path)\n",
        "                \n",
        "                # Process images\n",
        "                image_urls = {}\n",
        "                if cloudinary_manager and cloudinary_manager.configured:\n",
        "                    print(\"   ‚òÅÔ∏è Uploading to Cloudinary...\")\n",
        "                    image_urls = cloudinary_manager.process_epub_images(cover_path)\n",
        "                else:\n",
        "                    image_urls = {\n",
        "                        'cover_url': f\"https://via.placeholder.com/400x600/cccccc/ffffff?text={metadata['title'][:20]}\",\n",
        "                        'preview_url': f\"https://via.placeholder.com/800x1200/cccccc/ffffff?text={metadata['title'][:20]}\"\n",
        "                    }\n",
        "                \n",
        "                # Platform shortening\n",
        "                print(\"   üîó Shortening URLs...\")\n",
        "                download_links = []\n",
        "                \n",
        "                # Process with available shortener platforms\n",
        "                for platform_info in shortener_platforms:\n",
        "                    if platform_auths.get(platform_info['id'], False):\n",
        "                        shortened_url = dynamic_platform_manager.shorten_url(\n",
        "                            platform_info['name'], \n",
        "                            public_drive_link\n",
        "                        )\n",
        "                        \n",
        "                        if shortened_url != public_drive_link:\n",
        "                            download_links.append({\n",
        "                                'platform': platform_info['name'],\n",
        "                                'url': shortened_url,\n",
        "                                'index': platform_info['index'],\n",
        "                                'icon': platform_info['icon']\n",
        "                            })\n",
        "                        \n",
        "                        # Add delay ƒë·ªÉ tr√°nh rate limiting\n",
        "                        time.sleep(1)\n",
        "                \n",
        "                # Add direct link\n",
        "                gdrive_platform = platform_config_manager.get_platform_by_index(0)\n",
        "                if gdrive_platform:\n",
        "                    download_links.append({\n",
        "                        'platform': gdrive_platform['name'],\n",
        "                        'url': public_drive_link,\n",
        "                        'index': gdrive_platform['index'],\n",
        "                        'icon': gdrive_platform['icon']\n",
        "                    })\n",
        "                \n",
        "                if not download_links:\n",
        "                    print(\"   ‚ö†Ô∏è No download links available, skipping\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Build book data\n",
        "                preview_content = epub_processor.extract_preview_content(epub_path)\n",
        "                \n",
        "                book_data = {\n",
        "                    'title': metadata['title'],\n",
        "                    'author': metadata['author'],\n",
        "                    'description': metadata['description'],\n",
        "                    'cover_image': image_urls['cover_url'],\n",
        "                    'preview_image': image_urls['preview_url'],\n",
        "                    'language': metadata['language'],\n",
        "                    'download_links': download_links,\n",
        "                    'config_url': credential_manager.get('default_config_api') or \"\"\n",
        "                }\n",
        "                \n",
        "                # Add optional fields\n",
        "                if metadata.get('publisher'):\n",
        "                    book_data['publisher'] = metadata['publisher']\n",
        "                if metadata.get('published_date'):\n",
        "                    book_data['published_date'] = metadata['published_date']\n",
        "                if metadata.get('isbn'):\n",
        "                    book_data['isbn'] = metadata['isbn']\n",
        "                if preview_content:\n",
        "                    book_data['preview_content'] = preview_content\n",
        "                \n",
        "                # Generate v√† upload markdown\n",
        "                print(\"   üìù Generating markdown...\")\n",
        "                markdown_content = markdown_generator.generate_markdown(book_data)\n",
        "                md_filename = markdown_generator.generate_filename(metadata['title'])\n",
        "                \n",
        "                file_path = f\"_epubs/{md_filename}\"\n",
        "                commit_message = f\"Bulk add: {metadata['title']} - {metadata['author']}\"\n",
        "                \n",
        "                # Upload to GitHub\n",
        "                print(\"   üì§ Uploading to GitHub...\")\n",
        "                if github_manager.file_exists(file_path):\n",
        "                    success = github_manager.update_file(file_path, markdown_content, commit_message)\n",
        "                else:\n",
        "                    success = github_manager.create_file(file_path, markdown_content, commit_message)\n",
        "                \n",
        "                if success:\n",
        "                    success_count += 1\n",
        "                    print(f\"   ‚úÖ Success: {metadata['title']}\")\n",
        "                    print(f\"      üìÇ File: {md_filename}\")\n",
        "                    print(f\"      üîó Links: {len(download_links)}\")\n",
        "                else:\n",
        "                    error_count += 1\n",
        "                    print(f\"   ‚ùå Upload failed: {metadata['title']}\")\n",
        "                \n",
        "                # Cleanup\n",
        "                if cover_path and os.path.exists(cover_path):\n",
        "                    os.remove(cover_path)\n",
        "                \n",
        "            except Exception as e:\n",
        "                error_count += 1\n",
        "                print(f\"   ‚ùå Error processing {filename}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # Batch completion message\n",
        "        print(f\"\\nüìä Batch {batch_start//batch_size + 1} completed\")\n",
        "        print(f\"   ‚úÖ Success: {success_count}\")\n",
        "        print(f\"   ‚ö†Ô∏è Duplicates: {duplicate_count}\")\n",
        "        print(f\"   ‚ùå Errors: {error_count}\")\n",
        "        \n",
        "        # Pause between batches (n·∫øu kh√¥ng ph·∫£i batch cu·ªëi)\n",
        "        if batch_end < len(epub_files):\n",
        "            delay = input(f\"\\n‚è∏Ô∏è Pause before next batch? Enter seconds (default: 3): \").strip()\n",
        "            delay_time = int(delay) if delay.isdigit() else 3\n",
        "            print(f\"‚è±Ô∏è Waiting {delay_time} seconds...\")\n",
        "            time.sleep(delay_time)\n",
        "    \n",
        "    # Final summary\n",
        "    print(f\"\\nüéâ BULK PROCESSING COMPLETED!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"üìÇ Total files processed: {processed_count}\")\n",
        "    print(f\"‚úÖ Successfully added: {success_count}\")\n",
        "    print(f\"‚ö†Ô∏è Duplicates skipped: {duplicate_count}\")\n",
        "    print(f\"‚ùå Errors encountered: {error_count}\")\n",
        "    print(f\"üìà Success rate: {(success_count/processed_count)*100:.1f}%\")\n",
        "    \n",
        "    if success_count > 0:\n",
        "        print(f\"\\nüöÄ GitHub Pages will rebuild automatically\")\n",
        "        print(f\"üìö {success_count} new books added to library\")\n",
        "        \n",
        "        # Show processing stats\n",
        "        print(f\"\\nüìä Processing Statistics:\")\n",
        "        if shortener_platforms:\n",
        "            print(f\"   üîó Platform shortening: {len(shortener_platforms)} platforms used\")\n",
        "        if cloudinary_manager and cloudinary_manager.configured:\n",
        "            print(f\"   ‚òÅÔ∏è Image processing: Cloudinary enabled\")\n",
        "        print(f\"   üì¶ Batch size: {batch_size}\")\n",
        "        print(f\"   ‚è±Ô∏è Total time: ~{processed_count * 2} seconds estimated\")\n",
        "    \n",
        "    print(f\"\\nüí° Notes:\")\n",
        "    print(f\"   üìù Remember to manually create public sharing links\")\n",
        "    print(f\"   üîó Replace PLACEHOLDER links with real Google Drive URLs\")\n",
        "    print(f\"   üîÑ Re-run shortening for updated links if needed\")\n",
        "\n",
        "# Run Mode 3\n",
        "mode3_bulk_folder_processing()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üîÑ Legacy Book Conversion Tool\n",
        "\n",
        "Convert existing books khi c√≥ platform m·ªõi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üîÑ Legacy Book Conversion Tool\n",
        "# @markdown Convert existing books v·ªõi platform m·ªõi\n",
        "\n",
        "def legacy_book_conversion():\n",
        "    \"\"\"Convert t·∫•t c·∫£ s√°ch c≈© v·ªõi platform m·ªõi\"\"\"\n",
        "    \n",
        "    if not github_manager or not platform_config_manager:\n",
        "        print(\"‚ùå Required managers not available!\")\n",
        "        print(\"üîß Please configure GitHub credentials first\")\n",
        "        return\n",
        "    \n",
        "    print(\"üîÑ Legacy Book Conversion Tool\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Get list of all existing epub files\n",
        "    print(\"üìÇ Scanning existing books...\")\n",
        "    \n",
        "    try:\n",
        "        epub_contents = github_manager.repo.get_contents(\"_epubs\", ref=github_manager.branch)\n",
        "        existing_books = [content for content in epub_contents if content.name.endswith('.md')]\n",
        "        \n",
        "        if not existing_books:\n",
        "            print(\"‚ùå No existing books found!\")\n",
        "            return\n",
        "        \n",
        "        print(f\"‚úÖ Found {len(existing_books)} existing books\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error scanning books: {e}\")\n",
        "        return\n",
        "    \n",
        "    # Show available platforms\n",
        "    print(f\"\\nüîó Available Platforms:\")\n",
        "    platform_config_manager.list_platforms()\n",
        "    \n",
        "    # Get shortener platforms\n",
        "    shortener_platforms = [p for p in platform_config_manager.platforms.values() if p['type'] == 'shortener']\n",
        "    \n",
        "    if not shortener_platforms:\n",
        "        print(\"‚ùå No shortener platforms available for conversion!\")\n",
        "        return\n",
        "    \n",
        "    # Select platform for conversion\n",
        "    print(f\"\\nüéØ Platform Selection:\")\n",
        "    print(\"Available shortener platforms:\")\n",
        "    for i, platform in enumerate(shortener_platforms, 1):\n",
        "        print(f\"   {i}. {platform['name']} (index {platform['index']})\")\n",
        "    \n",
        "    platform_choice = input(f\"\\nSelect platform number (1-{len(shortener_platforms)}): \").strip()\n",
        "    \n",
        "    try:\n",
        "        platform_index = int(platform_choice) - 1\n",
        "        if 0 <= platform_index < len(shortener_platforms):\n",
        "            selected_platform = shortener_platforms[platform_index]\n",
        "        else:\n",
        "            print(\"‚ùå Invalid platform selection!\")\n",
        "            return\n",
        "    except ValueError:\n",
        "        print(\"‚ùå Invalid input!\")\n",
        "        return\n",
        "    \n",
        "    print(f\"‚úÖ Selected: {selected_platform['name']}\")\n",
        "    \n",
        "    # Get authentication for selected platform\n",
        "    print(f\"\\nüîê Setting up authentication for {selected_platform['name']}...\")\n",
        "    \n",
        "    authenticated_curl = platform_auth_manager.build_authenticated_curl(\n",
        "        selected_platform['id'], \n",
        "        selected_platform['name'], \n",
        "        selected_platform.get('curl_template', '')\n",
        "    )\n",
        "    \n",
        "    if not authenticated_curl:\n",
        "        print(f\"‚ùå Authentication failed for {selected_platform['name']}!\")\n",
        "        return\n",
        "    \n",
        "    # Setup platform for processing\n",
        "    dynamic_platform_manager.add_platform_from_curl(\n",
        "        selected_platform['name'], \n",
        "        authenticated_curl, \n",
        "        selected_platform.get('response_config')\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Platform {selected_platform['name']} ready for conversion\")\n",
        "    \n",
        "    # Processing options\n",
        "    print(f\"\\n‚öôÔ∏è Conversion Options:\")\n",
        "    \n",
        "    # Batch size\n",
        "    batch_size_input = input(\"üì¶ Batch size (default: 10): \").strip()\n",
        "    batch_size = int(batch_size_input) if batch_size_input.isdigit() else 10\n",
        "    \n",
        "    # Test mode\n",
        "    test_mode = input(\"üß™ Test mode (preview changes without committing)? (y/N): \").strip().lower() == 'y'\n",
        "    \n",
        "    # Confirmation\n",
        "    if not test_mode:\n",
        "        confirm = input(f\"\\n‚ö†Ô∏è  CONFIRM: Convert {len(existing_books)} books v·ªõi {selected_platform['name']}? (type 'CONVERT'): \").strip()\n",
        "        if confirm != 'CONVERT':\n",
        "            print(\"‚ùå Conversion cancelled\")\n",
        "            return\n",
        "    \n",
        "    # Start conversion\n",
        "    print(f\"\\nüöÄ Starting legacy book conversion...\")\n",
        "    print(f\"üì¶ Batch size: {batch_size}\")\n",
        "    print(f\"üß™ Test mode: {'Yes' if test_mode else 'No'}\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    processed_count = 0\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "    no_gdrive_count = 0\n",
        "    \n",
        "    # Process in batches\n",
        "    for batch_start in range(0, len(existing_books), batch_size):\n",
        "        batch_end = min(batch_start + batch_size, len(existing_books))\n",
        "        batch_books = existing_books[batch_start:batch_end]\n",
        "        \n",
        "        print(f\"\\nüì¶ Processing batch {batch_start//batch_size + 1}/{(len(existing_books)-1)//batch_size + 1}\")\n",
        "        print(f\"üìÇ Books {batch_start + 1}-{batch_end} of {len(existing_books)}\")\n",
        "        \n",
        "        for book_content in batch_books:\n",
        "            processed_count += 1\n",
        "            book_filename = book_content.name\n",
        "            \n",
        "            print(f\"\\nüìñ [{processed_count}/{len(existing_books)}] Processing: {book_filename}\")\n",
        "            \n",
        "            try:\n",
        "                # Get book content\n",
        "                print(\"   üì• Reading book content...\")\n",
        "                file_content = github_manager.get_file_content(f\"_epubs/{book_filename}\")\n",
        "                if not file_content:\n",
        "                    print(\"   ‚ùå Failed to read book content\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Parse YAML front matter\n",
        "                print(\"   üìù Parsing metadata...\")\n",
        "                if not file_content.startswith('---'):\n",
        "                    print(\"   ‚ùå Invalid file format (no YAML front matter)\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Split content into YAML and body\n",
        "                parts = file_content.split('---')\n",
        "                if len(parts) < 3:\n",
        "                    print(\"   ‚ùå Invalid YAML format\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                yaml_content = parts[1]\n",
        "                body_content = '---'.join(parts[2:])\n",
        "                \n",
        "                # Parse YAML\n",
        "                try:\n",
        "                    import yaml\n",
        "                    book_data = yaml.safe_load(yaml_content)\n",
        "                except Exception as e:\n",
        "                    print(f\"   ‚ùå YAML parsing error: {e}\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Extract existing download links\n",
        "                existing_links = book_data.get('download_links', [])\n",
        "                if not existing_links:\n",
        "                    print(\"   ‚ö†Ô∏è No download links found\")\n",
        "                    no_gdrive_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Find Google Drive links\n",
        "                gdrive_links = []\n",
        "                for link in existing_links:\n",
        "                    if ('drive.google.com' in link.get('url', '') and \n",
        "                        link.get('platform', '').lower() in ['google drive', 'gdrive']):\n",
        "                        gdrive_links.append(link['url'])\n",
        "                \n",
        "                if not gdrive_links:\n",
        "                    print(\"   ‚ö†Ô∏è No Google Drive links found to convert\")\n",
        "                    no_gdrive_count += 1\n",
        "                    continue\n",
        "                \n",
        "                print(f\"   üîç Found {len(gdrive_links)} Google Drive links\")\n",
        "                \n",
        "                # Process shortening for new platform\n",
        "                new_links_added = []\n",
        "                \n",
        "                for gdrive_url in gdrive_links:\n",
        "                    # Decode URL if obfuscated\n",
        "                    actual_url = gdrive_url\n",
        "                    if gdrive_url.startswith('data:encoded,'):\n",
        "                        decoded_url = link_obfuscator.decode(gdrive_url)\n",
        "                        if decoded_url:\n",
        "                            actual_url = decoded_url\n",
        "                    \n",
        "                    print(f\"   üîó Shortening: {actual_url[:50]}...\")\n",
        "                    \n",
        "                    # Shorten with new platform\n",
        "                    shortened_url = dynamic_platform_manager.shorten_url(\n",
        "                        selected_platform['name'], \n",
        "                        actual_url\n",
        "                    )\n",
        "                    \n",
        "                    if shortened_url != actual_url:\n",
        "                        new_link = {\n",
        "                            'platform': selected_platform['name'],\n",
        "                            'url': shortened_url,\n",
        "                            'index': selected_platform['index'],\n",
        "                            'icon': selected_platform['icon']\n",
        "                        }\n",
        "                        new_links_added.append(new_link)\n",
        "                        print(f\"   ‚úÖ Shortened: {shortened_url}\")\n",
        "                    else:\n",
        "                        print(f\"   ‚ö†Ô∏è Shortening failed\")\n",
        "                    \n",
        "                    # Delay ƒë·ªÉ tr√°nh rate limiting\n",
        "                    time.sleep(1)\n",
        "                \n",
        "                if not new_links_added:\n",
        "                    print(\"   ‚ùå No new links generated\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Check if platform already exists trong book\n",
        "                platform_exists = any(\n",
        "                    link.get('index') == selected_platform['index'] \n",
        "                    for link in existing_links\n",
        "                )\n",
        "                \n",
        "                if platform_exists:\n",
        "                    print(f\"   ‚ö†Ô∏è Platform {selected_platform['name']} already exists, updating...\")\n",
        "                    # Update existing platform link\n",
        "                    for i, link in enumerate(existing_links):\n",
        "                        if link.get('index') == selected_platform['index']:\n",
        "                            existing_links[i] = new_links_added[0]  # Use first new link\n",
        "                            break\n",
        "                else:\n",
        "                    print(f\"   ‚úÖ Adding new platform {selected_platform['name']}\")\n",
        "                    # Add new platform links\n",
        "                    existing_links.extend(new_links_added)\n",
        "                \n",
        "                # Update book data\n",
        "                book_data['download_links'] = existing_links\n",
        "                \n",
        "                # Generate updated YAML content\n",
        "                updated_yaml = yaml.dump(book_data, default_flow_style=False, allow_unicode=True)\n",
        "                updated_content = f\"---\\n{updated_yaml}---{body_content}\"\n",
        "                \n",
        "                if test_mode:\n",
        "                    print(\"   üß™ TEST MODE: Changes prepared (not committed)\")\n",
        "                    print(f\"      üìä New links: {len(new_links_added)}\")\n",
        "                    print(f\"      üìè Content length: {len(updated_content)} chars\")\n",
        "                    success_count += 1\n",
        "                else:\n",
        "                    # Commit changes\n",
        "                    print(\"   üì§ Updating book...\")\n",
        "                    commit_message = f\"Add {selected_platform['name']} links: {book_data.get('title', 'Unknown')}\"\n",
        "                    \n",
        "                    success = github_manager.update_file(\n",
        "                        f\"_epubs/{book_filename}\",\n",
        "                        updated_content,\n",
        "                        commit_message\n",
        "                    )\n",
        "                    \n",
        "                    if success:\n",
        "                        success_count += 1\n",
        "                        print(f\"   ‚úÖ Updated: {book_data.get('title', book_filename)}\")\n",
        "                        print(f\"      üìä Added {len(new_links_added)} new links\")\n",
        "                    else:\n",
        "                        error_count += 1\n",
        "                        print(f\"   ‚ùå Update failed\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                error_count += 1\n",
        "                print(f\"   ‚ùå Error processing {book_filename}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # Batch completion message\n",
        "        print(f\"\\nüìä Batch {batch_start//batch_size + 1} completed\")\n",
        "        print(f\"   ‚úÖ Success: {success_count}\")\n",
        "        print(f\"   ‚ö†Ô∏è No GDrive links: {no_gdrive_count}\")\n",
        "        print(f\"   ‚ùå Errors: {error_count}\")\n",
        "        \n",
        "        # Pause between batches\n",
        "        if batch_end < len(existing_books):\n",
        "            delay = input(f\"\\n‚è∏Ô∏è Pause before next batch? Enter seconds (default: 5): \").strip()\n",
        "            delay_time = int(delay) if delay.isdigit() else 5\n",
        "            print(f\"‚è±Ô∏è Waiting {delay_time} seconds...\")\n",
        "            time.sleep(delay_time)\n",
        "    \n",
        "    # Final summary\n",
        "    print(f\"\\nüéâ LEGACY CONVERSION COMPLETED!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"üìÇ Total books processed: {processed_count}\")\n",
        "    print(f\"‚úÖ Successfully converted: {success_count}\")\n",
        "    print(f\"‚ö†Ô∏è No Google Drive links: {no_gdrive_count}\")\n",
        "    print(f\"‚ùå Errors encountered: {error_count}\")\n",
        "    print(f\"üìà Success rate: {(success_count/max(processed_count-no_gdrive_count,1))*100:.1f}%\")\n",
        "    \n",
        "    if test_mode:\n",
        "        print(f\"\\nüß™ TEST MODE SUMMARY:\")\n",
        "        print(f\"   üìã Changes previewed, no commits made\")\n",
        "        print(f\"   üîÑ Run again without test mode to apply changes\")\n",
        "    else:\n",
        "        if success_count > 0:\n",
        "            print(f\"\\nüöÄ GitHub Pages will rebuild automatically\")\n",
        "            print(f\"üîó {success_count} books now have {selected_platform['name']} links\")\n",
        "            print(f\"üì± Platform index {selected_platform['index']} ready for API configuration\")\n",
        "    \n",
        "    print(f\"\\nüìä Platform Statistics:\")\n",
        "    print(f\"   üÜî Platform ID: {selected_platform['id']}\")\n",
        "    print(f\"   üìç Platform Index: {selected_platform['index']}\")\n",
        "    print(f\"   üéØ Books Updated: {success_count}\")\n",
        "    print(f\"   ‚è±Ô∏è Total Processing Time: ~{processed_count * 3} seconds\")\n",
        "\n",
        "# Run Legacy Conversion\n",
        "legacy_book_conversion()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
