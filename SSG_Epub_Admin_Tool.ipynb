{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 📚 SSG Epub Admin Tool - Google Colab\n",
        "\n",
        "**Version**: 1.0  \n",
        "**Updated**: 2024-01-16  \n",
        "**Purpose**: Automated tool để thêm sách vào SSG Epub Library\n",
        "\n",
        "## 🎯 Chức năng chính:\n",
        "- **Mode 1**: Thêm sách manual với platform shortening\n",
        "- **Mode 2**: Extract từ Google Drive epub file  \n",
        "- **Mode 3**: Bulk processing từ Google Drive folder\n",
        "- **Platform Management**: Add/manage URL shortening platforms\n",
        "- **Legacy Conversion**: Convert existing books với platform mới\n",
        "\n",
        "## ⚠️ Lưu ý:\n",
        "- Mode 2 & 3: Cần paste fresh cURL với authentication\n",
        "- Platform configs được lưu trong GitHub `_data/platforms.yml`\n",
        "- Tất cả URL được obfuscate trước khi lưu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 📦 Setup & Installation\n",
        "# @markdown Cài đặt dependencies và setup môi trường\n",
        "\n",
        "!pip install PyGithub requests ebooklib cloudinary Pillow python-dotenv pyyaml -q\n",
        "\n",
        "import os\n",
        "import json\n",
        "import yaml\n",
        "import requests\n",
        "import base64\n",
        "import re\n",
        "import shlex\n",
        "from datetime import datetime\n",
        "from urllib.parse import parse_qs, urlparse, urlencode\n",
        "import time\n",
        "\n",
        "# Google Colab specific imports\n",
        "from google.colab import files, drive, userdata\n",
        "from github import Github\n",
        "\n",
        "print(\"✅ Dependencies installed successfully!\")\n",
        "print(\"🔧 Setup hoàn tất - sẵn sàng sử dụng!\")\n",
        "print(\"🔐 Secure credential management enabled với Google Colab userdata\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 🔐 Secure Configuration & Credentials  \n",
        "# @markdown Load credentials từ Google Colab userdata (secure storage)\n",
        "\n",
        "class SecureCredentialManager:\n",
        "    \"\"\"Quản lý credentials một cách bảo mật với Google Colab userdata\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.credentials = {}\n",
        "        self.load_credentials()\n",
        "    \n",
        "    def get_credential(self, key, prompt_text, is_required=True):\n",
        "        \"\"\"Get credential từ userdata hoặc prompt user\"\"\"\n",
        "        try:\n",
        "            # Kiểm tra userdata trước\n",
        "            value = userdata.get(key)\n",
        "            if value:\n",
        "                print(f\"🔍 Đã tìm thấy {key} trong userdata\")\n",
        "                return value\n",
        "        except:\n",
        "            print(f\"⚠️ Không tìm thấy {key} trong userdata\")\n",
        "        \n",
        "        # Nếu chưa có, yêu cầu người dùng nhập\n",
        "        if is_required:\n",
        "            value = input(f\"🔑 {prompt_text}: \").strip()\n",
        "            if value:\n",
        "                print(f\"📝 Bạn có thể lưu vào userdata: userdata.set('{key}', 'your_value')\")\n",
        "                return value\n",
        "            else:\n",
        "                print(f\"❌ {key} is required!\")\n",
        "                return None\n",
        "        else:\n",
        "            value = input(f\"🔑 {prompt_text} (optional): \").strip()\n",
        "            if value:\n",
        "                print(f\"📝 Có thể lưu vào userdata: userdata.set('{key}', 'your_value')\")\n",
        "            return value or None\n",
        "    \n",
        "    def load_credentials(self):\n",
        "        \"\"\"Load tất cả credentials cần thiết\"\"\"\n",
        "        print(\"🔐 Loading Secure Credentials\")\n",
        "        print(\"=\" * 40)\n",
        "        \n",
        "        # GitHub credentials (required)\n",
        "        self.credentials['github_token'] = self.get_credential(\n",
        "            'GITHUB_TOKEN', \n",
        "            'GitHub Personal Access Token', \n",
        "            True\n",
        "        )\n",
        "        \n",
        "        self.credentials['github_repo'] = self.get_credential(\n",
        "            'GITHUB_REPO', \n",
        "            'GitHub Repository (user/repo)', \n",
        "            True\n",
        "        )\n",
        "        \n",
        "        self.credentials['branch_name'] = self.get_credential(\n",
        "            'BRANCH_NAME', \n",
        "            'Git Branch Name', \n",
        "            False\n",
        "        ) or \"main\"\n",
        "        \n",
        "        # Cloudinary credentials (optional)\n",
        "        self.credentials['cloudinary_cloud_name'] = self.get_credential(\n",
        "            'CLOUDINARY_CLOUD_NAME', \n",
        "            'Cloudinary Cloud Name', \n",
        "            False\n",
        "        )\n",
        "        \n",
        "        if self.credentials['cloudinary_cloud_name']:\n",
        "            self.credentials['cloudinary_api_key'] = self.get_credential(\n",
        "                'CLOUDINARY_API_KEY', \n",
        "                'Cloudinary API Key', \n",
        "                False\n",
        "            )\n",
        "            \n",
        "            self.credentials['cloudinary_api_secret'] = self.get_credential(\n",
        "                'CLOUDINARY_API_SECRET', \n",
        "                'Cloudinary API Secret', \n",
        "                False\n",
        "            )\n",
        "        \n",
        "        # API Configuration\n",
        "        self.credentials['default_config_api'] = self.get_credential(\n",
        "            'DEFAULT_CONFIG_API', \n",
        "            'Default Config API URL', \n",
        "            False\n",
        "        ) or \"\"\n",
        "        \n",
        "        # Validate and test GitHub\n",
        "        self.test_github_connection()\n",
        "    \n",
        "    def test_github_connection(self):\n",
        "        \"\"\"Test GitHub connection\"\"\"\n",
        "        if not self.credentials['github_token'] or not self.credentials['github_repo']:\n",
        "            print(\"❌ GitHub credentials missing!\")\n",
        "            return False\n",
        "        \n",
        "        try:\n",
        "            g = Github(self.credentials['github_token'])\n",
        "            repo = g.get_repo(self.credentials['github_repo'])\n",
        "            print(f\"✅ GitHub connection successful: {repo.full_name}\")\n",
        "            print(f\"📊 Repository stats: {repo.stargazers_count} stars, {repo.forks_count} forks\")\n",
        "            \n",
        "            self.credentials['github_instance'] = g\n",
        "            self.credentials['repo_instance'] = repo\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ GitHub connection failed: {e}\")\n",
        "            print(\"🔧 Please check your token and repository name\")\n",
        "            return False\n",
        "    \n",
        "    def get(self, key):\n",
        "        \"\"\"Get credential value\"\"\"\n",
        "        return self.credentials.get(key)\n",
        "    \n",
        "    def show_status(self):\n",
        "        \"\"\"Show configuration status\"\"\"\n",
        "        print(\"\\n🔧 Configuration Status:\")\n",
        "        print(\"=\" * 30)\n",
        "        print(f\"📂 Target repository: {self.get('github_repo')}\")\n",
        "        print(f\"🌿 Target branch: {self.get('branch_name')}\")\n",
        "        \n",
        "        if self.get('cloudinary_cloud_name'):\n",
        "            print(f\"☁️ Cloudinary configured: {self.get('cloudinary_cloud_name')}\")\n",
        "        else:\n",
        "            print(\"⚠️ Cloudinary not configured (image processing disabled)\")\n",
        "        \n",
        "        if self.get('default_config_api'):\n",
        "            print(f\"🔗 Default API: {self.get('default_config_api')[:50]}...\")\n",
        "        \n",
        "        print(\"\\n💡 Tip: Lưu credentials vào userdata để tránh nhập lại:\")\n",
        "        print(\"   userdata.set('GITHUB_TOKEN', 'your_token')\")\n",
        "        print(\"   userdata.set('GITHUB_REPO', 'user/repo')\")\n",
        "\n",
        "# Initialize secure credential manager\n",
        "credential_manager = SecureCredentialManager()\n",
        "credential_manager.show_status()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 🔧 Core Classes - GitHub Manager\n",
        "# @markdown GitHub operations for file management\n",
        "\n",
        "class GitHubManager:\n",
        "    def __init__(self, token, repo_name, branch=\"main\"):\n",
        "        self.github = Github(token)\n",
        "        self.repo = self.github.get_repo(repo_name)\n",
        "        self.branch = branch\n",
        "        \n",
        "    def file_exists(self, file_path):\n",
        "        \"\"\"Check if file exists in repo\"\"\"\n",
        "        try:\n",
        "            self.repo.get_contents(file_path, ref=self.branch)\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "    \n",
        "    def get_file_content(self, file_path):\n",
        "        \"\"\"Get file content as string\"\"\"\n",
        "        try:\n",
        "            file_data = self.repo.get_contents(file_path, ref=self.branch)\n",
        "            content = base64.b64decode(file_data.content).decode('utf-8')\n",
        "            return content\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to get file content: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def create_file(self, file_path, content, commit_message):\n",
        "        \"\"\"Create new file in repository\"\"\"\n",
        "        try:\n",
        "            if self.file_exists(file_path):\n",
        "                raise Exception(f\"File {file_path} already exists!\")\n",
        "            \n",
        "            self.repo.create_file(\n",
        "                path=file_path,\n",
        "                message=commit_message,\n",
        "                content=content,\n",
        "                branch=self.branch\n",
        "            )\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to create file: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def update_file(self, file_path, content, commit_message):\n",
        "        \"\"\"Update existing file\"\"\"\n",
        "        try:\n",
        "            file_data = self.repo.get_contents(file_path, ref=self.branch)\n",
        "            self.repo.update_file(\n",
        "                path=file_path,\n",
        "                message=commit_message,\n",
        "                content=content,\n",
        "                sha=file_data.sha,\n",
        "                branch=self.branch\n",
        "            )\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to update file: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def check_duplicate_book(self, title, author):\n",
        "        \"\"\"Check if book already exists\"\"\"\n",
        "        try:\n",
        "            contents = self.repo.get_contents(\"_epubs\", ref=self.branch)\n",
        "            \n",
        "            for content in contents:\n",
        "                if content.name.endswith('.md'):\n",
        "                    file_content = base64.b64decode(content.content).decode('utf-8')\n",
        "                    \n",
        "                    if '---' in file_content:\n",
        "                        yaml_content = file_content.split('---')[1]\n",
        "                        if f'title: \"{title}\"' in yaml_content and f'author: \"{author}\"' in yaml_content:\n",
        "                            return True, content.name\n",
        "            \n",
        "            return False, None\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Could not check duplicates: {e}\")\n",
        "            return False, None\n",
        "\n",
        "# Initialize GitHub manager với secure credentials\n",
        "if credential_manager.get('github_token') and credential_manager.get('github_repo'):\n",
        "    try:\n",
        "        github_manager = GitHubManager(\n",
        "            credential_manager.get('github_token'), \n",
        "            credential_manager.get('github_repo'), \n",
        "            credential_manager.get('branch_name')\n",
        "        )\n",
        "        print(\"📂 GitHub Manager initialized successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ GitHub Manager failed: {e}\")\n",
        "        github_manager = None\n",
        "else:\n",
        "    github_manager = None\n",
        "    print(\"⚠️ GitHub Manager not initialized - please configure credentials first\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 🔗 URL Obfuscation System\n",
        "# @markdown Simple obfuscation cho download URLs\n",
        "\n",
        "class LinkObfuscator:\n",
        "    \"\"\"Simple obfuscation utilities - consistent với frontend\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def encode(url):\n",
        "        try:\n",
        "            # Simple XOR with key + Base64 (same as frontend)\n",
        "            key = 'SSGEpub2024'\n",
        "            result = ''\n",
        "            for i in range(len(url)):\n",
        "                result += chr(ord(url[i]) ^ ord(key[i % len(key)]))\n",
        "            \n",
        "            encoded = base64.b64encode(result.encode('utf-8')).decode('utf-8')\n",
        "            return f\"data:encoded,{encoded}\"\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Failed to encode URL: {e}\")\n",
        "            return url\n",
        "    \n",
        "    @staticmethod\n",
        "    def decode(encoded_url):\n",
        "        try:\n",
        "            if encoded_url.startswith('data:encoded,'):\n",
        "                encoded_part = encoded_url.replace('data:encoded,', '')\n",
        "            else:\n",
        "                encoded_part = encoded_url\n",
        "            \n",
        "            key = 'SSGEpub2024'\n",
        "            decoded = base64.b64decode(encoded_part).decode('utf-8')\n",
        "            result = ''\n",
        "            for i in range(len(decoded)):\n",
        "                result += chr(ord(decoded[i]) ^ ord(key[i % len(key)]))\n",
        "            \n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Failed to decode URL: {e}\")\n",
        "            return None\n",
        "\n",
        "# Test obfuscation\n",
        "test_url = \"https://drive.google.com/file/d/1atVRKbZ07rSF5X_Q0OW1lLKywqAj4yvd/view?usp=sharing\"\n",
        "encoded = LinkObfuscator.encode(test_url)\n",
        "decoded = LinkObfuscator.decode(encoded)\n",
        "\n",
        "print(\"🧪 Testing URL Obfuscation:\")\n",
        "print(f\"Original: {test_url[:50]}...\")\n",
        "print(f\"Encoded: {encoded[:50]}...\")\n",
        "print(f\"Decoded: {decoded[:50]}...\")\n",
        "print(f\"✅ Test: {'PASSED' if decoded == test_url else 'FAILED'}\")\n",
        "\n",
        "link_obfuscator = LinkObfuscator()\n",
        "print(\"🔗 Link Obfuscator ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 🌐 Dynamic Platform Manager\n",
        "# @markdown Universal cURL parser cho custom shortening platforms\n",
        "\n",
        "class DynamicPlatformManager:\n",
        "    \"\"\"Dynamic platform manager với simplified authentication\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.platforms = {}\n",
        "        \n",
        "    def parse_curl_command(self, curl_command):\n",
        "        \"\"\"Parse cURL command thành request components\"\"\"\n",
        "        try:\n",
        "            # Clean command\n",
        "            curl_command = curl_command.strip()\n",
        "            if curl_command.startswith('curl '):\n",
        "                curl_command = curl_command[5:]\n",
        "            \n",
        "            config = {\n",
        "                'method': 'GET',\n",
        "                'url': '',\n",
        "                'headers': {},\n",
        "                'data': None,\n",
        "                'json': None\n",
        "            }\n",
        "            \n",
        "            # Extract method\n",
        "            method_match = re.search(r'-X\\s+(\\w+)', curl_command)\n",
        "            if method_match:\n",
        "                config['method'] = method_match.group(1).upper()\n",
        "            \n",
        "            # Extract URL\n",
        "            urls = re.findall(r'https?://[^\\s\\'\"]+', curl_command)\n",
        "            if urls:\n",
        "                config['url'] = urls[0]\n",
        "            \n",
        "            # Extract headers\n",
        "            headers = re.findall(r'-H\\s+[\\'\"]([^\\'\"]*)[\\'\"]', curl_command)\n",
        "            for header in headers:\n",
        "                if ':' in header:\n",
        "                    key, value = header.split(':', 1)\n",
        "                    config['headers'][key.strip()] = value.strip()\n",
        "            \n",
        "            # Extract data\n",
        "            data_matches = re.findall(r'-d\\s+[\\'\"]([^\\'\"]*)[\\'\"]', curl_command)\n",
        "            if data_matches:\n",
        "                data_string = data_matches[0]\n",
        "                \n",
        "                # Determine if JSON or form data\n",
        "                content_type = config['headers'].get('Content-Type', '').lower()\n",
        "                if 'application/json' in content_type:\n",
        "                    try:\n",
        "                        config['json'] = json.loads(data_string)\n",
        "                    except:\n",
        "                        config['data'] = data_string\n",
        "                else:\n",
        "                    # Parse as form data\n",
        "                    config['data'] = self._parse_form_data(data_string)\n",
        "            \n",
        "            return config\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error parsing cURL: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def _parse_form_data(self, data_string):\n",
        "        \"\"\"Parse form data string\"\"\"\n",
        "        try:\n",
        "            result = {}\n",
        "            pairs = data_string.split('&')\n",
        "            for pair in pairs:\n",
        "                if '=' in pair:\n",
        "                    key, value = pair.split('=', 1)\n",
        "                    result[key] = value\n",
        "            return result\n",
        "        except:\n",
        "            return data_string\n",
        "    \n",
        "    def add_platform_from_curl(self, platform_name, curl_command, response_config=None):\n",
        "        \"\"\"Add platform từ cURL example\"\"\"\n",
        "        request_config = self.parse_curl_command(curl_command)\n",
        "        if not request_config:\n",
        "            print(f\"❌ Failed to parse cURL for {platform_name}\")\n",
        "            return False\n",
        "        \n",
        "        if not response_config:\n",
        "            response_config = {'type': 'auto'}\n",
        "        \n",
        "        self.platforms[platform_name] = {\n",
        "            'name': platform_name,\n",
        "            'request_config': request_config,\n",
        "            'response_config': response_config,\n",
        "            'curl_template': curl_command\n",
        "        }\n",
        "        \n",
        "        print(f\"✅ Added platform: {platform_name}\")\n",
        "        return True\n",
        "    \n",
        "    def shorten_url(self, platform_name, target_url):\n",
        "        \"\"\"Shorten URL với specified platform\"\"\"\n",
        "        if platform_name not in self.platforms:\n",
        "            print(f\"❌ Platform not found: {platform_name}\")\n",
        "            return target_url\n",
        "        \n",
        "        platform = self.platforms[platform_name]\n",
        "        \n",
        "        try:\n",
        "            # Build request với target URL\n",
        "            request_config = self._prepare_request(platform['request_config'], target_url)\n",
        "            \n",
        "            # Execute request\n",
        "            response = self._execute_request(request_config)\n",
        "            \n",
        "            if response and response.status_code == 200:\n",
        "                short_url = self._extract_short_url(response, platform['response_config'])\n",
        "                \n",
        "                if short_url and short_url.startswith('http'):\n",
        "                    print(f\"✅ {platform_name}: {target_url[:50]}... → {short_url}\")\n",
        "                    return short_url\n",
        "                else:\n",
        "                    print(f\"⚠️ Could not extract URL from {platform_name} response\")\n",
        "                    return target_url\n",
        "            else:\n",
        "                status = response.status_code if response else 'No response'\n",
        "                print(f\"❌ {platform_name} request failed: {status}\")\n",
        "                return target_url\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error with {platform_name}: {e}\")\n",
        "            return target_url\n",
        "    \n",
        "    def _prepare_request(self, config, target_url):\n",
        "        \"\"\"Replace ${link_drive} placeholder với actual URL\"\"\"\n",
        "        prepared_config = config.copy()\n",
        "        \n",
        "        # Replace in JSON data\n",
        "        if prepared_config.get('json'):\n",
        "            prepared_config['json'] = self._replace_placeholder(\n",
        "                prepared_config['json'], target_url\n",
        "            )\n",
        "        \n",
        "        # Replace in form data\n",
        "        if prepared_config.get('data'):\n",
        "            prepared_config['data'] = self._replace_placeholder(\n",
        "                prepared_config['data'], target_url\n",
        "            )\n",
        "        \n",
        "        return prepared_config\n",
        "    \n",
        "    def _replace_placeholder(self, data, target_url):\n",
        "        \"\"\"Replace ${link_drive} placeholder recursively\"\"\"\n",
        "        if isinstance(data, dict):\n",
        "            return {k: self._replace_placeholder(v, target_url) for k, v in data.items()}\n",
        "        elif isinstance(data, str):\n",
        "            return data.replace('${link_drive}', target_url)\n",
        "        else:\n",
        "            return data\n",
        "    \n",
        "    def _execute_request(self, config):\n",
        "        \"\"\"Execute HTTP request\"\"\"\n",
        "        try:\n",
        "            method = config['method'].lower()\n",
        "            url = config['url']\n",
        "            headers = config.get('headers', {})\n",
        "            \n",
        "            kwargs = {'headers': headers}\n",
        "            \n",
        "            if config.get('json'):\n",
        "                kwargs['json'] = config['json']\n",
        "            elif config.get('data'):\n",
        "                kwargs['data'] = config['data']\n",
        "            \n",
        "            response = getattr(requests, method)(url, **kwargs)\n",
        "            return response\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Request execution failed: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def _extract_short_url(self, response, config):\n",
        "        \"\"\"Extract short URL từ response\"\"\"\n",
        "        try:\n",
        "            if response.headers.get('content-type', '').startswith('application/json'):\n",
        "                data = response.json()\n",
        "                \n",
        "                if 'path' in config:\n",
        "                    path_parts = config['path'].split('.')\n",
        "                    current = data\n",
        "                    for part in path_parts:\n",
        "                        if isinstance(current, dict) and part in current:\n",
        "                            current = current[part]\n",
        "                        else:\n",
        "                            return None\n",
        "                    return str(current) if current else None\n",
        "                \n",
        "                # Auto-detect common fields\n",
        "                common_fields = ['short_url', 'shortened_url', 'url', 'link', 'shortlink']\n",
        "                for field in common_fields:\n",
        "                    if field in data:\n",
        "                        return str(data[field])\n",
        "            else:\n",
        "                text = response.text.strip()\n",
        "                if 'regex' in config:\n",
        "                    match = re.search(config['regex'], text)\n",
        "                    return match.group(0) if match else None\n",
        "                elif text.startswith('http'):\n",
        "                    return text\n",
        "            \n",
        "            return None\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Extraction error: {e}\")\n",
        "            return None\n",
        "\n",
        "# Initialize dynamic platform manager\n",
        "dynamic_platform_manager = DynamicPlatformManager()\n",
        "print(\"🌐 Dynamic Platform Manager initialized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 🏗️ Platform Configuration Manager\n",
        "# @markdown Quản lý platform configs trong GitHub\n",
        "\n",
        "class PlatformConfigManager:\n",
        "    def __init__(self, github_manager):\n",
        "        self.github_manager = github_manager\n",
        "        self.config_file = \"_data/platforms.yml\"\n",
        "        self.platforms = {}\n",
        "        self.next_index = 0\n",
        "        \n",
        "        # Load existing platforms\n",
        "        self.load_platforms()\n",
        "    \n",
        "    def load_platforms(self):\n",
        "        \"\"\"Load platforms từ GitHub\"\"\"\n",
        "        try:\n",
        "            if self.github_manager and self.github_manager.file_exists(self.config_file):\n",
        "                content = self.github_manager.get_file_content(self.config_file)\n",
        "                if content:\n",
        "                    config = yaml.safe_load(content)\n",
        "                    if config and 'platforms' in config:\n",
        "                        for platform in config['platforms']:\n",
        "                            self.platforms[platform['id']] = platform\n",
        "                        \n",
        "                        # Calculate next available index\n",
        "                        if self.platforms:\n",
        "                            self.next_index = max(p['index'] for p in self.platforms.values()) + 1\n",
        "                        else:\n",
        "                            self.next_index = 0\n",
        "                        \n",
        "                        print(f\"✅ Loaded {len(self.platforms)} platforms from GitHub\")\n",
        "                        return\n",
        "            \n",
        "            # Initialize with default platforms\n",
        "            self._initialize_default_platforms()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error loading platforms: {e}\")\n",
        "            self._initialize_default_platforms()\n",
        "    \n",
        "    def _initialize_default_platforms(self):\n",
        "        \"\"\"Initialize với default platforms\"\"\"\n",
        "        default_platforms = [\n",
        "            {\n",
        "                'name': 'Google Drive',\n",
        "                'id': 'gdrive',\n",
        "                'index': 0,\n",
        "                'icon': 'fab fa-google-drive',\n",
        "                'type': 'direct',\n",
        "                'active': True,\n",
        "                'created_date': datetime.now().isoformat()\n",
        "            },\n",
        "            {\n",
        "                'name': 'OneDrive',\n",
        "                'id': 'onedrive',\n",
        "                'index': 1,\n",
        "                'icon': 'fab fa-microsoft',\n",
        "                'type': 'direct',\n",
        "                'active': True,\n",
        "                'created_date': datetime.now().isoformat()\n",
        "            }\n",
        "        ]\n",
        "        \n",
        "        for platform in default_platforms:\n",
        "            self.platforms[platform['id']] = platform\n",
        "        \n",
        "        self.next_index = 2\n",
        "        print(\"🔧 Initialized với default platforms\")\n",
        "    \n",
        "    def add_platform(self, name, platform_id, icon, curl_template, response_config):\n",
        "        \"\"\"Add new platform với fixed index\"\"\"\n",
        "        try:\n",
        "            if platform_id in self.platforms:\n",
        "                print(f\"⚠️ Platform {platform_id} already exists!\")\n",
        "                return False\n",
        "            \n",
        "            new_platform = {\n",
        "                'name': name,\n",
        "                'id': platform_id,\n",
        "                'index': self.next_index,\n",
        "                'icon': icon,\n",
        "                'type': 'shortener',\n",
        "                'active': True,\n",
        "                'created_date': datetime.now().isoformat(),\n",
        "                'curl_template': curl_template,\n",
        "                'response_config': response_config\n",
        "            }\n",
        "            \n",
        "            self.platforms[platform_id] = new_platform\n",
        "            self.next_index += 1\n",
        "            \n",
        "            # Save to GitHub\n",
        "            if self.save_platforms():\n",
        "                print(f\"✅ Added platform: {name} (index {new_platform['index']})\\\")\\n                return True\\n            else:\\n                # Rollback\\n                del self.platforms[platform_id]\\n                self.next_index -= 1\\n                print(f\\\"❌ Failed to save platform {name}\\\")\\n                return False\\n                \\n        except Exception as e:\\n            print(f\\\"❌ Error adding platform: {e}\\\")\\n            return False\\n    \\n    def save_platforms(self):\\n        \\\"\\\"\\\"Save platforms to GitHub\\\"\\\"\\\"\\n        try:\\n            config = {\\n                'platforms': list(self.platforms.values()),\\n                'metadata': {\\n                    'version': '1.0.0',\\n                    'last_updated': datetime.now().isoformat(),\\n                    'next_index': self.next_index\\n                }\\n            }\\n            \\n            yaml_content = yaml.dump(config, default_flow_style=False, allow_unicode=True)\\n            \\n            if self.github_manager.file_exists(self.config_file):\\n                success = self.github_manager.update_file(\\n                    self.config_file,\\n                    yaml_content,\\n                    f\\\"Cập nhật platform configurations - {len(self.platforms)} platforms\\\"\\n                )\\n            else:\\n                success = self.github_manager.create_file(\\n                    self.config_file,\\n                    yaml_content,\\n                    \\\"Khởi tạo platform configurations\\\"\\n                )\\n            \\n            if success:\\n                print(f\\\"💾 Saved {len(self.platforms)} platforms to GitHub\\\")\\n                return True\\n            else:\\n                print(\\\"❌ Failed to save platforms to GitHub\\\")\\n                return False\\n                \\n        except Exception as e:\\n            print(f\\\"❌ Error saving platforms: {e}\\\")\\n            return False\\n    \\n    def get_platform_by_index(self, index):\\n        \\\"\\\"\\\"Get platform by index\\\"\\\"\\\"\\n        for platform in self.platforms.values():\\n            if platform['index'] == index:\\n                return platform\\n        return None\\n    \\n    def list_platforms(self):\\n        \\\"\\\"\\\"List all platforms\\\"\\\"\\\"\\n        print(\\\"📋 Available Platforms:\\\")\\n        print(\\\"=\\\" * 50)\\n        \\n        sorted_platforms = sorted(self.platforms.values(), key=lambda x: x['index'])\\n        \\n        for platform in sorted_platforms:\\n            status = \\\"🟢\\\" if platform['active'] else \\\"🔴\\\"\\n            platform_type = \\\"📎\\\" if platform['type'] == 'direct' else \\\"🔗\\\"\\n            \\n            print(f\\\"{status} {platform_type} [{platform['index']}] {platform['name']} ({platform['id']})\\\")\\n            \\n            if platform.get('curl_template'):\\n                print(f\\\"   📝 cURL configured\\\")\\n            \\n        print(f\\\"\\\\n📊 Total: {len(self.platforms)} platforms\\\")\\n        print(f\\\"🔢 Next index: {self.next_index}\\\")\\n\\n# Initialize platform config manager\\nif github_manager:\\n    platform_config_manager = PlatformConfigManager(github_manager)\\n    print(\\\"🏗️ Platform Config Manager initialized!\\\")\\nelse:\\n    platform_config_manager = None\\n    print(\\\"⚠️ Platform Config Manager not initialized - GitHub required\\\")\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 📝 Markdown Generator\n",
        "# @markdown Generate Jekyll-compatible markdown files\n",
        "\n",
        "class MarkdownGenerator:\n",
        "    def __init__(self):\n",
        "        self.obfuscator = LinkObfuscator()\n",
        "    \n",
        "    def generate_filename(self, title):\n",
        "        \"\"\"Generate filename from title\"\"\"\n",
        "        # Remove Vietnamese tones and special chars\n",
        "        filename = self.remove_vietnamese_tones(title)\n",
        "        filename = re.sub(r'[^a-zA-Z0-9\\s]', '', filename)\n",
        "        filename = re.sub(r'\\s+', '-', filename.strip().lower())\n",
        "        return f\"{filename[:50]}.md\"\n",
        "    \n",
        "    def remove_vietnamese_tones(self, text):\n",
        "        \"\"\"Remove Vietnamese accents\"\"\"\n",
        "        replacements = {\n",
        "            'à|á|ạ|ả|ã|â|ầ|ấ|ậ|ẩ|ẫ|ă|ằ|ắ|ặ|ẳ|ẵ': 'a',\n",
        "            'è|é|ẹ|ẻ|ẽ|ê|ề|ế|ệ|ể|ễ': 'e',\n",
        "            'ì|í|ị|ỉ|ĩ': 'i',\n",
        "            'ò|ó|ọ|ỏ|õ|ô|ồ|ố|ộ|ổ|ỗ|ơ|ờ|ớ|ợ|ở|ỡ': 'o',\n",
        "            'ù|ú|ụ|ủ|ũ|ư|ừ|ứ|ự|ử|ữ': 'u',\n",
        "            'ỳ|ý|ỵ|ỷ|ỹ': 'y',\n",
        "            'đ': 'd'\n",
        "        }\n",
        "        \n",
        "        for pattern, replacement in replacements.items():\n",
        "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "        \n",
        "        return text\n",
        "    \n",
        "    def generate_markdown(self, book_data):\n",
        "        \"\"\"Generate complete markdown file content\"\"\"\n",
        "        \n",
        "        yaml_lines = [\"---\", \"layout: epub\"]\n",
        "        \n",
        "        # Required fields\n",
        "        yaml_lines.append(f'title: \"{book_data[\"title\"]}\"')\n",
        "        yaml_lines.append(f'author: \"{book_data[\"author\"]}\"')\n",
        "        yaml_lines.append(f'cover_image: \"{book_data[\"cover_image\"]}\"')\n",
        "        \n",
        "        # Optional fields\n",
        "        optional_fields = ['preview_image', 'isbn', 'published_date', 'language', 'publisher']\n",
        "        for field in optional_fields:\n",
        "            if book_data.get(field):\n",
        "                yaml_lines.append(f'{field}: \"{book_data[field]}\"')\n",
        "        \n",
        "        # Genre array\n",
        "        if book_data.get(\"genre\"):\n",
        "            yaml_lines.append(\"genre:\")\n",
        "            for genre in book_data[\"genre\"]:\n",
        "                yaml_lines.append(f'  - \"{genre}\"')\n",
        "        \n",
        "        yaml_lines.append(f'description: \"{book_data[\"description\"]}\"')\n",
        "        \n",
        "        # Numeric fields\n",
        "        if book_data.get(\"rating\"):\n",
        "            yaml_lines.append(f'rating: {book_data[\"rating\"]}')\n",
        "        \n",
        "        if book_data.get(\"pages\"):\n",
        "            yaml_lines.append(f'pages: {book_data[\"pages\"]}')\n",
        "        \n",
        "        # Preview content\n",
        "        if book_data.get(\"preview_content\"):\n",
        "            yaml_lines.append(\"preview_content: |\")\n",
        "            for line in book_data[\"preview_content\"].split('\\n'):\n",
        "                yaml_lines.append(f\"  {line}\")\n",
        "        \n",
        "        # Download links với obfuscation\n",
        "        if book_data.get(\"download_links\"):\n",
        "            yaml_lines.append(\"download_links:\")\n",
        "            for link in book_data[\"download_links\"]:\n",
        "                # Obfuscate URL if not already obfuscated\n",
        "                url = link[\"url\"]\n",
        "                if not url.startswith('data:encoded,'):\n",
        "                    url = self.obfuscator.encode(url)\n",
        "                \n",
        "                yaml_lines.append(f'  - platform: \"{link[\"platform\"]}\"')\n",
        "                yaml_lines.append(f'    url: \"{url}\"')\n",
        "                yaml_lines.append(f'    index: {link[\"index\"]}')\n",
        "                yaml_lines.append(f'    icon: \"{link[\"icon\"]}\"')\n",
        "        \n",
        "        # Config URL\n",
        "        if book_data.get(\"config_url\"):\n",
        "            yaml_lines.append(f'download_config_url: \"{book_data[\"config_url\"]}\"')\n",
        "        \n",
        "        # Tags\n",
        "        if book_data.get(\"tags\"):\n",
        "            yaml_lines.append(\"tags:\")\n",
        "            for tag in book_data[\"tags\"]:\n",
        "                yaml_lines.append(f'  - \"{tag}\"')\n",
        "        \n",
        "        yaml_lines.append(\"---\")\n",
        "        yaml_lines.append(\"\")\n",
        "        yaml_lines.append(f'Đây là trang chi tiết của cuốn sách \"{{{{ page.title }}}}\" của tác giả {{{{ page.author }}}}.') \n",
        "        \n",
        "        return '\\n'.join(yaml_lines)\n",
        "\n",
        "# Initialize markdown generator\n",
        "markdown_generator = MarkdownGenerator()\n",
        "print(\"📝 Markdown Generator initialized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 🚀 System Status Check\n",
        "# @markdown Kiểm tra status và sẵn sàng sử dụng\n",
        "\n",
        "def check_system_status():\n",
        "    \"\"\"Check system components status\"\"\"\n",
        "    print(\"🔍 System Status Check:\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # GitHub\n",
        "    if github_manager:\n",
        "        print(\"✅ GitHub Manager: Ready\")\n",
        "        try:\n",
        "            # Test repo access\n",
        "            repo_info = github_manager.repo\n",
        "            print(f\"   📂 Repository: {repo_info.full_name}\")\n",
        "            print(f\"   🌿 Branch: {github_manager.branch}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ⚠️ Repository access issue: {e}\")\n",
        "    else:\n",
        "        print(\"❌ GitHub Manager: Not configured\")\n",
        "    \n",
        "    # Platform Manager\n",
        "    print(f\"✅ Platform Manager: Ready ({len(dynamic_platform_manager.platforms)} platforms)\")\n",
        "    \n",
        "    # Platform Config Manager\n",
        "    if platform_config_manager:\n",
        "        print(f\"✅ Platform Config: Ready ({len(platform_config_manager.platforms)} registered)\")\n",
        "    else:\n",
        "        print(\"❌ Platform Config: Not initialized\")\n",
        "    \n",
        "    # Obfuscation\n",
        "    print(\"✅ Link Obfuscation: Ready\")\n",
        "    \n",
        "    # Markdown Generator\n",
        "    print(\"✅ Markdown Generator: Ready\")\n",
        "    \n",
        "    # Cloudinary\n",
        "    if credential_manager.get('cloudinary_cloud_name'):\n",
        "        print(f\"✅ Cloudinary: Configured ({credential_manager.get('cloudinary_cloud_name')})\")\n",
        "    else:\n",
        "        print(\"⚠️ Cloudinary: Not configured (image processing disabled)\")\n",
        "    \n",
        "    print(\"\\n🎯 Available Commands:\")\n",
        "    print(\"   📚 Mode 1: Manual book addition\")\n",
        "    print(\"   📂 Mode 2: Google Drive epub extraction\")\n",
        "    print(\"   📁 Mode 3: Bulk folder processing\")\n",
        "    print(\"   🔧 Platform Management\")\n",
        "    print(\"   🔄 Legacy Conversion\")\n",
        "\n",
        "# Run status check\n",
        "check_system_status()\n",
        "\n",
        "print(\"\\n🚀 SSG Epub Admin Tool sẵn sàng sử dụng!\")\n",
        "print(\"📋 Chạy các cell bên dưới để bắt đầu...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# 🔧 Platform Management\n",
        "\n",
        "Quản lý các platform rút gọn link\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 📋 List Existing Platforms\n",
        "# @markdown Hiển thị tất cả platforms đã đăng ký\n",
        "\n",
        "if platform_config_manager:\n",
        "    platform_config_manager.list_platforms()\n",
        "else:\n",
        "    print(\"❌ Platform Config Manager not available!\")\n",
        "    print(\"🔧 Please configure GitHub credentials first\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ➕ Add New Platform\n",
        "# @markdown Thêm platform rút gọn mới\n",
        "\n",
        "def add_new_platform():\n",
        "    \"\"\"Interactive platform addition\"\"\"\n",
        "    if not platform_config_manager:\n",
        "        print(\"❌ Platform Config Manager not available!\")\n",
        "        return\n",
        "    \n",
        "    print(\"🔧 Thêm Platform Rút Gọn Mới\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Platform info\n",
        "    platform_name = input(\"📝 Tên platform (VD: YeuMoney): \").strip()\n",
        "    if not platform_name:\n",
        "        print(\"❌ Platform name is required!\")\n",
        "        return\n",
        "    \n",
        "    platform_id = input(\"🆔 Platform ID (VD: yeumoney): \").strip().lower()\n",
        "    if not platform_id:\n",
        "        platform_id = platform_name.lower().replace(' ', '')\n",
        "    \n",
        "    icon = input(\"🎨 Icon class (VD: fas fa-heart): \").strip()\n",
        "    if not icon:\n",
        "        icon = \"fas fa-link\"\n",
        "    \n",
        "    print(f\"\\n📝 Nhập cURL command (có chứa ${{link_drive}}):\")\n",
        "    print(\"VD: curl -X POST 'https://yeumoney.com/api' -H 'Authorization: Bearer abc123' -d '{\\\"url\\\": \\\"${{link_drive}}\\\"}'\\\")\n",
        "    \n",
        "    curl_command = input(\"\\ncURL: \").strip()\n",
        "    if not curl_command:\n",
        "        print(\"❌ cURL command is required!\")\n",
        "        return\n",
        "    \n",
        "    # Response config\n",
        "    print(f\"\\n🔧 Response Configuration:\")\n",
        "    print(\"1. Auto-detect (recommended)\")\n",
        "    print(\"2. JSON path (VD: data.short_url)\")\n",
        "    print(\"3. Regex pattern\")\n",
        "    \n",
        "    config_choice = input(\"Chọn (1-3): \").strip()\n",
        "    \n",
        "    response_config = {'type': 'auto'}\n",
        "    \n",
        "    if config_choice == \"2\":\n",
        "        json_path = input(\"JSON path (VD: data.short_url): \").strip()\n",
        "        if json_path:\n",
        "            response_config = {'type': 'json', 'path': json_path}\n",
        "    elif config_choice == \"3\":\n",
        "        regex_pattern = input(\"Regex pattern: \").strip()\n",
        "        if regex_pattern:\n",
        "            response_config = {'type': 'text', 'regex': regex_pattern}\n",
        "    \n",
        "    # Test platform\n",
        "    print(f\"\\n🧪 Testing platform configuration...\")\n",
        "    \n",
        "    # Add to dynamic manager for testing\n",
        "    dynamic_platform_manager.add_platform_from_curl(platform_name, curl_command, response_config)\n",
        "    \n",
        "    test_url = \"https://drive.google.com/file/d/1atVRKbZ07rSF5X_Q0OW1lLKywqAj4yvd/view?usp=sharing\"\n",
        "    print(f\"🔗 Testing với: {test_url[:50]}...\")\n",
        "    \n",
        "    result = dynamic_platform_manager.shorten_url(platform_name, test_url)\n",
        "    \n",
        "    if result != test_url:\n",
        "        print(f\"✅ Test successful: {result}\")\n",
        "        \n",
        "        # Confirm save\n",
        "        save_confirm = input(f\"\\n💾 Save platform '{platform_name}' to GitHub? (y/N): \").strip().lower()\n",
        "        \n",
        "        if save_confirm == 'y':\n",
        "            success = platform_config_manager.add_platform(\n",
        "                platform_name, platform_id, icon, curl_command, response_config\n",
        "            )\n",
        "            \n",
        "            if success:\n",
        "                print(f\"✅ Platform '{platform_name}' added successfully!\")\n",
        "                print(f\"📍 Assigned index: {platform_config_manager.platforms[platform_id]['index']}\")\n",
        "            else:\n",
        "                print(f\"❌ Failed to save platform!\")\n",
        "        else:\n",
        "            print(\"❌ Platform not saved\")\n",
        "    else:\n",
        "        print(f\"❌ Test failed - platform không hoạt động đúng\")\n",
        "        print(\"🔧 Kiểm tra lại cURL command và response config\")\n",
        "\n",
        "# Run interactive platform addition\n",
        "add_new_platform()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# 📚 Mode 1: Manual Book Addition  \n",
        "\n",
        "Thêm sách thủ công với platform shortening\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 📝 Mode 1: Manual Book Addition\n",
        "# @markdown Thêm sách thủ công với platform shortening\n",
        "\n",
        "def mode1_manual_book_addition():\n",
        "    \"\"\"Mode 1: Manual book addition với platform shortening\"\"\"\n",
        "    \n",
        "    if not github_manager or not platform_config_manager:\n",
        "        print(\"❌ Required managers not available!\")\n",
        "        print(\"🔧 Please configure GitHub credentials first\")\n",
        "        return\n",
        "    \n",
        "    print(\"📚 Mode 1: Manual Book Addition\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Basic book information\n",
        "    print(\"📖 Basic Information:\")\n",
        "    title = input(\"📖 Title: \").strip()\n",
        "    if not title:\n",
        "        print(\"❌ Title is required!\")\n",
        "        return\n",
        "    \n",
        "    author = input(\"✍️ Author: \").strip()\n",
        "    if not author:\n",
        "        print(\"❌ Author is required!\")\n",
        "        return\n",
        "    \n",
        "    # Check for duplicates\n",
        "    print(f\"\\n🔍 Checking for duplicates...\")\n",
        "    is_duplicate, existing_file = github_manager.check_duplicate_book(title, author)\n",
        "    \n",
        "    if is_duplicate:\n",
        "        print(f\"⚠️ Book already exists: {existing_file}\")\n",
        "        overwrite = input(\"📝 Continue anyway? (y/N): \").strip().lower()\n",
        "        if overwrite != 'y':\n",
        "            print(\"❌ Operation cancelled\")\n",
        "            return\n",
        "    \n",
        "    # Collect book metadata\n",
        "    description = input(\"📄 Description: \").strip()\n",
        "    cover_image = input(\"🖼️ Cover image URL: \").strip()\n",
        "    \n",
        "    # Optional fields\n",
        "    preview_image = input(\"🖼️ Preview image URL (optional): \").strip()\n",
        "    isbn = input(\"📊 ISBN (optional): \").strip()\n",
        "    published_date = input(\"📅 Published date (YYYY-MM-DD, optional): \").strip()\n",
        "    language = input(\"🌐 Language (optional): \").strip() or \"Tiếng Việt\"\n",
        "    publisher = input(\"🏢 Publisher (optional): \").strip()\n",
        "    \n",
        "    # Genre\n",
        "    genres_input = input(\"🏷️ Genres (comma separated): \").strip()\n",
        "    genres = [g.strip() for g in genres_input.split(',')] if genres_input else []\n",
        "    \n",
        "    # Rating and pages\n",
        "    rating_input = input(\"⭐ Rating (1-5, optional): \").strip()\n",
        "    rating = float(rating_input) if rating_input and rating_input.replace('.', '').isdigit() else None\n",
        "    \n",
        "    pages_input = input(\"📄 Pages (optional): \").strip()\n",
        "    pages = int(pages_input) if pages_input.isdigit() else None\n",
        "    \n",
        "    # Config URL\n",
        "    config_url = input(\"🔗 Config API URL (optional): \").strip() or credential_manager.get('default_config_api')\n",
        "    \n",
        "    # Download links setup\n",
        "    print(f\"\\n🔗 Download Links Setup:\")\n",
        "    print(\"Available platforms:\")\n",
        "    if platform_config_manager:\n",
        "        platform_config_manager.list_platforms()\n",
        "    \n",
        "    download_links = []\n",
        "    \n",
        "    while True:\n",
        "        print(f\"\\n➕ Adding download link #{len(download_links) + 1}\")\n",
        "        \n",
        "        # Show available platforms\n",
        "        available_platforms = list(platform_config_manager.platforms.keys())\n",
        "        print(f\"Available platforms: {', '.join(available_platforms)}\")\n",
        "        \n",
        "        platform_id = input(\"🌐 Platform ID (hoặc 'done' để hoàn thành): \").strip().lower()\n",
        "        \n",
        "        if platform_id == 'done':\n",
        "            break\n",
        "        \n",
        "        if platform_id not in platform_config_manager.platforms:\n",
        "            print(f\"❌ Platform '{platform_id}' not found!\")\n",
        "            continue\n",
        "        \n",
        "        platform_info = platform_config_manager.platforms[platform_id]\n",
        "        \n",
        "        # Get original URL\n",
        "        original_url = input(f\"🔗 Original URL cho {platform_info['name']}: \").strip()\n",
        "        if not original_url:\n",
        "            print(\"❌ URL is required!\")\n",
        "            continue\n",
        "        \n",
        "        # For shortener platforms, get cURL for shortening\n",
        "        if platform_info['type'] == 'shortener':\n",
        "            print(f\"\\n🔧 Shortening with {platform_info['name']}...\")\n",
        "            print(f\"📝 Paste fresh cURL command (với authentication):\\\")\\n            print(f\\\"(Replace ${{link_drive}} sẽ được thay thế tự động)\\\")\\n            \\n            fresh_curl = input(\\\"cURL: \\\").strip()\\n            if fresh_curl:\\n                # Update platform with fresh cURL\\n                dynamic_platform_manager.add_platform_from_curl(\\n                    platform_info['name'], \\n                    fresh_curl, \\n                    platform_info.get('response_config')\\n                )\\n                \\n                # Shorten URL\\n                shortened_url = dynamic_platform_manager.shorten_url(platform_info['name'], original_url)\\n                \\n                if shortened_url != original_url:\\n                    final_url = shortened_url\\n                    print(f\\\"✅ Shortened: {original_url[:30]}... → {shortened_url}\\\")\\n                else:\\n                    print(f\\\"⚠️ Shortening failed, using original URL\\\")\\n                    final_url = original_url\\n            else:\\n                print(f\\\"⚠️ No cURL provided, using original URL\\\")\\n                final_url = original_url\\n        else:\\n            # Direct platform\\n            final_url = original_url\\n        \\n        download_links.append({\\n            'platform': platform_info['name'],\\n            'url': final_url,\\n            'index': platform_info['index'],\\n            'icon': platform_info['icon']\\n        })\\n        \\n        print(f\\\"✅ Added {platform_info['name']} (index {platform_info['index']})\\\")\\n    \\n    if not download_links:\\n        print(\\\"❌ At least one download link is required!\\\")\\n        return\\n    \\n    # Build book data\\n    book_data = {\\n        'title': title,\\n        'author': author,\\n        'description': description,\\n        'cover_image': cover_image,\\n        'download_links': download_links,\\n        'config_url': config_url\\n    }\\n    \\n    # Add optional fields\\n    if preview_image:\\n        book_data['preview_image'] = preview_image\\n    if isbn:\\n        book_data['isbn'] = isbn\\n    if published_date:\\n        book_data['published_date'] = published_date\\n    if language:\\n        book_data['language'] = language\\n    if publisher:\\n        book_data['publisher'] = publisher\\n    if genres:\\n        book_data['genre'] = genres\\n    if rating:\\n        book_data['rating'] = rating\\n    if pages:\\n        book_data['pages'] = pages\\n    \\n    # Generate markdown\\n    print(f\\\"\\\\n📝 Generating markdown file...\\\")\\n    markdown_content = markdown_generator.generate_markdown(book_data)\\n    filename = markdown_generator.generate_filename(title)\\n    \\n    print(f\\\"📄 Generated file: {filename}\\\")\\n    print(f\\\"📏 Content length: {len(markdown_content)} characters\\\")\\n    \\n    # Preview\\n    print(f\\\"\\\\n📋 Preview (first 300 chars):\\\")\\n    print(\\\"-\\\" * 40)\\n    print(markdown_content[:300] + \\\"...\\\")\\n    print(\\\"-\\\" * 40)\\n    \\n    # Confirm upload\\n    upload_confirm = input(f\\\"\\\\n📤 Upload '{filename}' to GitHub? (y/N): \\\").strip().lower()\\n    \\n    if upload_confirm == 'y':\\n        file_path = f\\\"_epubs/{filename}\\\"\\n        commit_message = f\\\"Thêm sách: {title} - {author}\\\"\\n        \\n        try:\\n            if github_manager.file_exists(file_path):\\n                success = github_manager.update_file(file_path, markdown_content, commit_message)\\n                action = \\\"Updated\\\"\\n            else:\\n                success = github_manager.create_file(file_path, markdown_content, commit_message)\\n                action = \\\"Created\\\"\\n            \\n            if success:\\n                print(f\\\"✅ {action} file successfully!\\\")\\n                print(f\\\"📂 File: {file_path}\\\")\\n                print(f\\\"💬 Commit: {commit_message}\\\")\\n                print(f\\\"🚀 GitHub Pages sẽ rebuild automatically\\\")\\n                \\n                # Summary\\n                print(f\\\"\\\\n📊 Summary:\\\")\\n                print(f\\\"   📖 Title: {title}\\\")\\n                print(f\\\"   ✍️ Author: {author}\\\")\\n                print(f\\\"   🔗 Download links: {len(download_links)}\\\")\\n                for link in download_links:\\n                    print(f\\\"      [{link['index']}] {link['platform']}\\\")\\n            else:\\n                print(f\\\"❌ Failed to {action.lower()} file!\\\")\\n                \\n        except Exception as e:\\n            print(f\\\"❌ Error uploading file: {e}\\\")\\n    else:\\n        print(\\\"❌ File not uploaded\\\")\\n        print(f\\\"💾 Markdown content saved locally for reference\\\")\\n\\n# Run Mode 1\\nmode1_manual_book_addition()\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 🔐 Secure Platform Authentication Manager\n",
        "# @markdown Quản lý authentication cho các platform một cách bảo mật\n",
        "\n",
        "class SecurePlatformAuthManager:\n",
        "    \"\"\"Quản lý authentication cho platforms với userdata\"\"\"\n",
        "    \n",
        "    def __init__(self, credential_manager):\n",
        "        self.credential_manager = credential_manager\n",
        "        self.platform_auth = {}\n",
        "    \n",
        "    def get_platform_auth(self, platform_id, platform_name, auth_type=\"cookie\"):\n",
        "        \"\"\"Get authentication cho platform từ userdata hoặc input\"\"\"\n",
        "        auth_key = f\"{platform_id}_{auth_type}\".upper()\n",
        "        \n",
        "        try:\n",
        "            # Kiểm tra userdata trước\n",
        "            auth_value = userdata.get(auth_key)\n",
        "            if auth_value:\n",
        "                print(f\"🔍 Đã tìm thấy {auth_type} cho {platform_name} trong userdata\")\n",
        "                return auth_value\n",
        "        except:\n",
        "            print(f\"⚠️ Không tìm thấy {auth_type} cho {platform_name} trong userdata\")\n",
        "        \n",
        "        # Yêu cầu user nhập\n",
        "        if auth_type == \"cookie\":\n",
        "            prompt = f\"🍪 Nhập cookie cho {platform_name}\"\n",
        "        elif auth_type == \"token\":\n",
        "            prompt = f\"🔑 Nhập access token cho {platform_name}\"\n",
        "        else:\n",
        "            prompt = f\"🔐 Nhập {auth_type} cho {platform_name}\"\n",
        "        \n",
        "        auth_value = input(f\"{prompt}: \").strip()\n",
        "        \n",
        "        if auth_value:\n",
        "            print(f\"📝 Lưu vào userdata: userdata.set('{auth_key}', 'your_{auth_type}')\")\n",
        "            self.platform_auth[platform_id] = {\n",
        "                'type': auth_type,\n",
        "                'value': auth_value\n",
        "            }\n",
        "            return auth_value\n",
        "        else:\n",
        "            print(f\"❌ {auth_type} cho {platform_name} không được cung cấp\")\n",
        "            return None\n",
        "    \n",
        "    def get_fresh_curl_with_auth(self, platform_id, platform_name, base_curl_template):\n",
        "        \"\"\"Get fresh cURL với authentication mới\"\"\"\n",
        "        print(f\"\\n🔧 Cần fresh authentication cho {platform_name}\")\n",
        "        print(\"⚠️ Platform authentication có thể đã hết hạn\")\n",
        "        print(\"📝 Vui lòng cung cấp cURL command mới với valid authentication\")\n",
        "        print(\"🔗 Placeholder ${link_drive} sẽ được thay thế tự động\")\n",
        "        print(\"\\nVí dụ:\")\n",
        "        print(f\"curl -X POST 'https://{platform_id}.com/api' \\\\\")\n",
        "        print(\"  -H 'Authorization: Bearer your_fresh_token' \\\\\")\n",
        "        print(\"  -d '{\\\"url\\\": \\\"${link_drive}\\\"}'\")\n",
        "        \n",
        "        fresh_curl = input(f\"\\n🔄 Fresh cURL cho {platform_name}: \").strip()\n",
        "        \n",
        "        if fresh_curl:\n",
        "            print(f\"✅ Fresh cURL received cho {platform_name}\")\n",
        "            \n",
        "            # Extract và lưu authentication info nếu có thể\n",
        "            if 'Authorization: Bearer' in fresh_curl:\n",
        "                auth_match = re.search(r'Authorization: Bearer ([^\\'\\\"\\\\s]+)', fresh_curl)\n",
        "                if auth_match:\n",
        "                    token = auth_match.group(1)\n",
        "                    auth_key = f\"{platform_id}_TOKEN\".upper()\n",
        "                    print(f\"🔑 Extracted token - có thể lưu: userdata.set('{auth_key}', '{token[:10]}...')\")\n",
        "            \n",
        "            elif 'Cookie:' in fresh_curl:\n",
        "                cookie_match = re.search(r'Cookie: ([^\\'\\\"\\\\n]+)', fresh_curl)\n",
        "                if cookie_match:\n",
        "                    cookie = cookie_match.group(1)\n",
        "                    auth_key = f\"{platform_id}_COOKIE\".upper()\n",
        "                    print(f\"🍪 Extracted cookie - có thể lưu: userdata.set('{auth_key}', 'your_cookie')\")\n",
        "            \n",
        "            return fresh_curl\n",
        "        else:\n",
        "            print(f\"❌ Không có fresh cURL cho {platform_name}\")\n",
        "            return None\n",
        "    \n",
        "    def build_authenticated_curl(self, platform_id, platform_name, base_template):\n",
        "        \"\"\"Build cURL với authentication từ userdata hoặc fresh input\"\"\"\n",
        "        \n",
        "        # Try to get stored auth first\n",
        "        stored_auth = None\n",
        "        for auth_type in ['TOKEN', 'COOKIE', 'API_KEY']:\n",
        "            auth_key = f\"{platform_id}_{auth_type}\".upper()\n",
        "            try:\n",
        "                stored_value = userdata.get(auth_key)\n",
        "                if stored_value:\n",
        "                    stored_auth = {'type': auth_type, 'value': stored_value}\n",
        "                    print(f\"🔍 Found stored {auth_type} cho {platform_name}\")\n",
        "                    break\n",
        "            except:\n",
        "                continue\n",
        "        \n",
        "        if stored_auth:\n",
        "            # Try to use stored auth\n",
        "            use_stored = input(f\"🔄 Sử dụng stored {stored_auth['type']} cho {platform_name}? (y/N): \").strip().lower()\n",
        "            \n",
        "            if use_stored == 'y':\n",
        "                # Build cURL với stored auth\n",
        "                auth_curl = self._inject_auth_into_curl(base_template, stored_auth)\n",
        "                if auth_curl:\n",
        "                    return auth_curl\n",
        "        \n",
        "        # Get fresh cURL if no stored auth hoặc user không muốn dùng\n",
        "        return self.get_fresh_curl_with_auth(platform_id, platform_name, base_template)\n",
        "    \n",
        "    def _inject_auth_into_curl(self, base_template, auth_info):\n",
        "        \"\"\"Inject authentication vào base cURL template\"\"\"\n",
        "        try:\n",
        "            if auth_info['type'] == 'TOKEN':\n",
        "                if 'Authorization:' not in base_template:\n",
        "                    # Add authorization header\n",
        "                    if '-H' in base_template:\n",
        "                        base_template = base_template.replace(\n",
        "                            '-H', \n",
        "                            f'-H \"Authorization: Bearer {auth_info[\"value\"]}\" -H', \n",
        "                            1\n",
        "                        )\n",
        "                    else:\n",
        "                        base_template = base_template.replace(\n",
        "                            'curl ', \n",
        "                            f'curl -H \"Authorization: Bearer {auth_info[\"value\"]}\" '\n",
        "                        )\n",
        "                else:\n",
        "                    # Replace existing authorization\n",
        "                    base_template = re.sub(\n",
        "                        r'Authorization: Bearer [^\\s\\'\"]+',\n",
        "                        f'Authorization: Bearer {auth_info[\"value\"]}',\n",
        "                        base_template\n",
        "                    )\n",
        "            \n",
        "            elif auth_info['type'] == 'COOKIE':\n",
        "                if 'Cookie:' not in base_template:\n",
        "                    # Add cookie header\n",
        "                    if '-H' in base_template:\n",
        "                        base_template = base_template.replace(\n",
        "                            '-H', \n",
        "                            f'-H \"Cookie: {auth_info[\"value\"]}\" -H', \n",
        "                            1\n",
        "                        )\n",
        "                    else:\n",
        "                        base_template = base_template.replace(\n",
        "                            'curl ', \n",
        "                            f'curl -H \"Cookie: {auth_info[\"value\"]}\" '\n",
        "                        )\n",
        "                else:\n",
        "                    # Replace existing cookie\n",
        "                    base_template = re.sub(\n",
        "                        r'Cookie: [^\\n\\'\"]+',\n",
        "                        f'Cookie: {auth_info[\"value\"]}',\n",
        "                        base_template\n",
        "                    )\n",
        "            \n",
        "            print(f\"✅ Injected {auth_info['type']} vào cURL template\")\n",
        "            return base_template\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error injecting auth: {e}\")\n",
        "            return None\n",
        "\n",
        "# Initialize secure platform auth manager\n",
        "platform_auth_manager = SecurePlatformAuthManager(credential_manager)\n",
        "print(\"🔐 Secure Platform Authentication Manager initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# 🔐 Secure Credentials Usage Guide\n",
        "\n",
        "Cách sử dụng Google Colab userdata để lưu credentials an toàn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 💡 Secure Credentials Setup Guide\n",
        "# @markdown Hướng dẫn setup credentials an toàn\n",
        "\n",
        "def show_credentials_setup_guide():\n",
        "    \"\"\"Display guide cho việc setup secure credentials\"\"\"\n",
        "    print(\"🔐 SECURE CREDENTIALS SETUP GUIDE\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    print(\"\\n📋 REQUIRED CREDENTIALS:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"🔑 GitHub Token:\")\n",
        "    print(\"   userdata.set('GITHUB_TOKEN', 'ghp_your_token_here')\")\n",
        "    print(\"   👆 Get from: https://github.com/settings/tokens\")\n",
        "    \n",
        "    print(\"\\n📂 GitHub Repository:\")\n",
        "    print(\"   userdata.set('GITHUB_REPO', 'username/repository')\")\n",
        "    print(\"   👆 Format: username/repo-name\")\n",
        "    \n",
        "    print(\"\\n🌿 Git Branch (optional):\")\n",
        "    print(\"   userdata.set('BRANCH_NAME', 'main')\")\n",
        "    print(\"   👆 Default: 'main'\")\n",
        "    \n",
        "    print(\"\\n📋 OPTIONAL CREDENTIALS:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"☁️ Cloudinary (for image processing):\")\n",
        "    print(\"   userdata.set('CLOUDINARY_CLOUD_NAME', 'your_cloud')\")\n",
        "    print(\"   userdata.set('CLOUDINARY_API_KEY', 'your_key')\")\n",
        "    print(\"   userdata.set('CLOUDINARY_API_SECRET', 'your_secret')\")\n",
        "    \n",
        "    print(\"\\n🔗 Default Config API:\")\n",
        "    print(\"   userdata.set('DEFAULT_CONFIG_API', 'https://your-api.com')\")\n",
        "    \n",
        "    print(\"\\n📋 PLATFORM AUTHENTICATION:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"🍪 Platform Cookies/Tokens (ví dụ cho YeuMoney):\")\n",
        "    print(\"   userdata.set('YEUMONEY_TOKEN', 'your_token')\")\n",
        "    print(\"   userdata.set('YEUMONEY_COOKIE', 'session=abc123;auth=xyz')\")\n",
        "    print(\"   userdata.set('SITE2S_TOKEN', 'your_token')\")\n",
        "    \n",
        "    print(\"\\n💡 USAGE TIPS:\")\n",
        "    print(\"-\" * 20)\n",
        "    print(\"✅ Credentials được lưu permanent trong session\")\n",
        "    print(\"✅ Không cần nhập lại khi restart notebook\")\n",
        "    print(\"✅ An toàn hơn so với hardcode trong code\")\n",
        "    print(\"✅ Automatically detect và sử dụng stored values\")\n",
        "    \n",
        "    print(\"\\n🛡️ SECURITY BEST PRACTICES:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"🔒 Chỉ lưu credentials trong userdata khi cần\")\n",
        "    print(\"🔒 Không share notebook với credentials\")\n",
        "    print(\"🔒 Use minimal scope tokens cho GitHub\")\n",
        "    print(\"🔒 Revoke tokens khi không sử dụng\")\n",
        "    \n",
        "    print(\"\\n📋 QUICK SETUP COMMANDS:\")\n",
        "    print(\"-\" * 25)\n",
        "    print(\"# Copy và run những dòng sau để setup nhanh:\")\n",
        "    print(\"from google.colab import userdata\")\n",
        "    print(\"userdata.set('GITHUB_TOKEN', 'your_token')\")\n",
        "    print(\"userdata.set('GITHUB_REPO', 'username/repo')\")\n",
        "    print(\"# Sau đó restart notebook để load credentials\")\n",
        "\n",
        "# Run setup guide\n",
        "show_credentials_setup_guide()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 📚 Google Drive & Epub Processing Support\n",
        "# @markdown Support libraries cho Mode 2 & 3\n",
        "\n",
        "# Additional imports for epub processing\n",
        "try:\n",
        "    import ebooklib\n",
        "    from ebooklib import epub\n",
        "    print(\"✅ ebooklib imported successfully\")\n",
        "except ImportError:\n",
        "    print(\"⚠️ Installing ebooklib...\")\n",
        "    !pip install ebooklib -q\n",
        "    import ebooklib\n",
        "    from ebooklib import epub\n",
        "    print(\"✅ ebooklib installed and imported\")\n",
        "\n",
        "# Additional imports for image processing\n",
        "try:\n",
        "    from PIL import Image\n",
        "    import cloudinary\n",
        "    import cloudinary.uploader\n",
        "    import cloudinary.api\n",
        "    print(\"✅ Image processing libraries available\")\n",
        "except ImportError:\n",
        "    print(\"⚠️ Installing image processing libraries...\")\n",
        "    !pip install Pillow cloudinary -q\n",
        "    from PIL import Image\n",
        "    import cloudinary\n",
        "    import cloudinary.uploader\n",
        "    import cloudinary.api\n",
        "    print(\"✅ Image processing libraries installed\")\n",
        "\n",
        "# Google Drive processing\n",
        "import io\n",
        "from urllib.parse import parse_qs, urlparse\n",
        "\n",
        "class GoogleDriveProcessor:\n",
        "    \"\"\"Process Google Drive links và files\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.drive_mounted = False\n",
        "        \n",
        "    def mount_drive(self):\n",
        "        \"\"\"Mount Google Drive if not already mounted\"\"\"\n",
        "        if not self.drive_mounted:\n",
        "            try:\n",
        "                drive.mount('/content/drive')\n",
        "                self.drive_mounted = True\n",
        "                print(\"✅ Google Drive mounted successfully\")\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Failed to mount Google Drive: {e}\")\n",
        "                return False\n",
        "        return True\n",
        "    \n",
        "    def extract_file_id_from_url(self, drive_url):\n",
        "        \"\"\"Extract file ID từ Google Drive URL\"\"\"\n",
        "        try:\n",
        "            if '/file/d/' in drive_url:\n",
        "                # Standard sharing link\n",
        "                file_id = drive_url.split('/file/d/')[1].split('/')[0]\n",
        "                return file_id\n",
        "            elif 'id=' in drive_url:\n",
        "                # Query parameter format\n",
        "                parsed = urlparse(drive_url)\n",
        "                query_params = parse_qs(parsed.query)\n",
        "                return query_params.get('id', [None])[0]\n",
        "            else:\n",
        "                print(f\"❌ Unsupported Google Drive URL format: {drive_url}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error extracting file ID: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def get_direct_download_url(self, file_id):\n",
        "        \"\"\"Convert file ID to direct download URL\"\"\"\n",
        "        return f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "    \n",
        "    def download_file_from_drive(self, drive_url, local_path):\n",
        "        \"\"\"Download file from Google Drive URL\"\"\"\n",
        "        try:\n",
        "            file_id = self.extract_file_id_from_url(drive_url)\n",
        "            if not file_id:\n",
        "                return False\n",
        "            \n",
        "            download_url = self.get_direct_download_url(file_id)\n",
        "            \n",
        "            # Download file\n",
        "            response = requests.get(download_url)\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                with open(local_path, 'wb') as f:\n",
        "                    f.write(response.content)\n",
        "                print(f\"✅ Downloaded: {local_path}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"❌ Download failed: HTTP {response.status_code}\")\n",
        "                return False\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error downloading file: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def create_public_sharing_link(self, file_path):\n",
        "        \"\"\"Create public sharing link for file in user's Drive\"\"\"\n",
        "        try:\n",
        "            if not self.mount_drive():\n",
        "                return None\n",
        "            \n",
        "            # This would require Google Drive API setup\n",
        "            # For now, we'll assume user provides the public link\n",
        "            print(\"⚠️ Please create public sharing link manually and provide it\")\n",
        "            public_link = input(\"📂 Public sharing link: \").strip()\n",
        "            return public_link if public_link else None\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error creating public link: {e}\")\n",
        "            return None\n",
        "\n",
        "class EpubProcessor:\n",
        "    \"\"\"Process EPUB files và extract metadata\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.temp_dir = \"/tmp/epub_processing\"\n",
        "        os.makedirs(self.temp_dir, exist_ok=True)\n",
        "    \n",
        "    def extract_metadata(self, epub_path):\n",
        "        \"\"\"Extract metadata từ EPUB file\"\"\"\n",
        "        try:\n",
        "            book = epub.read_epub(epub_path)\n",
        "            \n",
        "            metadata = {\n",
        "                'title': '',\n",
        "                'author': '',\n",
        "                'description': '',\n",
        "                'language': 'Tiếng Việt',\n",
        "                'publisher': '',\n",
        "                'published_date': '',\n",
        "                'isbn': '',\n",
        "                'pages': 0,\n",
        "                'preview_content': ''\n",
        "            }\n",
        "            \n",
        "            # Extract basic metadata\n",
        "            title = book.get_metadata('DC', 'title')\n",
        "            if title:\n",
        "                metadata['title'] = title[0][0] if title else 'Unknown Title'\n",
        "            \n",
        "            creator = book.get_metadata('DC', 'creator')\n",
        "            if creator:\n",
        "                metadata['author'] = creator[0][0] if creator else 'Unknown Author'\n",
        "            \n",
        "            description = book.get_metadata('DC', 'description')\n",
        "            if description:\n",
        "                metadata['description'] = description[0][0] if description else ''\n",
        "            \n",
        "            language = book.get_metadata('DC', 'language')\n",
        "            if language:\n",
        "                metadata['language'] = language[0][0] if language else 'Tiếng Việt'\n",
        "            \n",
        "            publisher = book.get_metadata('DC', 'publisher')\n",
        "            if publisher:\n",
        "                metadata['publisher'] = publisher[0][0] if publisher else ''\n",
        "            \n",
        "            date = book.get_metadata('DC', 'date')\n",
        "            if date:\n",
        "                metadata['published_date'] = date[0][0] if date else ''\n",
        "            \n",
        "            identifier = book.get_metadata('DC', 'identifier')\n",
        "            if identifier:\n",
        "                for ident in identifier:\n",
        "                    if 'isbn' in ident[1].get('scheme', '').lower():\n",
        "                        metadata['isbn'] = ident[0]\n",
        "                        break\n",
        "            \n",
        "            print(f\"✅ Extracted metadata for: {metadata['title']}\")\n",
        "            return metadata\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error extracting metadata: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def extract_cover_image(self, epub_path):\n",
        "        \"\"\"Extract cover image từ EPUB\"\"\"\n",
        "        try:\n",
        "            book = epub.read_epub(epub_path)\n",
        "            \n",
        "            # Try to find cover image\n",
        "            cover_image = None\n",
        "            \n",
        "            # Method 1: Look for cover in metadata\n",
        "            cover_meta = book.get_metadata('OPF', 'cover')\n",
        "            if cover_meta:\n",
        "                cover_id = cover_meta[0][0]\n",
        "                for item in book.get_items():\n",
        "                    if item.get_id() == cover_id:\n",
        "                        cover_image = item.get_content()\n",
        "                        break\n",
        "            \n",
        "            # Method 2: Look for common cover file names\n",
        "            if not cover_image:\n",
        "                cover_names = ['cover.jpg', 'cover.jpeg', 'cover.png', 'cover.gif']\n",
        "                for item in book.get_items():\n",
        "                    if item.get_type() == ebooklib.ITEM_IMAGE:\n",
        "                        filename = item.get_name().lower()\n",
        "                        if any(name in filename for name in cover_names):\n",
        "                            cover_image = item.get_content()\n",
        "                            break\n",
        "            \n",
        "            # Method 3: Take first image\n",
        "            if not cover_image:\n",
        "                for item in book.get_items():\n",
        "                    if item.get_type() == ebooklib.ITEM_IMAGE:\n",
        "                        cover_image = item.get_content()\n",
        "                        break\n",
        "            \n",
        "            if cover_image:\n",
        "                cover_path = os.path.join(self.temp_dir, \"cover.jpg\")\n",
        "                with open(cover_path, 'wb') as f:\n",
        "                    f.write(cover_image)\n",
        "                print(f\"✅ Extracted cover image: {cover_path}\")\n",
        "                return cover_path\n",
        "            else:\n",
        "                print(\"⚠️ No cover image found in EPUB\")\n",
        "                return None\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error extracting cover: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def extract_preview_content(self, epub_path, max_chars=500):\n",
        "        \"\"\"Extract preview text từ EPUB\"\"\"\n",
        "        try:\n",
        "            book = epub.read_epub(epub_path)\n",
        "            \n",
        "            preview_text = \"\"\n",
        "            \n",
        "            # Get readable items (chapters)\n",
        "            for item in book.get_items():\n",
        "                if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
        "                    content = item.get_content().decode('utf-8')\n",
        "                    \n",
        "                    # Simple HTML tag removal\n",
        "                    import re\n",
        "                    text = re.sub(r'<[^>]+>', '', content)\n",
        "                    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "                    \n",
        "                    if text and len(text) > 50:  # Skip short/empty chapters\n",
        "                        preview_text = text[:max_chars]\n",
        "                        break\n",
        "            \n",
        "            if preview_text:\n",
        "                print(f\"✅ Extracted preview ({len(preview_text)} chars)\")\n",
        "                return preview_text\n",
        "            else:\n",
        "                print(\"⚠️ No readable content found for preview\")\n",
        "                return \"\"\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error extracting preview: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "# Initialize processors\n",
        "drive_processor = GoogleDriveProcessor()\n",
        "epub_processor = EpubProcessor()\n",
        "\n",
        "print(\"📚 Google Drive & Epub Processing initialized!\")\n",
        "print(\"🔧 Ready for Mode 2 & 3 operations\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ☁️ Cloudinary Image Manager\n",
        "# @markdown Process và upload images to Cloudinary với optimal settings\n",
        "\n",
        "class CloudinaryImageManager:\n",
        "    \"\"\"Manage image processing và upload với Cloudinary\"\"\"\n",
        "    \n",
        "    def __init__(self, credential_manager):\n",
        "        self.credential_manager = credential_manager\n",
        "        self.configured = False\n",
        "        self.setup_cloudinary()\n",
        "    \n",
        "    def setup_cloudinary(self):\n",
        "        \"\"\"Setup Cloudinary configuration\"\"\"\n",
        "        try:\n",
        "            cloud_name = self.credential_manager.get('cloudinary_cloud_name')\n",
        "            api_key = self.credential_manager.get('cloudinary_api_key')\n",
        "            api_secret = self.credential_manager.get('cloudinary_api_secret')\n",
        "            \n",
        "            if cloud_name and api_key and api_secret:\n",
        "                cloudinary.config(\n",
        "                    cloud_name=cloud_name,\n",
        "                    api_key=api_key,\n",
        "                    api_secret=api_secret\n",
        "                )\n",
        "                self.configured = True\n",
        "                print(f\"✅ Cloudinary configured: {cloud_name}\")\n",
        "            else:\n",
        "                print(\"⚠️ Cloudinary not configured - image processing disabled\")\n",
        "                self.configured = False\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Cloudinary setup failed: {e}\")\n",
        "            self.configured = False\n",
        "    \n",
        "    def optimize_image(self, image_path, target_width, target_height, quality=80):\n",
        "        \"\"\"Optimize image dimensions và quality\"\"\"\n",
        "        try:\n",
        "            with Image.open(image_path) as img:\n",
        "                # Convert to RGB if needed\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "                \n",
        "                # Calculate resize dimensions maintaining aspect ratio\n",
        "                img_ratio = img.width / img.height\n",
        "                target_ratio = target_width / target_height\n",
        "                \n",
        "                if img_ratio > target_ratio:\n",
        "                    # Image is wider, fit by height\n",
        "                    new_height = target_height\n",
        "                    new_width = int(target_height * img_ratio)\n",
        "                else:\n",
        "                    # Image is taller, fit by width\n",
        "                    new_width = target_width\n",
        "                    new_height = int(target_width / img_ratio)\n",
        "                \n",
        "                # Resize image\n",
        "                resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "                \n",
        "                # Save optimized version\n",
        "                optimized_path = image_path.replace('.jpg', '_optimized.jpg')\n",
        "                resized_img.save(optimized_path, 'JPEG', quality=quality, optimize=True)\n",
        "                \n",
        "                print(f\"✅ Optimized: {img.width}x{img.height} → {new_width}x{new_height}\")\n",
        "                return optimized_path\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Image optimization failed: {e}\")\n",
        "            return image_path\n",
        "    \n",
        "    def upload_cover_image(self, image_path):\n",
        "        \"\"\"Upload cover image với optimal settings cho epub cards\"\"\"\n",
        "        if not self.configured:\n",
        "            print(\"⚠️ Cloudinary not configured, returning local path\")\n",
        "            return image_path\n",
        "        \n",
        "        try:\n",
        "            # Optimize for cover display (400x600px, WebP 80% quality)\n",
        "            optimized_path = self.optimize_image(image_path, 400, 600, 80)\n",
        "            \n",
        "            # Upload to Cloudinary\n",
        "            upload_result = cloudinary.uploader.upload(\n",
        "                optimized_path,\n",
        "                folder=\"epub_covers\",\n",
        "                format=\"webp\",\n",
        "                quality=\"auto:good\",\n",
        "                fetch_format=\"auto\",\n",
        "                responsive=True,\n",
        "                width=400,\n",
        "                height=600,\n",
        "                crop=\"fit\"\n",
        "            )\n",
        "            \n",
        "            cloudinary_url = upload_result['secure_url']\n",
        "            print(f\"✅ Cover uploaded: {cloudinary_url}\")\n",
        "            \n",
        "            # Cleanup local files\n",
        "            if os.path.exists(optimized_path):\n",
        "                os.remove(optimized_path)\n",
        "            \n",
        "            return cloudinary_url\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Cover upload failed: {e}\")\n",
        "            return image_path\n",
        "    \n",
        "    def upload_preview_image(self, image_path):\n",
        "        \"\"\"Upload preview image với larger dimensions\"\"\"\n",
        "        if not self.configured:\n",
        "            print(\"⚠️ Cloudinary not configured, returning local path\")\n",
        "            return image_path\n",
        "        \n",
        "        try:\n",
        "            # Optimize for preview display (800x1200px, WebP 80% quality)\n",
        "            optimized_path = self.optimize_image(image_path, 800, 1200, 80)\n",
        "            \n",
        "            # Upload to Cloudinary\n",
        "            upload_result = cloudinary.uploader.upload(\n",
        "                optimized_path,\n",
        "                folder=\"epub_previews\",\n",
        "                format=\"webp\",\n",
        "                quality=\"auto:good\",\n",
        "                fetch_format=\"auto\",\n",
        "                responsive=True,\n",
        "                width=800,\n",
        "                height=1200,\n",
        "                crop=\"fit\"\n",
        "            )\n",
        "            \n",
        "            cloudinary_url = upload_result['secure_url']\n",
        "            print(f\"✅ Preview uploaded: {cloudinary_url}\")\n",
        "            \n",
        "            # Cleanup local files\n",
        "            if os.path.exists(optimized_path):\n",
        "                os.remove(optimized_path)\n",
        "            \n",
        "            return cloudinary_url\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Preview upload failed: {e}\")\n",
        "            return image_path\n",
        "    \n",
        "    def process_epub_images(self, cover_path, preview_path=None):\n",
        "        \"\"\"Process both cover và preview images\"\"\"\n",
        "        results = {}\n",
        "        \n",
        "        if cover_path and os.path.exists(cover_path):\n",
        "            results['cover_url'] = self.upload_cover_image(cover_path)\n",
        "        else:\n",
        "            results['cover_url'] = \"https://via.placeholder.com/400x600/cccccc/ffffff?text=No+Cover\"\n",
        "        \n",
        "        if preview_path and os.path.exists(preview_path):\n",
        "            results['preview_url'] = self.upload_preview_image(preview_path)\n",
        "        else:\n",
        "            results['preview_url'] = results['cover_url']  # Use cover as preview fallback\n",
        "        \n",
        "        return results\n",
        "\n",
        "# Initialize cloudinary manager\n",
        "if credential_manager:\n",
        "    cloudinary_manager = CloudinaryImageManager(credential_manager)\n",
        "    print(\"☁️ Cloudinary Image Manager initialized!\")\n",
        "else:\n",
        "    cloudinary_manager = None\n",
        "    print(\"⚠️ Cloudinary Image Manager not initialized - missing credential manager\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# 📂 Mode 2: Google Drive Epub Extraction\n",
        "\n",
        "Extract thông tin từ single Google Drive EPUB file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 📂 Mode 2: Google Drive Epub Extraction\n",
        "# @markdown Extract metadata từ single Google Drive EPUB link\n",
        "\n",
        "def mode2_gdrive_epub_extraction():\n",
        "    \"\"\"Mode 2: Extract book từ Google Drive EPUB link\"\"\"\n",
        "    \n",
        "    if not github_manager or not platform_config_manager:\n",
        "        print(\"❌ Required managers not available!\")\n",
        "        print(\"🔧 Please configure GitHub credentials first\")\n",
        "        return\n",
        "    \n",
        "    print(\"📂 Mode 2: Google Drive Epub Extraction\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Get Google Drive link\n",
        "    print(\"📋 Google Drive Information:\")\n",
        "    drive_url = input(\"🔗 Google Drive EPUB URL: \").strip()\n",
        "    if not drive_url:\n",
        "        print(\"❌ Google Drive URL is required!\")\n",
        "        return\n",
        "    \n",
        "    # Validate Google Drive URL\n",
        "    if 'drive.google.com' not in drive_url:\n",
        "        print(\"❌ Invalid Google Drive URL!\")\n",
        "        return\n",
        "    \n",
        "    file_id = drive_processor.extract_file_id_from_url(drive_url)\n",
        "    if not file_id:\n",
        "        print(\"❌ Could not extract file ID from URL!\")\n",
        "        return\n",
        "    \n",
        "    print(f\"✅ Extracted file ID: {file_id}\")\n",
        "    \n",
        "    # Download EPUB file\n",
        "    temp_epub_path = f\"/tmp/epub_{file_id}.epub\"\n",
        "    print(f\"\\n📥 Downloading EPUB file...\")\n",
        "    \n",
        "    if not drive_processor.download_file_from_drive(drive_url, temp_epub_path):\n",
        "        print(\"❌ Failed to download EPUB file!\")\n",
        "        return\n",
        "    \n",
        "    # Extract metadata\n",
        "    print(f\"\\n📖 Extracting metadata...\")\n",
        "    metadata = epub_processor.extract_metadata(temp_epub_path)\n",
        "    if not metadata:\n",
        "        print(\"❌ Failed to extract metadata!\")\n",
        "        return\n",
        "    \n",
        "    # Check for duplicates\n",
        "    print(f\"\\n🔍 Checking for duplicates...\")\n",
        "    is_duplicate, existing_file = github_manager.check_duplicate_book(\n",
        "        metadata['title'], metadata['author']\n",
        "    )\n",
        "    \n",
        "    if is_duplicate:\n",
        "        print(f\"⚠️ Book already exists: {existing_file}\")\n",
        "        overwrite = input(\"📝 Continue anyway? (y/N): \").strip().lower()\n",
        "        if overwrite != 'y':\n",
        "            print(\"❌ Operation cancelled\")\n",
        "            # Cleanup\n",
        "            if os.path.exists(temp_epub_path):\n",
        "                os.remove(temp_epub_path)\n",
        "            return\n",
        "    \n",
        "    # Extract images\n",
        "    print(f\"\\n🖼️ Processing images...\")\n",
        "    cover_path = epub_processor.extract_cover_image(temp_epub_path)\n",
        "    \n",
        "    # Process với Cloudinary nếu available\n",
        "    image_urls = {}\n",
        "    if cloudinary_manager and cloudinary_manager.configured:\n",
        "        print(\"☁️ Uploading images to Cloudinary...\")\n",
        "        image_urls = cloudinary_manager.process_epub_images(cover_path)\n",
        "    else:\n",
        "        print(\"⚠️ Cloudinary not configured, using placeholder images\")\n",
        "        image_urls = {\n",
        "            'cover_url': \"https://via.placeholder.com/400x600/cccccc/ffffff?text=No+Cover\",\n",
        "            'preview_url': \"https://via.placeholder.com/800x1200/cccccc/ffffff?text=No+Preview\"\n",
        "        }\n",
        "    \n",
        "    # Extract preview content\n",
        "    print(f\"\\n📄 Extracting preview content...\")\n",
        "    preview_content = epub_processor.extract_preview_content(temp_epub_path)\n",
        "    \n",
        "    # Review extracted information\n",
        "    print(f\"\\n📋 Extracted Information:\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"📖 Title: {metadata['title']}\")\n",
        "    print(f\"✍️ Author: {metadata['author']}\")\n",
        "    print(f\"📄 Description: {metadata['description'][:100]}...\" if metadata['description'] else \"📄 Description: (empty)\")\n",
        "    print(f\"🌐 Language: {metadata['language']}\")\n",
        "    print(f\"🏢 Publisher: {metadata['publisher']}\")\n",
        "    print(f\"📅 Published: {metadata['published_date']}\")\n",
        "    print(f\"📊 ISBN: {metadata['isbn']}\")\n",
        "    print(f\"🖼️ Cover: {image_urls['cover_url'][:50]}...\")\n",
        "    print(f\"📄 Preview: {len(preview_content)} characters\")\n",
        "    \n",
        "    # Allow editing\n",
        "    print(f\"\\n✏️ Review and Edit Information:\")\n",
        "    edit_confirm = input(\"📝 Edit any information? (y/N): \").strip().lower()\n",
        "    \n",
        "    if edit_confirm == 'y':\n",
        "        print(\"\\n📝 Edit Mode (press Enter to keep current value):\")\n",
        "        \n",
        "        new_title = input(f\"📖 Title [{metadata['title']}]: \").strip()\n",
        "        if new_title:\n",
        "            metadata['title'] = new_title\n",
        "        \n",
        "        new_author = input(f\"✍️ Author [{metadata['author']}]: \").strip()\n",
        "        if new_author:\n",
        "            metadata['author'] = new_author\n",
        "        \n",
        "        new_description = input(f\"📄 Description [{metadata['description'][:50]}...]: \").strip()\n",
        "        if new_description:\n",
        "            metadata['description'] = new_description\n",
        "        \n",
        "        new_language = input(f\"🌐 Language [{metadata['language']}]: \").strip()\n",
        "        if new_language:\n",
        "            metadata['language'] = new_language\n",
        "        \n",
        "        # Genre input\n",
        "        genres_input = input(\"🏷️ Genres (comma separated): \").strip()\n",
        "        genres = [g.strip() for g in genres_input.split(',')] if genres_input else []\n",
        "        \n",
        "        # Rating and pages\n",
        "        rating_input = input(\"⭐ Rating (1-5, optional): \").strip()\n",
        "        rating = float(rating_input) if rating_input and rating_input.replace('.', '').isdigit() else None\n",
        "    else:\n",
        "        genres = []\n",
        "        rating = None\n",
        "    \n",
        "    # Platform shortening setup\n",
        "    print(f\"\\n🔗 Platform Shortening Setup:\")\n",
        "    print(\"Available platforms:\")\n",
        "    if platform_config_manager:\n",
        "        platform_config_manager.list_platforms()\n",
        "    \n",
        "    # Use the original Google Drive sharing URL for shortening\n",
        "    download_links = []\n",
        "    shortener_platforms = [p for p in platform_config_manager.platforms.values() if p['type'] == 'shortener']\n",
        "    \n",
        "    if shortener_platforms:\n",
        "        print(f\"\\n🚀 Auto-shortening với all available platforms...\")\n",
        "        \n",
        "        for platform_info in shortener_platforms:\n",
        "            print(f\"\\n🔧 Processing {platform_info['name']}...\")\n",
        "            \n",
        "            # Get authenticated cURL (userdata or fresh input)\n",
        "            authenticated_curl = platform_auth_manager.build_authenticated_curl(\n",
        "                platform_info['id'], \n",
        "                platform_info['name'], \n",
        "                platform_info.get('curl_template', '')\n",
        "            )\n",
        "            \n",
        "            if authenticated_curl:\n",
        "                # Update platform với authenticated cURL\n",
        "                dynamic_platform_manager.add_platform_from_curl(\n",
        "                    platform_info['name'], \n",
        "                    authenticated_curl, \n",
        "                    platform_info.get('response_config')\n",
        "                )\n",
        "                \n",
        "                # Shorten the original Google Drive URL\n",
        "                shortened_url = dynamic_platform_manager.shorten_url(platform_info['name'], drive_url)\n",
        "                \n",
        "                if shortened_url != drive_url:\n",
        "                    download_links.append({\n",
        "                        'platform': platform_info['name'],\n",
        "                        'url': shortened_url,\n",
        "                        'index': platform_info['index'],\n",
        "                        'icon': platform_info['icon']\n",
        "                    })\n",
        "                    print(f\"✅ {platform_info['name']}: {drive_url[:30]}... → {shortened_url}\")\n",
        "                else:\n",
        "                    print(f\"⚠️ {platform_info['name']}: Shortening failed, skipping\")\n",
        "            else:\n",
        "                print(f\"⚠️ {platform_info['name']}: No authentication, skipping\")\n",
        "    \n",
        "    # Add direct Google Drive link as fallback\n",
        "    gdrive_platform = platform_config_manager.get_platform_by_index(0)  # Assuming Google Drive is index 0\n",
        "    if gdrive_platform:\n",
        "        download_links.append({\n",
        "            'platform': gdrive_platform['name'],\n",
        "            'url': drive_url,\n",
        "            'index': gdrive_platform['index'],\n",
        "            'icon': gdrive_platform['icon']\n",
        "        })\n",
        "        print(f\"✅ Added direct Google Drive link\")\n",
        "    \n",
        "    if not download_links:\n",
        "        print(\"❌ No download links available!\")\n",
        "        return\n",
        "    \n",
        "    # Build book data\n",
        "    book_data = {\n",
        "        'title': metadata['title'],\n",
        "        'author': metadata['author'],\n",
        "        'description': metadata['description'],\n",
        "        'cover_image': image_urls['cover_url'],\n",
        "        'preview_image': image_urls['preview_url'],\n",
        "        'language': metadata['language'],\n",
        "        'download_links': download_links,\n",
        "        'config_url': credential_manager.get('default_config_api') or \"\"\n",
        "    }\n",
        "    \n",
        "    # Add optional fields\n",
        "    if metadata.get('publisher'):\\n        book_data['publisher'] = metadata['publisher']\\n    if metadata.get('published_date'):\\n        book_data['published_date'] = metadata['published_date']\\n    if metadata.get('isbn'):\\n        book_data['isbn'] = metadata['isbn']\\n    if genres:\\n        book_data['genre'] = genres\\n    if rating:\\n        book_data['rating'] = rating\\n    if preview_content:\\n        book_data['preview_content'] = preview_content\\n    \\n    # Generate markdown\\n    print(f\\\"\\\\n📝 Generating markdown file...\\\")\\n    markdown_content = markdown_generator.generate_markdown(book_data)\\n    filename = markdown_generator.generate_filename(metadata['title'])\\n    \\n    print(f\\\"📄 Generated file: {filename}\\\")\\n    print(f\\\"📏 Content length: {len(markdown_content)} characters\\\")\\n    print(f\\\"🔗 Download links: {len(download_links)}\\\")\\n    \\n    # Preview\\n    print(f\\\"\\\\n📋 Preview (first 300 chars):\\\")\\n    print(\\\"-\\\" * 40)\\n    print(markdown_content[:300] + \\\"...\\\")\\n    print(\\\"-\\\" * 40)\\n    \\n    # Confirm upload\\n    upload_confirm = input(f\\\"\\\\n📤 Upload '{filename}' to GitHub? (y/N): \\\").strip().lower()\\n    \\n    if upload_confirm == 'y':\\n        file_path = f\\\"_epubs/{filename}\\\"\\n        commit_message = f\\\"Thêm sách từ Google Drive: {metadata['title']} - {metadata['author']}\\\"\\n        \\n        try:\\n            if github_manager.file_exists(file_path):\\n                success = github_manager.update_file(file_path, markdown_content, commit_message)\\n                action = \\\"Updated\\\"\\n            else:\\n                success = github_manager.create_file(file_path, markdown_content, commit_message)\\n                action = \\\"Created\\\"\\n            \\n            if success:\\n                print(f\\\"✅ {action} file successfully!\\\")\\n                print(f\\\"📂 File: {file_path}\\\")\\n                print(f\\\"💬 Commit: {commit_message}\\\")\\n                print(f\\\"🚀 GitHub Pages sẽ rebuild automatically\\\")\\n                \\n                # Summary\\n                print(f\\\"\\\\n📊 Summary:\\\")\\n                print(f\\\"   📖 Title: {metadata['title']}\\\")\\n                print(f\\\"   ✍️ Author: {metadata['author']}\\\")\\n                print(f\\\"   📂 Source: Google Drive\\\")\\n                print(f\\\"   🔗 Download links: {len(download_links)}\\\")\\n                print(f\\\"   🖼️ Images: Processed\\\")\\n                for link in download_links:\\n                    print(f\\\"      [{link['index']}] {link['platform']}\\\")\\n            else:\\n                print(f\\\"❌ Failed to {action.lower()} file!\\\")\\n                \\n        except Exception as e:\\n            print(f\\\"❌ Error uploading file: {e}\\\")\\n    else:\\n        print(\\\"❌ File not uploaded\\\")\\n        print(f\\\"💾 Markdown content available for reference\\\")\\n    \\n    # Cleanup temporary files\\n    print(f\\\"\\\\n🧹 Cleaning up temporary files...\\\")\\n    if os.path.exists(temp_epub_path):\\n        os.remove(temp_epub_path)\\n    if cover_path and os.path.exists(cover_path):\\n        os.remove(cover_path)\\n    print(\\\"✅ Cleanup completed\\\")\\n\\n# Run Mode 2\\nmode2_gdrive_epub_extraction()\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# 📁 Mode 3: Bulk Folder Processing\n",
        "\n",
        "Xử lý bulk từ thư mục Google Drive chứa nhiều EPUB files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 📁 Mode 3: Bulk Folder Processing\n",
        "# @markdown Xử lý bulk multiple EPUB files từ Google Drive folder\n",
        "\n",
        "def mode3_bulk_folder_processing():\n",
        "    \"\"\"Mode 3: Bulk process EPUB files từ Google Drive folder\"\"\"\n",
        "    \n",
        "    if not github_manager or not platform_config_manager:\n",
        "        print(\"❌ Required managers not available!\")\n",
        "        print(\"🔧 Please configure GitHub credentials first\")\n",
        "        return\n",
        "    \n",
        "    print(\"📁 Mode 3: Bulk Folder Processing\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Mount Google Drive\n",
        "    print(\"📂 Mounting Google Drive...\")\n",
        "    if not drive_processor.mount_drive():\n",
        "        print(\"❌ Failed to mount Google Drive!\")\n",
        "        return\n",
        "    \n",
        "    # Get folder path\n",
        "    print(\"\\n📋 Folder Information:\")\n",
        "    print(\"💡 Tip: Browse to your EPUB folder trong file browser và copy path\")\n",
        "    print(\"📝 Example: /content/drive/MyDrive/Books/EPUBs/\")\n",
        "    \n",
        "    folder_path = input(\"📁 Folder path containing EPUB files: \").strip()\n",
        "    if not folder_path:\n",
        "        print(\"❌ Folder path is required!\")\n",
        "        return\n",
        "    \n",
        "    # Validate folder exists\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"❌ Folder not found: {folder_path}\")\n",
        "        return\n",
        "    \n",
        "    # Find EPUB files\n",
        "    print(f\"\\n🔍 Scanning for EPUB files...\")\n",
        "    epub_files = []\n",
        "    \n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.epub'):\n",
        "                epub_path = os.path.join(root, file)\n",
        "                epub_files.append(epub_path)\n",
        "    \n",
        "    if not epub_files:\n",
        "        print(f\"❌ No EPUB files found in {folder_path}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"✅ Found {len(epub_files)} EPUB files:\")\n",
        "    for i, epub_path in enumerate(epub_files, 1):\n",
        "        filename = os.path.basename(epub_path)\n",
        "        print(f\"   {i}. {filename}\")\n",
        "    \n",
        "    # Confirm processing\n",
        "    process_confirm = input(f\"\\n📋 Process all {len(epub_files)} EPUB files? (y/N): \").strip().lower()\n",
        "    \n",
        "    if process_confirm != 'y':\n",
        "        print(\"❌ Bulk processing cancelled\")\n",
        "        return\n",
        "    \n",
        "    # Setup processing parameters\n",
        "    print(f\"\\n⚙️ Processing Configuration:\")\n",
        "    \n",
        "    # Batch size\n",
        "    batch_size_input = input(\"📦 Batch size (default: 5): \").strip()\n",
        "    batch_size = int(batch_size_input) if batch_size_input.isdigit() else 5\n",
        "    \n",
        "    # Skip duplicates option\n",
        "    skip_duplicates = input(\"🔄 Skip duplicate books? (Y/n): \").strip().lower()\n",
        "    skip_duplicates = skip_duplicates != 'n'\n",
        "    \n",
        "    # Get shortener platforms for bulk processing\n",
        "    shortener_platforms = [p for p in platform_config_manager.platforms.values() if p['type'] == 'shortener']\n",
        "    \n",
        "    if shortener_platforms:\n",
        "        print(f\"\\n🔗 Available shortener platforms: {len(shortener_platforms)}\")\n",
        "        for platform in shortener_platforms:\n",
        "            print(f\"   • {platform['name']} (index {platform['index']})\")\n",
        "        \n",
        "        # Get fresh authentication for all platforms upfront\n",
        "        platform_auths = {}\n",
        "        for platform_info in shortener_platforms:\n",
        "            print(f\"\\n🔐 Setting up authentication for {platform_info['name']}...\")\n",
        "            \n",
        "            authenticated_curl = platform_auth_manager.build_authenticated_curl(\n",
        "                platform_info['id'], \n",
        "                platform_info['name'], \n",
        "                platform_info.get('curl_template', '')\n",
        "            )\n",
        "            \n",
        "            if authenticated_curl:\n",
        "                # Setup platform for bulk processing\n",
        "                dynamic_platform_manager.add_platform_from_curl(\n",
        "                    platform_info['name'], \n",
        "                    authenticated_curl, \n",
        "                    platform_info.get('response_config')\n",
        "                )\n",
        "                platform_auths[platform_info['id']] = True\n",
        "                print(f\"✅ {platform_info['name']} ready for bulk processing\")\n",
        "            else:\n",
        "                platform_auths[platform_info['id']] = False\n",
        "                print(f\"⚠️ {platform_info['name']} authentication failed, will skip\")\n",
        "    \n",
        "    # Start bulk processing\n",
        "    print(f\"\\n🚀 Starting bulk processing...\")\n",
        "    print(f\"📦 Batch size: {batch_size}\")\n",
        "    print(f\"🔄 Skip duplicates: {'Yes' if skip_duplicates else 'No'}\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    processed_count = 0\n",
        "    success_count = 0\n",
        "    duplicate_count = 0\n",
        "    error_count = 0\n",
        "    \n",
        "    # Process in batches\n",
        "    for batch_start in range(0, len(epub_files), batch_size):\n",
        "        batch_end = min(batch_start + batch_size, len(epub_files))\n",
        "        batch_files = epub_files[batch_start:batch_end]\n",
        "        \n",
        "        print(f\"\\n📦 Processing batch {batch_start//batch_size + 1}/{(len(epub_files)-1)//batch_size + 1}\")\n",
        "        print(f\"📂 Files {batch_start + 1}-{batch_end} of {len(epub_files)}\")\n",
        "        \n",
        "        for epub_path in batch_files:\n",
        "            processed_count += 1\n",
        "            filename = os.path.basename(epub_path)\n",
        "            \n",
        "            print(f\"\\n📖 [{processed_count}/{len(epub_files)}] Processing: {filename}\")\n",
        "            \n",
        "            try:\n",
        "                # Extract metadata\n",
        "                print(\"   📝 Extracting metadata...\")\n",
        "                metadata = epub_processor.extract_metadata(epub_path)\n",
        "                if not metadata:\n",
        "                    print(\"   ❌ Failed to extract metadata, skipping\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Check for duplicates\n",
        "                if skip_duplicates:\n",
        "                    is_duplicate, existing_file = github_manager.check_duplicate_book(\n",
        "                        metadata['title'], metadata['author']\n",
        "                    )\n",
        "                    \n",
        "                    if is_duplicate:\n",
        "                        print(f\"   ⚠️ Duplicate found: {existing_file}, skipping\")\n",
        "                        duplicate_count += 1\n",
        "                        continue\n",
        "                \n",
        "                # Create public sharing link\n",
        "                print(\"   🔗 Creating public sharing link...\")\n",
        "                # For bulk processing, we'll create a simple file://path as placeholder\n",
        "                # In real scenario, this would involve Google Drive API\n",
        "                public_drive_link = f\"https://drive.google.com/file/d/PLACEHOLDER_{processed_count}/view?usp=sharing\"\n",
        "                print(f\"   📋 Note: Please manually create sharing link for {filename}\")\n",
        "                \n",
        "                # Extract images\n",
        "                print(\"   🖼️ Processing images...\")\n",
        "                cover_path = epub_processor.extract_cover_image(epub_path)\n",
        "                \n",
        "                # Process images\n",
        "                image_urls = {}\n",
        "                if cloudinary_manager and cloudinary_manager.configured:\n",
        "                    print(\"   ☁️ Uploading to Cloudinary...\")\n",
        "                    image_urls = cloudinary_manager.process_epub_images(cover_path)\n",
        "                else:\n",
        "                    image_urls = {\n",
        "                        'cover_url': f\"https://via.placeholder.com/400x600/cccccc/ffffff?text={metadata['title'][:20]}\",\n",
        "                        'preview_url': f\"https://via.placeholder.com/800x1200/cccccc/ffffff?text={metadata['title'][:20]}\"\n",
        "                    }\n",
        "                \n",
        "                # Platform shortening\n",
        "                print(\"   🔗 Shortening URLs...\")\n",
        "                download_links = []\n",
        "                \n",
        "                # Process with available shortener platforms\n",
        "                for platform_info in shortener_platforms:\n",
        "                    if platform_auths.get(platform_info['id'], False):\n",
        "                        shortened_url = dynamic_platform_manager.shorten_url(\n",
        "                            platform_info['name'], \n",
        "                            public_drive_link\n",
        "                        )\n",
        "                        \n",
        "                        if shortened_url != public_drive_link:\n",
        "                            download_links.append({\n",
        "                                'platform': platform_info['name'],\n",
        "                                'url': shortened_url,\n",
        "                                'index': platform_info['index'],\n",
        "                                'icon': platform_info['icon']\n",
        "                            })\n",
        "                        \n",
        "                        # Add delay để tránh rate limiting\n",
        "                        time.sleep(1)\n",
        "                \n",
        "                # Add direct link\n",
        "                gdrive_platform = platform_config_manager.get_platform_by_index(0)\n",
        "                if gdrive_platform:\n",
        "                    download_links.append({\n",
        "                        'platform': gdrive_platform['name'],\n",
        "                        'url': public_drive_link,\n",
        "                        'index': gdrive_platform['index'],\n",
        "                        'icon': gdrive_platform['icon']\n",
        "                    })\n",
        "                \n",
        "                if not download_links:\n",
        "                    print(\"   ⚠️ No download links available, skipping\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Build book data\n",
        "                preview_content = epub_processor.extract_preview_content(epub_path)\n",
        "                \n",
        "                book_data = {\n",
        "                    'title': metadata['title'],\n",
        "                    'author': metadata['author'],\n",
        "                    'description': metadata['description'],\n",
        "                    'cover_image': image_urls['cover_url'],\n",
        "                    'preview_image': image_urls['preview_url'],\n",
        "                    'language': metadata['language'],\n",
        "                    'download_links': download_links,\n",
        "                    'config_url': credential_manager.get('default_config_api') or \"\"\n",
        "                }\n",
        "                \n",
        "                # Add optional fields\n",
        "                if metadata.get('publisher'):\n",
        "                    book_data['publisher'] = metadata['publisher']\n",
        "                if metadata.get('published_date'):\n",
        "                    book_data['published_date'] = metadata['published_date']\n",
        "                if metadata.get('isbn'):\n",
        "                    book_data['isbn'] = metadata['isbn']\n",
        "                if preview_content:\n",
        "                    book_data['preview_content'] = preview_content\n",
        "                \n",
        "                # Generate và upload markdown\n",
        "                print(\"   📝 Generating markdown...\")\n",
        "                markdown_content = markdown_generator.generate_markdown(book_data)\n",
        "                md_filename = markdown_generator.generate_filename(metadata['title'])\n",
        "                \n",
        "                file_path = f\"_epubs/{md_filename}\"\n",
        "                commit_message = f\"Bulk add: {metadata['title']} - {metadata['author']}\"\n",
        "                \n",
        "                # Upload to GitHub\n",
        "                print(\"   📤 Uploading to GitHub...\")\n",
        "                if github_manager.file_exists(file_path):\n",
        "                    success = github_manager.update_file(file_path, markdown_content, commit_message)\n",
        "                else:\n",
        "                    success = github_manager.create_file(file_path, markdown_content, commit_message)\n",
        "                \n",
        "                if success:\n",
        "                    success_count += 1\n",
        "                    print(f\"   ✅ Success: {metadata['title']}\")\n",
        "                    print(f\"      📂 File: {md_filename}\")\n",
        "                    print(f\"      🔗 Links: {len(download_links)}\")\n",
        "                else:\n",
        "                    error_count += 1\n",
        "                    print(f\"   ❌ Upload failed: {metadata['title']}\")\n",
        "                \n",
        "                # Cleanup\n",
        "                if cover_path and os.path.exists(cover_path):\n",
        "                    os.remove(cover_path)\n",
        "                \n",
        "            except Exception as e:\n",
        "                error_count += 1\n",
        "                print(f\"   ❌ Error processing {filename}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # Batch completion message\n",
        "        print(f\"\\n📊 Batch {batch_start//batch_size + 1} completed\")\n",
        "        print(f\"   ✅ Success: {success_count}\")\n",
        "        print(f\"   ⚠️ Duplicates: {duplicate_count}\")\n",
        "        print(f\"   ❌ Errors: {error_count}\")\n",
        "        \n",
        "        # Pause between batches (nếu không phải batch cuối)\n",
        "        if batch_end < len(epub_files):\n",
        "            delay = input(f\"\\n⏸️ Pause before next batch? Enter seconds (default: 3): \").strip()\n",
        "            delay_time = int(delay) if delay.isdigit() else 3\n",
        "            print(f\"⏱️ Waiting {delay_time} seconds...\")\n",
        "            time.sleep(delay_time)\n",
        "    \n",
        "    # Final summary\n",
        "    print(f\"\\n🎉 BULK PROCESSING COMPLETED!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"📂 Total files processed: {processed_count}\")\n",
        "    print(f\"✅ Successfully added: {success_count}\")\n",
        "    print(f\"⚠️ Duplicates skipped: {duplicate_count}\")\n",
        "    print(f\"❌ Errors encountered: {error_count}\")\n",
        "    print(f\"📈 Success rate: {(success_count/processed_count)*100:.1f}%\")\n",
        "    \n",
        "    if success_count > 0:\n",
        "        print(f\"\\n🚀 GitHub Pages will rebuild automatically\")\n",
        "        print(f\"📚 {success_count} new books added to library\")\n",
        "        \n",
        "        # Show processing stats\n",
        "        print(f\"\\n📊 Processing Statistics:\")\n",
        "        if shortener_platforms:\n",
        "            print(f\"   🔗 Platform shortening: {len(shortener_platforms)} platforms used\")\n",
        "        if cloudinary_manager and cloudinary_manager.configured:\n",
        "            print(f\"   ☁️ Image processing: Cloudinary enabled\")\n",
        "        print(f\"   📦 Batch size: {batch_size}\")\n",
        "        print(f\"   ⏱️ Total time: ~{processed_count * 2} seconds estimated\")\n",
        "    \n",
        "    print(f\"\\n💡 Notes:\")\n",
        "    print(f\"   📝 Remember to manually create public sharing links\")\n",
        "    print(f\"   🔗 Replace PLACEHOLDER links with real Google Drive URLs\")\n",
        "    print(f\"   🔄 Re-run shortening for updated links if needed\")\n",
        "\n",
        "# Run Mode 3\n",
        "mode3_bulk_folder_processing()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# 🔄 Legacy Book Conversion Tool\n",
        "\n",
        "Convert existing books khi có platform mới\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 🔄 Legacy Book Conversion Tool\n",
        "# @markdown Convert existing books với platform mới\n",
        "\n",
        "def legacy_book_conversion():\n",
        "    \"\"\"Convert tất cả sách cũ với platform mới\"\"\"\n",
        "    \n",
        "    if not github_manager or not platform_config_manager:\n",
        "        print(\"❌ Required managers not available!\")\n",
        "        print(\"🔧 Please configure GitHub credentials first\")\n",
        "        return\n",
        "    \n",
        "    print(\"🔄 Legacy Book Conversion Tool\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Get list of all existing epub files\n",
        "    print(\"📂 Scanning existing books...\")\n",
        "    \n",
        "    try:\n",
        "        epub_contents = github_manager.repo.get_contents(\"_epubs\", ref=github_manager.branch)\n",
        "        existing_books = [content for content in epub_contents if content.name.endswith('.md')]\n",
        "        \n",
        "        if not existing_books:\n",
        "            print(\"❌ No existing books found!\")\n",
        "            return\n",
        "        \n",
        "        print(f\"✅ Found {len(existing_books)} existing books\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error scanning books: {e}\")\n",
        "        return\n",
        "    \n",
        "    # Show available platforms\n",
        "    print(f\"\\n🔗 Available Platforms:\")\n",
        "    platform_config_manager.list_platforms()\n",
        "    \n",
        "    # Get shortener platforms\n",
        "    shortener_platforms = [p for p in platform_config_manager.platforms.values() if p['type'] == 'shortener']\n",
        "    \n",
        "    if not shortener_platforms:\n",
        "        print(\"❌ No shortener platforms available for conversion!\")\n",
        "        return\n",
        "    \n",
        "    # Select platform for conversion\n",
        "    print(f\"\\n🎯 Platform Selection:\")\n",
        "    print(\"Available shortener platforms:\")\n",
        "    for i, platform in enumerate(shortener_platforms, 1):\n",
        "        print(f\"   {i}. {platform['name']} (index {platform['index']})\")\n",
        "    \n",
        "    platform_choice = input(f\"\\nSelect platform number (1-{len(shortener_platforms)}): \").strip()\n",
        "    \n",
        "    try:\n",
        "        platform_index = int(platform_choice) - 1\n",
        "        if 0 <= platform_index < len(shortener_platforms):\n",
        "            selected_platform = shortener_platforms[platform_index]\n",
        "        else:\n",
        "            print(\"❌ Invalid platform selection!\")\n",
        "            return\n",
        "    except ValueError:\n",
        "        print(\"❌ Invalid input!\")\n",
        "        return\n",
        "    \n",
        "    print(f\"✅ Selected: {selected_platform['name']}\")\n",
        "    \n",
        "    # Get authentication for selected platform\n",
        "    print(f\"\\n🔐 Setting up authentication for {selected_platform['name']}...\")\n",
        "    \n",
        "    authenticated_curl = platform_auth_manager.build_authenticated_curl(\n",
        "        selected_platform['id'], \n",
        "        selected_platform['name'], \n",
        "        selected_platform.get('curl_template', '')\n",
        "    )\n",
        "    \n",
        "    if not authenticated_curl:\n",
        "        print(f\"❌ Authentication failed for {selected_platform['name']}!\")\n",
        "        return\n",
        "    \n",
        "    # Setup platform for processing\n",
        "    dynamic_platform_manager.add_platform_from_curl(\n",
        "        selected_platform['name'], \n",
        "        authenticated_curl, \n",
        "        selected_platform.get('response_config')\n",
        "    )\n",
        "    \n",
        "    print(f\"✅ Platform {selected_platform['name']} ready for conversion\")\n",
        "    \n",
        "    # Processing options\n",
        "    print(f\"\\n⚙️ Conversion Options:\")\n",
        "    \n",
        "    # Batch size\n",
        "    batch_size_input = input(\"📦 Batch size (default: 10): \").strip()\n",
        "    batch_size = int(batch_size_input) if batch_size_input.isdigit() else 10\n",
        "    \n",
        "    # Test mode\n",
        "    test_mode = input(\"🧪 Test mode (preview changes without committing)? (y/N): \").strip().lower() == 'y'\n",
        "    \n",
        "    # Confirmation\n",
        "    if not test_mode:\n",
        "        confirm = input(f\"\\n⚠️  CONFIRM: Convert {len(existing_books)} books với {selected_platform['name']}? (type 'CONVERT'): \").strip()\n",
        "        if confirm != 'CONVERT':\n",
        "            print(\"❌ Conversion cancelled\")\n",
        "            return\n",
        "    \n",
        "    # Start conversion\n",
        "    print(f\"\\n🚀 Starting legacy book conversion...\")\n",
        "    print(f\"📦 Batch size: {batch_size}\")\n",
        "    print(f\"🧪 Test mode: {'Yes' if test_mode else 'No'}\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    processed_count = 0\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "    no_gdrive_count = 0\n",
        "    \n",
        "    # Process in batches\n",
        "    for batch_start in range(0, len(existing_books), batch_size):\n",
        "        batch_end = min(batch_start + batch_size, len(existing_books))\n",
        "        batch_books = existing_books[batch_start:batch_end]\n",
        "        \n",
        "        print(f\"\\n📦 Processing batch {batch_start//batch_size + 1}/{(len(existing_books)-1)//batch_size + 1}\")\n",
        "        print(f\"📂 Books {batch_start + 1}-{batch_end} of {len(existing_books)}\")\n",
        "        \n",
        "        for book_content in batch_books:\n",
        "            processed_count += 1\n",
        "            book_filename = book_content.name\n",
        "            \n",
        "            print(f\"\\n📖 [{processed_count}/{len(existing_books)}] Processing: {book_filename}\")\n",
        "            \n",
        "            try:\n",
        "                # Get book content\n",
        "                print(\"   📥 Reading book content...\")\n",
        "                file_content = github_manager.get_file_content(f\"_epubs/{book_filename}\")\n",
        "                if not file_content:\n",
        "                    print(\"   ❌ Failed to read book content\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Parse YAML front matter\n",
        "                print(\"   📝 Parsing metadata...\")\n",
        "                if not file_content.startswith('---'):\n",
        "                    print(\"   ❌ Invalid file format (no YAML front matter)\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Split content into YAML and body\n",
        "                parts = file_content.split('---')\n",
        "                if len(parts) < 3:\n",
        "                    print(\"   ❌ Invalid YAML format\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                yaml_content = parts[1]\n",
        "                body_content = '---'.join(parts[2:])\n",
        "                \n",
        "                # Parse YAML\n",
        "                try:\n",
        "                    import yaml\n",
        "                    book_data = yaml.safe_load(yaml_content)\n",
        "                except Exception as e:\n",
        "                    print(f\"   ❌ YAML parsing error: {e}\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Extract existing download links\n",
        "                existing_links = book_data.get('download_links', [])\n",
        "                if not existing_links:\n",
        "                    print(\"   ⚠️ No download links found\")\n",
        "                    no_gdrive_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Find Google Drive links\n",
        "                gdrive_links = []\n",
        "                for link in existing_links:\n",
        "                    if ('drive.google.com' in link.get('url', '') and \n",
        "                        link.get('platform', '').lower() in ['google drive', 'gdrive']):\n",
        "                        gdrive_links.append(link['url'])\n",
        "                \n",
        "                if not gdrive_links:\n",
        "                    print(\"   ⚠️ No Google Drive links found to convert\")\n",
        "                    no_gdrive_count += 1\n",
        "                    continue\n",
        "                \n",
        "                print(f\"   🔍 Found {len(gdrive_links)} Google Drive links\")\n",
        "                \n",
        "                # Process shortening for new platform\n",
        "                new_links_added = []\n",
        "                \n",
        "                for gdrive_url in gdrive_links:\n",
        "                    # Decode URL if obfuscated\n",
        "                    actual_url = gdrive_url\n",
        "                    if gdrive_url.startswith('data:encoded,'):\n",
        "                        decoded_url = link_obfuscator.decode(gdrive_url)\n",
        "                        if decoded_url:\n",
        "                            actual_url = decoded_url\n",
        "                    \n",
        "                    print(f\"   🔗 Shortening: {actual_url[:50]}...\")\n",
        "                    \n",
        "                    # Shorten with new platform\n",
        "                    shortened_url = dynamic_platform_manager.shorten_url(\n",
        "                        selected_platform['name'], \n",
        "                        actual_url\n",
        "                    )\n",
        "                    \n",
        "                    if shortened_url != actual_url:\n",
        "                        new_link = {\n",
        "                            'platform': selected_platform['name'],\n",
        "                            'url': shortened_url,\n",
        "                            'index': selected_platform['index'],\n",
        "                            'icon': selected_platform['icon']\n",
        "                        }\n",
        "                        new_links_added.append(new_link)\n",
        "                        print(f\"   ✅ Shortened: {shortened_url}\")\n",
        "                    else:\n",
        "                        print(f\"   ⚠️ Shortening failed\")\n",
        "                    \n",
        "                    # Delay để tránh rate limiting\n",
        "                    time.sleep(1)\n",
        "                \n",
        "                if not new_links_added:\n",
        "                    print(\"   ❌ No new links generated\")\n",
        "                    error_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Check if platform already exists trong book\n",
        "                platform_exists = any(\n",
        "                    link.get('index') == selected_platform['index'] \n",
        "                    for link in existing_links\n",
        "                )\n",
        "                \n",
        "                if platform_exists:\n",
        "                    print(f\"   ⚠️ Platform {selected_platform['name']} already exists, updating...\")\n",
        "                    # Update existing platform link\n",
        "                    for i, link in enumerate(existing_links):\n",
        "                        if link.get('index') == selected_platform['index']:\n",
        "                            existing_links[i] = new_links_added[0]  # Use first new link\n",
        "                            break\n",
        "                else:\n",
        "                    print(f\"   ✅ Adding new platform {selected_platform['name']}\")\n",
        "                    # Add new platform links\n",
        "                    existing_links.extend(new_links_added)\n",
        "                \n",
        "                # Update book data\n",
        "                book_data['download_links'] = existing_links\n",
        "                \n",
        "                # Generate updated YAML content\n",
        "                updated_yaml = yaml.dump(book_data, default_flow_style=False, allow_unicode=True)\n",
        "                updated_content = f\"---\\n{updated_yaml}---{body_content}\"\n",
        "                \n",
        "                if test_mode:\n",
        "                    print(\"   🧪 TEST MODE: Changes prepared (not committed)\")\n",
        "                    print(f\"      📊 New links: {len(new_links_added)}\")\n",
        "                    print(f\"      📏 Content length: {len(updated_content)} chars\")\n",
        "                    success_count += 1\n",
        "                else:\n",
        "                    # Commit changes\n",
        "                    print(\"   📤 Updating book...\")\n",
        "                    commit_message = f\"Add {selected_platform['name']} links: {book_data.get('title', 'Unknown')}\"\n",
        "                    \n",
        "                    success = github_manager.update_file(\n",
        "                        f\"_epubs/{book_filename}\",\n",
        "                        updated_content,\n",
        "                        commit_message\n",
        "                    )\n",
        "                    \n",
        "                    if success:\n",
        "                        success_count += 1\n",
        "                        print(f\"   ✅ Updated: {book_data.get('title', book_filename)}\")\n",
        "                        print(f\"      📊 Added {len(new_links_added)} new links\")\n",
        "                    else:\n",
        "                        error_count += 1\n",
        "                        print(f\"   ❌ Update failed\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                error_count += 1\n",
        "                print(f\"   ❌ Error processing {book_filename}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # Batch completion message\n",
        "        print(f\"\\n📊 Batch {batch_start//batch_size + 1} completed\")\n",
        "        print(f\"   ✅ Success: {success_count}\")\n",
        "        print(f\"   ⚠️ No GDrive links: {no_gdrive_count}\")\n",
        "        print(f\"   ❌ Errors: {error_count}\")\n",
        "        \n",
        "        # Pause between batches\n",
        "        if batch_end < len(existing_books):\n",
        "            delay = input(f\"\\n⏸️ Pause before next batch? Enter seconds (default: 5): \").strip()\n",
        "            delay_time = int(delay) if delay.isdigit() else 5\n",
        "            print(f\"⏱️ Waiting {delay_time} seconds...\")\n",
        "            time.sleep(delay_time)\n",
        "    \n",
        "    # Final summary\n",
        "    print(f\"\\n🎉 LEGACY CONVERSION COMPLETED!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"📂 Total books processed: {processed_count}\")\n",
        "    print(f\"✅ Successfully converted: {success_count}\")\n",
        "    print(f\"⚠️ No Google Drive links: {no_gdrive_count}\")\n",
        "    print(f\"❌ Errors encountered: {error_count}\")\n",
        "    print(f\"📈 Success rate: {(success_count/max(processed_count-no_gdrive_count,1))*100:.1f}%\")\n",
        "    \n",
        "    if test_mode:\n",
        "        print(f\"\\n🧪 TEST MODE SUMMARY:\")\n",
        "        print(f\"   📋 Changes previewed, no commits made\")\n",
        "        print(f\"   🔄 Run again without test mode to apply changes\")\n",
        "    else:\n",
        "        if success_count > 0:\n",
        "            print(f\"\\n🚀 GitHub Pages will rebuild automatically\")\n",
        "            print(f\"🔗 {success_count} books now have {selected_platform['name']} links\")\n",
        "            print(f\"📱 Platform index {selected_platform['index']} ready for API configuration\")\n",
        "    \n",
        "    print(f\"\\n📊 Platform Statistics:\")\n",
        "    print(f\"   🆔 Platform ID: {selected_platform['id']}\")\n",
        "    print(f\"   📍 Platform Index: {selected_platform['index']}\")\n",
        "    print(f\"   🎯 Books Updated: {success_count}\")\n",
        "    print(f\"   ⏱️ Total Processing Time: ~{processed_count * 3} seconds\")\n",
        "\n",
        "# Run Legacy Conversion\n",
        "legacy_book_conversion()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
